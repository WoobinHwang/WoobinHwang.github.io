<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>k-최근접 이웃 회귀 03 | WB&#39;blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="특성 공학과 규제 다중회귀: 여러가지 특성을 사용한 선형회귀   특성공학: 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업    데이터 준비 판다스: 유명한 데이터 분석 라이브러리 데이터프레임: 판다스의 핵심 데이터 구조    12345import pandas as pd# pd.__version__df &#x3D; pd.read_csv(&quot;https:&#x2F;&#x2F;b">
<meta property="og:type" content="article">
<meta property="og:title" content="k-최근접 이웃 회귀 03">
<meta property="og:url" content="https://woobinhwang.github.io/2022/03/28/0328_Regression_03/index.html">
<meta property="og:site_name" content="WB&#39;blog">
<meta property="og:description" content="특성 공학과 규제 다중회귀: 여러가지 특성을 사용한 선형회귀   특성공학: 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업    데이터 준비 판다스: 유명한 데이터 분석 라이브러리 데이터프레임: 판다스의 핵심 데이터 구조    12345import pandas as pd# pd.__version__df &#x3D; pd.read_csv(&quot;https:&#x2F;&#x2F;b">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0328_Regression_03/output_34_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0328_Regression_03/output_41_0.png">
<meta property="article:published_time" content="2022-03-28T00:00:00.000Z">
<meta property="article:modified_time" content="2022-03-28T14:00:10.311Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://woobinhwang.github.io/Images/0328_Regression_03/output_34_0.png">
  
    <link rel="alternate" href="/atom.xml" title="WB'blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">WB&#39;blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://woobinhwang.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-0328_Regression_03" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/28/0328_Regression_03/" class="article-date">
  <time class="dt-published" datetime="2022-03-28T00:00:00.000Z" itemprop="datePublished">2022-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      k-최근접 이웃 회귀 03
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="특성-공학과-규제"><a href="#특성-공학과-규제" class="headerlink" title="특성 공학과 규제"></a>특성 공학과 규제</h1><ul>
<li>다중회귀:<ul>
<li>여러가지 특성을 사용한 선형회귀</li>
</ul>
</li>
<li>특성공학:<ul>
<li>기존의 특성을 사용해 새로운 특성을 뽑아내는 작업</li>
</ul>
</li>
</ul>
<h1 id="데이터-준비"><a href="#데이터-준비" class="headerlink" title="데이터 준비"></a>데이터 준비</h1><ul>
<li>판다스: 유명한 데이터 분석 라이브러리<ul>
<li>데이터프레임: 판다스의 핵심 데이터 구조</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># pd.__version__</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;https://bit.ly/perch_csv_data&quot;</span>)</span><br><span class="line">perch_full = df.to_numpy()</span><br><span class="line"><span class="comment"># print(perch_full)</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://gist.github.com/rickiepark/2cd82455e985001542047d7d55d50630</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">perch_weight = np.array([<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, <span class="number">110.0</span>,</span><br><span class="line">       <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, <span class="number">130.0</span>,</span><br><span class="line">       <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, <span class="number">197.0</span>,</span><br><span class="line">       <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, <span class="number">514.0</span>,</span><br><span class="line">       <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, <span class="number">820.0</span>,</span><br><span class="line">       <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>,</span><br><span class="line">       <span class="number">1000.0</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li>perch_full과 perch_weight를 훈련세트와 테스트 세트로 나눔</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state= <span class="number">42</span>)</span><br><span class="line"><span class="built_in">print</span>(train_target)</span><br></pre></td></tr></table></figure>

<pre><code>[  85.  135.   78.   70.  700.  180.  850.  820. 1000.  120.   85.  130.
  225.  260. 1100.  900.  145.  115.  265. 1015.  514.  218.  685.   32.
  145.   40.  690.  840.  300.  170.  650.  110.  150.  110. 1000.  150.
   80.  700.  120.  197. 1100.  556.]
</code></pre>
<h1 id="사이킷런의-변환기"><a href="#사이킷런의-변환기" class="headerlink" title="사이킷런의 변환기"></a>사이킷런의 변환기</h1><ul>
<li>변환기: 특성을 만들거나 전처리하기 위한 다양한 클래스들<ul>
<li>fit(), score(), predict(), transform(), 등등…</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line">poly = PolynomialFeatures()</span><br><span class="line">poly.fit([[<span class="number">2</span>,<span class="number">3</span>]])  <span class="comment"># 변환 전 학습시키기</span></span><br><span class="line"><span class="built_in">print</span>(poly.transform([[<span class="number">2</span>,<span class="number">3</span>]]))  <span class="comment"># 2,3의 특성을 변환시킨것</span></span><br></pre></td></tr></table></figure>

<pre><code>[[1. 2. 3. 4. 6. 9.]]


  - 2와 3을 곱한 6, 각각 제곱한 4, 9, 절편인 1이 추가되었다.
</code></pre>
<ul>
<li>사이킷런 특성상 절편을 자동으로 추가하므로 1은 필요 없음.<ul>
<li>include_bias&#x3D; False로 제거</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(include_bias= <span class="literal">False</span>)</span><br><span class="line">poly.fit([[<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(poly.transform([[<span class="number">2</span>, <span class="number">3</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[[2. 3. 4. 6. 9.]]
</code></pre>
<ul>
<li>train_input에 적용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(include_bias= <span class="literal">False</span>)  <span class="comment"># 1은 제외</span></span><br><span class="line">poly.fit(train_input)  <span class="comment"># 변환 전 학습시키기</span></span><br><span class="line">train_poly = poly.transform(train_input)  <span class="comment"># 변환</span></span><br><span class="line"><span class="built_in">print</span>(train_poly.shape)</span><br><span class="line"><span class="comment"># print(train_poly)</span></span><br></pre></td></tr></table></figure>

<pre><code>(42, 9)
</code></pre>
<ul>
<li>PolynomiaFeatures클래스의 get_feature_names_&#x2F;Images&#x2F;0328_Regression_03&#x2F;out()의 메서드로 9개의 특성이 각각 어떤 입력의 조합으로 만들어졌는지 알 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poly.get_feature_names_/Images/0328_Regression_03/out()</span><br></pre></td></tr></table></figure>




<pre><code>array([&#39;x0&#39;, &#39;x1&#39;, &#39;x2&#39;, &#39;x0^2&#39;, &#39;x0 x1&#39;, &#39;x0 x2&#39;, &#39;x1^2&#39;, &#39;x1 x2&#39;,
       &#39;x2^2&#39;], dtype=object)



  각각 x0, x1, x2에서 파생된 값들
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_poly= poly.transform(test_input)  <span class="comment"># test_input 을 변환</span></span><br><span class="line"><span class="comment"># print(test_poly)</span></span><br></pre></td></tr></table></figure>

<pre><code>  poly: 2,3을 transform한 값
  train_poly: train_input을 transform한 값
  test_poly: test_input을 transform한 값
</code></pre>
<h1 id="다중회귀-모델-훈련"><a href="#다중회귀-모델-훈련" class="headerlink" title="다중회귀 모델 훈련"></a>다중회귀 모델 훈련</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(train_poly, train_target)  <span class="comment"># fit(): 훈련시키기</span></span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))  <span class="comment"># 정답률 99퍼센트</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9903183436982124
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))  <span class="comment"># 정답률 97퍼센트</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9714559911594134
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(degree= <span class="number">5</span>, include_bias= <span class="literal">False</span>)  <span class="comment"># 5제곱까지 특성을 만들어 출력, 1은 제외</span></span><br><span class="line">poly.fit(train_input)  <span class="comment"># 변환 전 학습시키기</span></span><br><span class="line">train_poly = poly.transform(train_input)  <span class="comment"># 변환시키기</span></span><br><span class="line">test_poly = poly.transform(test_input)  <span class="comment"># 변환시키기</span></span><br><span class="line"><span class="built_in">print</span>(train_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 55)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr.fit(train_poly, train_target)  <span class="comment"># fit(): 훈련시키기</span></span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))  <span class="comment"># 정답률 100퍼센트에 가까움</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9999999999991097
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))  <span class="comment"># 점수가 음수로 나옴</span></span><br></pre></td></tr></table></figure>

<pre><code>-144.40579242684848


  144로 음수가 나와 과대적합이 되었음.
  특성을 줄일 필요가 있음.
</code></pre>
<h1 id="규제-Regularization"><a href="#규제-Regularization" class="headerlink" title="규제(Regularization)"></a>규제(Regularization)</h1><ul>
<li>머신러닝 모델이 훈련세트를 너무 과도하게 학습하지 못하도록 훼방하는 것</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 정규화 우선</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_poly)  <span class="comment"># 변환 전 학습시키기 </span></span><br><span class="line">train_scaled = ss.transform(train_poly)  <span class="comment"># 정규화</span></span><br><span class="line">test_scaled = ss.transform(test_poly)  <span class="comment"># 정규화</span></span><br></pre></td></tr></table></figure>

<h1 id="릿지-Ridge-와-라쏘-Lasso"><a href="#릿지-Ridge-와-라쏘-Lasso" class="headerlink" title="릿지(Ridge)와 라쏘(Lasso)"></a>릿지(Ridge)와 라쏘(Lasso)</h1><ul>
<li>선형 회귀모델에 규제를 추가한 모델</li>
</ul>
<h2 id="릿지-회귀-Ridge"><a href="#릿지-회귀-Ridge" class="headerlink" title="릿지 회귀 (Ridge)"></a>릿지 회귀 (Ridge)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">ridge = Ridge()</span><br><span class="line">ridge.fit(train_scaled, train_target)  <span class="comment"># fit()로 학습시키기</span></span><br><span class="line"><span class="built_in">print</span>(ridge.score(train_scaled, train_target))  <span class="comment"># 0.99의 점수가 나옴</span></span><br><span class="line"><span class="built_in">print</span>(ridge.score(test_scaled, test_target))  <span class="comment"># 점수가 정상으로 돌아옴</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9896101671037343
0.9790693977615397
</code></pre>
<ul>
<li><p>릿지와 라쏘 모델을 사용 할 때 alpha매개변수로 규제의 강도를 조절 가능</p>
<ul>
<li>alpha값이 크면 규제강도가 세지므로 과소적합되도록 유도</li>
<li>alpha값이 작으면 규제강도가 세지므로 과대적합되도록 유도</li>
</ul>
</li>
<li><p>적절한 alpha값을 찾는 방법중 하나로는 alpha값에 대한 R^2값의 그래프를 그려보는것.</p>
<ul>
<li>훈련세트와 테스트 세트의 점수가 가장 가까운 지점이 최적의 alpha값</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># alpha값을 0.001~100까지 10배씩 늘리며 회귀모델을 훈련</span></span><br><span class="line">alpha_list = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alpha_list:</span><br><span class="line">  <span class="comment"># 릿지모델을 만듬</span></span><br><span class="line">  ridge = Ridge(alpha=alpha)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 릿지모델을 훈련</span></span><br><span class="line">  ridge.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 훈련 점수와 테스트 점수를 저장</span></span><br><span class="line">  train_score.append(ridge.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(ridge.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 로그함수로 나타내어 그래프 그리기</span></span><br><span class="line"><span class="comment"># 객체지향 함수로 진행</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax= plt.subplots()</span><br><span class="line">ax.plot(np.log10(alpha_list), train_score)  <span class="comment"># 위에 그려질 그래프</span></span><br><span class="line">ax.plot(np.log10(alpha_list), test_score)  <span class="comment"># 아래에 그려질 그래프</span></span><br><span class="line">ax.set_xlabel(<span class="string">&quot;alpha&quot;</span>)  <span class="comment"># x축은 지수를 나타냄</span></span><br><span class="line">ax.set_ylabel(<span class="string">&quot;R^2&quot;</span>)  <span class="comment"># == score의 점수</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0328_Regression_03/output_34_0.png" alt="png"></p>
<pre><code>  0.1인 -1에서 가장 가깝고 결정계수가 가장 높기때문에 alpha로 선정
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ridge = Ridge(alpha=<span class="number">0.1</span>)</span><br><span class="line">ridge.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(ridge.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(ridge.score(test_scaled, test_target))  <span class="comment"># 둘이 비슷하게 높은 점수가 나옴.</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9903815817570366
0.9827976465386926
</code></pre>
<h1 id="라쏘-Lasso"><a href="#라쏘-Lasso" class="headerlink" title="라쏘 (Lasso)"></a>라쏘 (Lasso)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line">lasso = Lasso()</span><br><span class="line">lasso.fit(train_scaled, train_target)  <span class="comment"># fit()로 학습시키기</span></span><br><span class="line"><span class="built_in">print</span>(lasso.score(train_scaled, train_target))  <span class="comment"># 0.99의 점수가 나옴</span></span><br><span class="line"><span class="built_in">print</span>(lasso.score(test_scaled, test_target))  <span class="comment"># 점수가 정상으로 돌아옴</span></span><br></pre></td></tr></table></figure>

<pre><code>0.989789897208096
0.9800593698421883
</code></pre>
<ul>
<li>적절한 alpha 값 찾기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># alpha값을 0.001~100까지 10배씩 늘리며 회귀모델을 훈련</span></span><br><span class="line">alpha_list = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alpha_list:</span><br><span class="line">  <span class="comment"># 라쏘모델을 만듬</span></span><br><span class="line">  lasso = Lasso(alpha=alpha, max_iter=<span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 라쏘모델을 훈련</span></span><br><span class="line">  lasso.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 훈련 점수와 테스트 점수를 저장</span></span><br><span class="line">  train_score.append(lasso.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(lasso.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+04, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+04, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 로그함수로 나타내어 그래프 그리기</span></span><br><span class="line"><span class="comment"># 객체지향 함수로 진행</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax= plt.subplots()</span><br><span class="line">ax.plot(np.log10(alpha_list), train_score)  <span class="comment"># 위에 그려질 그래프</span></span><br><span class="line">ax.plot(np.log10(alpha_list), test_score)  <span class="comment"># 아래에 그려질 그래프</span></span><br><span class="line">ax.set_xlabel(<span class="string">&quot;alpha&quot;</span>)  <span class="comment"># x축은 지수를 나타냄</span></span><br><span class="line">ax.set_ylabel(<span class="string">&quot;R^2&quot;</span>)  <span class="comment"># == score의 점수</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0328_Regression_03/output_41_0.png" alt="png"></p>
<pre><code>  alpha가 2인 값은 훈련세트와 테스트세트의 점수가 좁음
  하지만 결정계수가 낮기때문에 10을 의미하는 1이 최적의 alpha값임. 
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lasso = Lasso(alpha=<span class="number">0.1</span>)</span><br><span class="line">lasso.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lasso.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lasso.score(test_scaled, test_target))  <span class="comment"># 라쏘 또한 둘이 비슷하게 높은 점수가 나옴.</span></span><br></pre></td></tr></table></figure>

<pre><code>0.990137631128448
0.9819405116249363


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.062e+02, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
</code></pre>
<ul>
<li>라쏘모델의 계수값을 아예 0으로 만들 수 있음.</li>
<li>라쏘 모델의 계수는 coef_ 속성에 저장되어 있음.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(lasso.coef_ == <span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<pre><code>52
</code></pre>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li><p>키워드</p>
<ul>
<li>다중회귀: 여러개의 특성을 사용하는 회귀모델</li>
<li>특성공학: 주어진 특성을 조합하여 새로운 특성을 만드는 일련의 작업과정</li>
<li>릿지: 규제가 있는 선형 회귀모델중 하나이며 선형 모델의 계수를 작게 만들어 과대적합을 완화시킴</li>
<li>라쏘: 또 다른 규제가 있는 선형회귀 모델. 릿지와 달리 계수값을 0으로 만들 수 있음.</li>
<li>하이퍼파라미터: 머신러닝 알고리즘이 학습하지 않는 파라미터. 사람이 지정해야함. 대표적으로 릿지와 라쏘의 규제 강도 alpha파라미터가 있음.</li>
</ul>
</li>
<li><p>Pandas 패키지</p>
<ul>
<li>유명한 데이터 분석 라이브러리</li>
<li>read_csv(): 로컬 컴퓨터나 인터넷에 있는 csv파일을 읽어 판다스 데이터프레임으로 변환하는 함수</li>
</ul>
</li>
<li><p>Scikit-learn 패키지</p>
<ul>
<li>PolynomialFeatures: 주어진 특성을 조합하여 새로운 특성을 만듬<ul>
<li>degree: 최고 차수를 지정함. [default: 2]</li>
<li>interactopm_only: True이면 거듭제곱항은 제외되고 특성간의 곱셈항만 추가됨. [default: False]</li>
<li>include_bias: False이면 절편을 위한 특성을 추가하지 않음. [default: True]</li>
</ul>
</li>
<li>Ridge: 규제가 있는 회귀 알고리즘인 릿지 회귀모델을 훈련함.<ul>
<li>alpha: 매개변수로 규제의 강도를 조절함. 값이 클수록 규제가 강함. [default: 1]</li>
</ul>
</li>
<li>Lasso: 규제가 있는 회귀 알고리즘인 라쏘 회귀모델을 훈련함. 최적의 모델을 찾기 위해 좌표축을 따라 최적화를 수행해가는 좌표 하강법을 사용<ul>
<li>alpha와 random_state매개변수는 Ridge클래스와 동일</li>
<li>max_iter: 알고리즘의 수행 반복 횟수를 지정함. [default: 1000]</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/28/0328_Regression_03/" data-id="cl1as2bec0002dknhbc968uhc" data-title="k-최근접 이웃 회귀 03" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/03/28/0328_Regression_02/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          k-최근접 이웃 회귀 02
        
      </div>
    </a>
  
  
    <a href="/2022/03/26/0326_Machine_Learning/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">머신러닝 교재 실습 01</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/04/08/0408_LSTM,GRU_Cell/">LSTM과 GRU셀</a>
          </li>
        
          <li>
            <a href="/2022/04/08/0408_IMDB/">IMDB 리뷰</a>
          </li>
        
          <li>
            <a href="/2022/04/07/0407_Sequentoal_Data,Recurrent_Neural_Network/">순차 데이터와 순환 신경망</a>
          </li>
        
          <li>
            <a href="/2022/04/07/0407_Convolution_Neural_Network_02/">합성곱 신경망_02</a>
          </li>
        
          <li>
            <a href="/2022/04/06/0406_Convolution_Neural_Network/">합성곱 신경망_01</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>