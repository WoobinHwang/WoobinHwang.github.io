<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>합성곱 신경망_02 | WB&#39;blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="합성곱 신경망을 사용한 이미지 분류패션 MNIST 데이터 불러오기 데이터 스케일 0 ~ 255의 데이터를 0 ~ 1로 표준화  훈련 데이터 &#x2F; 검증 데이터 분류  합성곱 신경망은 2차원 이미지를 그대로 사용하기 때문에 일렬로 펼치지 않아도 됨  완전 연결 신경망 (Fully Connected Layer)  2차원 배열을 1차원 배열로 바꿔야함">
<meta property="og:type" content="article">
<meta property="og:title" content="합성곱 신경망_02">
<meta property="og:url" content="https://woobinhwang.github.io/2022/04/07/0407_Convolution_Neural_Network_02/index.html">
<meta property="og:site_name" content="WB&#39;blog">
<meta property="og:description" content="합성곱 신경망을 사용한 이미지 분류패션 MNIST 데이터 불러오기 데이터 스케일 0 ~ 255의 데이터를 0 ~ 1로 표준화  훈련 데이터 &#x2F; 검증 데이터 분류  합성곱 신경망은 2차원 이미지를 그대로 사용하기 때문에 일렬로 펼치지 않아도 됨  완전 연결 신경망 (Fully Connected Layer)  2차원 배열을 1차원 배열로 바꿔야함">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_9_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_10_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_12_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_19_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_29_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_31_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_36_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_37_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_41_1.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_44_0.png">
<meta property="og:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_45_1.png">
<meta property="article:published_time" content="2022-04-07T00:00:00.000Z">
<meta property="article:modified_time" content="2022-04-08T05:00:41.400Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://woobinhwang.github.io/Images/0407_Convolution_Neural_Network_02/output_9_0.png">
  
    <link rel="alternate" href="/atom.xml" title="WB'blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">WB&#39;blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://woobinhwang.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-0407_Convolution_Neural_Network_02" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/04/07/0407_Convolution_Neural_Network_02/" class="article-date">
  <time class="dt-published" datetime="2022-04-07T00:00:00.000Z" itemprop="datePublished">2022-04-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      합성곱 신경망_02
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="합성곱-신경망을-사용한-이미지-분류"><a href="#합성곱-신경망을-사용한-이미지-분류" class="headerlink" title="합성곱 신경망을 사용한 이미지 분류"></a>합성곱 신경망을 사용한 이미지 분류</h1><h1 id="패션-MNIST-데이터-불러오기"><a href="#패션-MNIST-데이터-불러오기" class="headerlink" title="패션 MNIST 데이터 불러오기"></a>패션 MNIST 데이터 불러오기</h1><ul>
<li><p>데이터 스케일 0 ~ 255의 데이터를 0 ~ 1로 표준화</p>
</li>
<li><p>훈련 데이터 &#x2F; 검증 데이터 분류</p>
</li>
<li><p>합성곱 신경망은 2차원 이미지를 그대로 사용하기 때문에 일렬로 펼치지 않아도 됨</p>
</li>
<li><p>완전 연결 신경망 (Fully Connected Layer)</p>
<ul>
<li>2차원 배열을 1차원 배열로 바꿔야함</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">(train_input, train_target), (test_input, test_target) = \</span><br><span class="line">    keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">train_scaled = train_input.reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>) / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">train_scaled, val_scaled, train_target, val_target = train_test_split(</span><br><span class="line">    train_scaled, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, train_scaled.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
40960/29515 [=========================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
26435584/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
16384/5148 [===============================================================================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
4431872/4422102 [==============================] - 0s 0us/step
(60000, 28, 28) (48000, 28, 28, 1)


- (60000, 28, 28)크기였던 train_input이 (48000, 28, 28, 1)크기의 train_scaled가 됨.
</code></pre>
<h1 id="합성곱-신경망-만들기"><a href="#합성곱-신경망-만들기" class="headerlink" title="합성곱 신경망 만들기"></a>합성곱 신경망 만들기</h1><ul>
<li>합성곱 신경망의 전형적인 구조<ul>
<li>합성곱 층으로 이미지에서 특징을 감지 한 후 밀집층으로 클래스에 따른 분류 확률을 계산</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 실험 코드</span></span><br><span class="line">model = keras.Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 합성곱 층</span></span><br><span class="line">model.add(keras.layers.Conv2D(<span class="number">32</span>, kernel_size = <span class="number">3</span>, activation = <span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding = <span class="string">&#x27;same&#x27;</span>, input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 풀링층</span></span><br><span class="line"><span class="comment"># 평균 풀링을 사용, 풀링 크기는 (3, 3)로 지정</span></span><br><span class="line"><span class="comment"># # 최대 풀링의 함수: MaxPooling2D()</span></span><br><span class="line"><span class="comment"># # 평균 풀링의 함수: AveragePooling2D()</span></span><br><span class="line">model.add(keras.layers.AveragePooling2D(<span class="number">3</span>))  <span class="comment"># 1/3으로 줄이겠다는 의미</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 합성곱 층</span></span><br><span class="line">model.add(keras.layers.Conv2D(<span class="number">32</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, </span><br><span class="line">                              padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 풀링층</span></span><br><span class="line">model.add(keras.layers.AveragePooling2D(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 완전연결층 (밀집층 = Fully Connected Layer)</span></span><br><span class="line">model.add(keras.layers.Flatten())</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(keras.layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 28, 28, 32)        320       
                                                                 
 average_pooling2d (AverageP  (None, 9, 9, 32)         0         
 ooling2D)                                                       
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 32)          9248      
                                                                 
 average_pooling2d_1 (Averag  (None, 3, 3, 32)         0         
 ePooling2D)                                                     
                                                                 
 flatten (Flatten)           (None, 288)               0         
                                                                 
 dense (Dense)               (None, 100)               28900     
                                                                 
 dropout (Dropout)           (None, 100)               0         
                                                                 
 dense_1 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 39,478
Trainable params: 39,478
Non-trainable params: 0
_________________________________________________________________


                                        
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 합성곱 층</span></span><br><span class="line">model.add(keras.layers.Conv2D(<span class="number">32</span>, kernel_size = <span class="number">3</span>, activation = <span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding = <span class="string">&#x27;same&#x27;</span>, input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 풀링층</span></span><br><span class="line"><span class="comment"># 최대 풀링을 사용, 전형적인 풀링 크기인 (2,2)로 지정</span></span><br><span class="line"><span class="comment"># # 최대 풀링의 함수: MaxPooling2D()</span></span><br><span class="line"><span class="comment"># # 평균 풀링의 함수: AveragePooling2D()</span></span><br><span class="line">model.add(keras.layers.MaxPooling2D(<span class="number">2</span>))  <span class="comment"># 절반으로 줄이겠다는 의미</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 합성곱 층</span></span><br><span class="line">model.add(keras.layers.Conv2D(<span class="number">64</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, </span><br><span class="line">                              padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 풀링층</span></span><br><span class="line">model.add(keras.layers.MaxPooling2D(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 완전연결층 (밀집층 = Fully Connected Layer)</span></span><br><span class="line">model.add(keras.layers.Flatten())</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(keras.layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_2 (Conv2D)           (None, 28, 28, 32)        320       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         
 )                                                               
                                                                 
 conv2d_3 (Conv2D)           (None, 14, 14, 64)        18496     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         
 2D)                                                             
                                                                 
 flatten_1 (Flatten)         (None, 3136)              0         
                                                                 
 dense_2 (Dense)             (None, 100)               313700    
                                                                 
 dropout_1 (Dropout)         (None, 100)               0         
                                                                 
 dense_3 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 333,526
Trainable params: 333,526
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<ul>
<li>층의 구조를 그림으로 표현<ul>
<li>plot_model()함수</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.utils.plot_model(model)</span><br></pre></td></tr></table></figure>




<p><img src="/Images/0407_Convolution_Neural_Network_02/output_9_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 실험 코드</span></span><br><span class="line">keras.utils.plot_model(model, show_shapes=<span class="literal">True</span>,</span><br><span class="line">                       dpi= <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dpi로 크기를 조절 할 수 있음 [default: 96]</span></span><br></pre></td></tr></table></figure>




<p><img src="/Images/0407_Convolution_Neural_Network_02/output_10_0.png" alt="png"></p>
<ul>
<li>매개변수 show_shapes를 적용하여 입력과 출력의 크기를 표시</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.utils.plot_model(model, show_shapes=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<p><img src="/Images/0407_Convolution_Neural_Network_02/output_12_0.png" alt="png"></p>
<pre><code>- 지금까지 한 것은 모델 정의
</code></pre>
<ul>
<li>모델 컴파일 후, 훈련</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-cnn-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line">early_stopping_cb = keras.callbacks.EarlyStopping(patience=<span class="number">2</span>,</span><br><span class="line">                                                  restore_best_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># with tf.device(&#x27;/device:GPU:0&#x27;):</span></span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">10</span>,</span><br><span class="line">                    validation_data=(val_scaled, val_target),</span><br><span class="line">                    callbacks=[checkpoint_cb, early_stopping_cb])</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/10
1500/1500 [==============================] - 22s 7ms/step - loss: 0.5226 - accuracy: 0.8148 - val_loss: 0.3283 - val_accuracy: 0.8823
Epoch 2/10
1500/1500 [==============================] - 12s 8ms/step - loss: 0.3447 - accuracy: 0.8770 - val_loss: 0.2821 - val_accuracy: 0.8950
Epoch 3/10
1500/1500 [==============================] - 11s 7ms/step - loss: 0.2924 - accuracy: 0.8943 - val_loss: 0.2594 - val_accuracy: 0.8985
Epoch 4/10
1500/1500 [==============================] - 13s 8ms/step - loss: 0.2618 - accuracy: 0.9046 - val_loss: 0.2387 - val_accuracy: 0.9109
Epoch 5/10
1500/1500 [==============================] - 12s 8ms/step - loss: 0.2392 - accuracy: 0.9132 - val_loss: 0.2278 - val_accuracy: 0.9163
Epoch 6/10
1500/1500 [==============================] - 10s 7ms/step - loss: 0.2190 - accuracy: 0.9192 - val_loss: 0.2297 - val_accuracy: 0.9172
Epoch 7/10
1500/1500 [==============================] - 10s 7ms/step - loss: 0.2006 - accuracy: 0.9255 - val_loss: 0.2286 - val_accuracy: 0.9179
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"><span class="comment"># model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, </span></span><br><span class="line"><span class="comment">#               metrics=&#x27;accuracy&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-cnn-model.h5&#x27;, </span></span><br><span class="line"><span class="comment">#                                                 save_best_only=True)</span></span><br><span class="line"><span class="comment"># early_stopping_cb = keras.callbacks.EarlyStopping(patience=2,</span></span><br><span class="line"><span class="comment">#                                                   restore_best_weights=True)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># with tf.device(&#x27;/device:GPU:0&#x27;):</span></span><br><span class="line"><span class="comment">#   history = model.fit(train_scaled, train_target, epochs=10,</span></span><br><span class="line"><span class="comment">#                       validation_data=(val_scaled, val_target),</span></span><br><span class="line"><span class="comment">#                       callbacks=[checkpoint_cb, early_stopping_cb])</span></span><br></pre></td></tr></table></figure>

<ul>
<li>모델 학습 곡선 그리기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 연습 코드: plotly로 그려보기</span></span><br><span class="line"><span class="comment"># # 아래와 비슷한 결과를 얻었지만 블로그에 올리기 위해 주석 처리</span></span><br><span class="line"><span class="comment"># import plotly.express as px</span></span><br><span class="line"><span class="comment"># from plotly.subplots import make_subplots</span></span><br><span class="line"><span class="comment"># import plotly.graph_objects as go</span></span><br><span class="line"><span class="comment"># import matplotlib.pyplot as plt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig = make_subplots()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig.add_trace(go.Bar(y= history.history[&#x27;loss&#x27;]))</span></span><br><span class="line"><span class="comment"># fig.add_trace(go.Scatter(y= history.history[&#x27;val_loss&#x27;]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_19_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 그래픽 카드로 돌리는지 확인하는 방법</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">device_name = tf.test.gpu_device_name()</span><br><span class="line"><span class="keyword">if</span> device_name != <span class="string">&#x27;/device:GPU:0&#x27;</span>:</span><br><span class="line">  <span class="keyword">raise</span> SystemError(<span class="string">&#x27;GPU device not found&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Found GPU at: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(device_name))</span><br></pre></td></tr></table></figure>

<pre><code>Found GPU at: /device:GPU:0
</code></pre>
<h1 id="합성곱-신경망-시각화"><a href="#합성곱-신경망-시각화" class="headerlink" title="합성곱 신경망 시각화"></a>합성곱 신경망 시각화</h1><ul>
<li>model이 어떤 가중치를 학습했는지 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">model = keras.models.load_model(<span class="string">&#x27;best-cnn-model.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># keras.utils.plot_model(model2, show_shapes=True)</span></span><br><span class="line"></span><br><span class="line">model.layers  <span class="comment"># 리스트 형태로 저장되어 있음</span></span><br></pre></td></tr></table></figure>




<pre><code>[&lt;keras.layers.convolutional.Conv2D at 0x7fc7d81a7790&gt;,
 &lt;keras.layers.pooling.MaxPooling2D at 0x7fc8e00bfc10&gt;,
 &lt;keras.layers.convolutional.Conv2D at 0x7fc7f2f88490&gt;,
 &lt;keras.layers.pooling.MaxPooling2D at 0x7fc7d710d5d0&gt;,
 &lt;keras.layers.core.flatten.Flatten at 0x7fc8e023bb10&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7fc7f3fb5350&gt;,
 &lt;keras.layers.core.dropout.Dropout at 0x7fc86a7a7050&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7fc86a793750&gt;]



- 2번의 합성곱과 풀링을 하고 Flatten층, Dense층, Dropout층, Dense층이 보임
</code></pre>
<ul>
<li>합성곱층의 가중치를 확인 가능</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv = model.layers[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(conv.weights[<span class="number">0</span>].shape, conv.weights[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>(3, 3, 1, 32) (32,)


- 깊이가 1이므로 실제 커널 크기: (3, 3, 1)
- 필터 개수가 32개이므로 weights의 첫번째 원소인 가중치의 크기: (3, 3, 1, 32)
- weights의 두번째 원소는 절편의 개수를 나타냄
- 필터마다 1개의 절편이 있으므로 (32,)크기가 됨.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv_weights = conv.weights[<span class="number">0</span>].numpy()</span><br><span class="line"><span class="built_in">print</span>(conv_weights.mean(), conv_weights.std())  <span class="comment"># 평균(mean), 표준편차(std)</span></span><br></pre></td></tr></table></figure>

<pre><code>-0.025856383 0.21591602
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(conv_weights.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_29_0.png" alt="png"></p>
<pre><code>- 0을 중심으로 종 모양 분포를 띄고 있음
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">16</span>, figsize=(<span class="number">15</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">        axs[i, j].imshow(conv_weights[:,:,<span class="number">0</span>,i*<span class="number">16</span> + j], vmin=-<span class="number">0.5</span>, vmax=<span class="number">0.5</span>)</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_31_0.png" alt="png"></p>
<ul>
<li>훈련하지 않은 빈 합성곱 신경망을 작성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">no_training_model = keras.Sequential()</span><br><span class="line"></span><br><span class="line">no_training_model.add(keras.layers.Conv2D(<span class="number">32</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, </span><br><span class="line">                                          padding=<span class="string">&#x27;same&#x27;</span>, input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">no_training_conv = no_training_model.layers[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(no_training_conv.weights[<span class="number">0</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>(3, 3, 1, 32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">no_training_weights = no_training_conv.weights[<span class="number">0</span>].numpy()</span><br><span class="line"><span class="built_in">print</span>(no_training_weights.mean(), no_training_weights.std())</span><br></pre></td></tr></table></figure>

<pre><code>0.0065383185 0.081879705
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(no_training_weights.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_36_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">16</span>, figsize=(<span class="number">15</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">        axs[i, j].imshow(no_training_weights[:,:,<span class="number">0</span>,i*<span class="number">16</span> + j], vmin=-<span class="number">0.5</span>, vmax=<span class="number">0.5</span>)</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_37_0.png" alt="png"></p>
<pre><code>- 히스토그램에서 보앗듯이 전체적으로 가중치가 밋밋하게 초기화됨.
- 특징이 뚜렷하지 않음.
</code></pre>
<h1 id="함수형-API"><a href="#함수형-API" class="headerlink" title="함수형 API"></a>함수형 API</h1><ul>
<li>딥러닝에는 더 복잡한 모델이 많이 있음.<ul>
<li>입력이 2개일수도 있고 출력이 2개일수도 있는데 이런 경우엔 함수형API를 사용</li>
</ul>
</li>
</ul>
<h1 id="특성-맵-시각화"><a href="#특성-맵-시각화" class="headerlink" title="특성 맵 시각화"></a>특성 맵 시각화</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.<span class="built_in">input</span>)</span><br><span class="line">conv_acti = keras.Model(model.<span class="built_in">input</span>, model.layers[<span class="number">0</span>].output)</span><br><span class="line">(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()</span><br><span class="line">plt.imshow(train_input[<span class="number">0</span>], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=&#39;conv2d_2_input&#39;), name=&#39;conv2d_2_input&#39;, description=&quot;created by layer &#39;conv2d_2_input&#39;&quot;)
</code></pre>
<p><img src="/Images/0407_Convolution_Neural_Network_02/output_41_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inputs = train_input[<span class="number">0</span>:<span class="number">1</span>].reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)/<span class="number">255.0</span></span><br><span class="line">feature_maps = conv_acti.predict(inputs)</span><br><span class="line"><span class="built_in">print</span>(feature_maps.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(1, 28, 28, 32)
</code></pre>
<ul>
<li>32개의 필터로 인해 입력 이미지에서 강하게 활성화 된 부분을 보여줌.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">4</span>, <span class="number">8</span>, figsize=(<span class="number">15</span>,<span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">        axs[i, j].imshow(feature_maps[<span class="number">0</span>,:,:,i*<span class="number">8</span> + j])</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_44_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">conv2_acti = keras.Model(model.<span class="built_in">input</span>, model.layers[<span class="number">2</span>].output)</span><br><span class="line">feature_maps = conv2_acti.predict(train_input[<span class="number">0</span>:<span class="number">1</span>].reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)/<span class="number">255.0</span>)</span><br><span class="line"><span class="built_in">print</span>(feature_maps.shape)</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(<span class="number">8</span>, <span class="number">8</span>, figsize=(<span class="number">12</span>,<span class="number">12</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">        axs[i, j].imshow(feature_maps[<span class="number">0</span>,:,:,i*<span class="number">8</span> + j])</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>(1, 14, 14, 64)
</code></pre>
<p><img src="/Images/0407_Convolution_Neural_Network_02/output_45_1.png" alt="png"></p>
<ul>
<li><ul>
<li>합성곱 신경망의 앞부분에 있는 합성곱 층은 이미지의 시각적인 정보를 감지하고 뒤쪽에 있는 합성곱 층은 앞쪽에서 감지한 시각적인 정보를 바탕으로 추상적인 정보를 학습한다는 추론이 가능.</li>
</ul>
</li>
</ul>
<h1 id="마무리"><a href="#마무리" class="headerlink" title="마무리"></a>마무리</h1><ul>
<li><p>키워드</p>
<ul>
<li><strong>가중치 시각화</strong>: 합성곱 층의 가중치를 이미지로 출력하는것</li>
<li><strong>특성 맵 시각화</strong>: 합성곱 층의 활성화 출력을 이미지로 그리는 것</li>
<li><strong>함수형 API</strong>: 케라스에서 신경망 모델을 만드는 방법 중 하나. 전형적으로 입력은 Input()함수를 사용하고, 출력은 마지막 층의 출력으로 정의</li>
</ul>
</li>
<li><p><strong>TensolFlow</strong> 패키지</p>
<ul>
<li><strong>Conv2D</strong>: 입력의 너비와 높이 방향의 합성곱 연산을 구현한 클래스</li>
<li><strong>MaxPooling2D</strong>: 입력의 너비와 높이를 줄이는 풀링 연산을 구현한 클래스</li>
<li><strong>plot_model()</strong>: 케라스 모델 구조를 주피터 노트북에 그리거나 파일로 저장.</li>
<li><strong>Model</strong>: 케라스 모델을 만드는 클래스</li>
</ul>
</li>
<li><p><strong>matplotlib</strong> 패키지</p>
<ul>
<li><strong>bar()</strong>: 막대그래프를 출력</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/04/07/0407_Convolution_Neural_Network_02/" data-id="cl1oq6dcw0000jonh2p957nxm" data-title="합성곱 신경망_02" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/04/07/0407_Sequentoal_Data,Recurrent_Neural_Network/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          순차 데이터와 순환 신경망
        
      </div>
    </a>
  
  
    <a href="/2022/04/06/0406_Convolution_Neural_Network/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">합성곱 신경망_01</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/04/08/0408_LSTM,GRU_Cell/">LSTM과 GRU셀</a>
          </li>
        
          <li>
            <a href="/2022/04/08/0408_IMDB/">IMDB 리뷰</a>
          </li>
        
          <li>
            <a href="/2022/04/07/0407_Sequentoal_Data,Recurrent_Neural_Network/">순차 데이터와 순환 신경망</a>
          </li>
        
          <li>
            <a href="/2022/04/07/0407_Convolution_Neural_Network_02/">합성곱 신경망_02</a>
          </li>
        
          <li>
            <a href="/2022/04/06/0406_Convolution_Neural_Network/">합성곱 신경망_01</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>