<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>WB&#039;blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="WB&#039;blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="WB&#039;blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="WB&#039;blog"><meta property="og:url" content="https://woobinhwang.github.io/"><meta property="og:site_name" content="WB&#039;blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://woobinhwang.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://woobinhwang.github.io"},"headline":"WB'blog","image":["https://woobinhwang.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"WB'blog","logo":{"@type":"ImageObject","url":"https://woobinhwang.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="WB&#039;blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-13T00:00:00.000Z" title="2022. 4. 13. 오전 9:00:00">2022-04-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-13T10:54:02.680Z" title="2022. 4. 13. 오후 7:54:02">2022-04-13</time></span><span class="level-item"> woobin </span><span class="level-item">a few seconds read (About 111 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/13/0413_Kibana_Install/">Kibana 설치</a></h1><div class="content"><h1 id="kibana-설치"><a href="#kibana-설치" class="headerlink" title="kibana 설치"></a>kibana 설치</h1><ul>
<li>설명: Elasticsearch 데이터를 시각화하고 Elastic Stack을 탐색하게 해주는 무료 오픈소스 인터페이스</li>
<li>kibana 설치</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install kibana</span><br></pre></td></tr></table></figure>

<p><img src="/Images/0413_Kibana_Install/Untitled.png" alt="Untitled"></p>
<ul>
<li>kibana 서비스를 활성화</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl <span class="built_in">enable</span> kibana</span><br></pre></td></tr></table></figure>

<p><img src="/Images/0413_Kibana_Install/Untitled%201.png" alt="Untitled"></p>
<ul>
<li>서비스를 시작하고, 확인</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start kibana</span><br><span class="line">$ sudo systemctl status kibana</span><br></pre></td></tr></table></figure>

<p><img src="/Images/0413_Kibana_Install/Untitled%202.png" alt="Untitled"></p>
<ul>
<li>로컬에서 확인</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="http://localhost:5601/">http://localhost:5601/</a></strong></p>
<p><img src="/Images/0413_Kibana_Install/Untitled%203.png" alt="Untitled"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-12T00:00:00.000Z" title="2022. 4. 12. 오전 9:00:00">2022-04-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-13T10:51:03.717Z" title="2022. 4. 13. 오후 7:51:03">2022-04-13</time></span><span class="level-item"> woobin </span><span class="level-item">a minute read (About 194 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/12/0412_Multiples_of_3_and_5/">코딩도장 문제 01</a></h1><div class="content"><h1 id="3과-5의-배수의-문제"><a href="#3과-5의-배수의-문제" class="headerlink" title="3과 5의 배수의 문제"></a>3과 5의 배수의 문제</h1><ul>
<li><p>코딩도장에 있는 퀴즈 (추천 1위)</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://codingdojang.com/scode/350?answer_mode=hide">https://codingdojang.com/scode/350?answer_mode=hide</a></p>
</li>
<li><p>10미만의 자연수에서 3과 5의 배수를 구하면 3,5,6,9이다. 이들의 총합은 23이다.</p>
</li>
<li><p>1000미만의 자연수에서 3,5의 배수의 총합을 구하라.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 나머지를 구하는 방법: %</span></span><br><span class="line"><span class="comment"># ex)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;%로 나머지를 구하는 방법 : 17 % 4 =&quot;</span>,<span class="number">17</span> % <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 함수를 이용하는 방법: divmod()</span></span><br><span class="line"><span class="comment"># ex)</span></span><br><span class="line"><span class="built_in">divmod</span>(<span class="number">17</span>, <span class="number">4</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;divmod(17, 4):&quot;</span>, <span class="built_in">divmod</span>(<span class="number">17</span>, <span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;divmod(17, 4)[1]:&quot;</span>, <span class="built_in">divmod</span>(<span class="number">17</span>, <span class="number">4</span>)[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<pre><code>%로 나머지를 구하는 방법 : 17 % 4 = 1
divmod(17, 4): (4, 1)
divmod(17, 4)[1]: 1
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">quest1 = <span class="number">1000</span></span><br><span class="line">Q_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, quest1):</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">divmod</span>(i, <span class="number">3</span>)[<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">    Q_list.append(i)</span><br><span class="line">  <span class="keyword">elif</span> <span class="built_in">divmod</span>(i, <span class="number">5</span>)[<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">    Q_list.append(i)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(Q_list)</span><br></pre></td></tr></table></figure>

<pre><code>[3, 5, 6, 9, 10, 12, 15, 18, 20, 21, 24, 25, 27, 30, 33, 35, 36, 39, 40, 42, 45, 48, 50, 51, 54, 55, 57, 60, 63, 65, 66, 69, 70, 72, 75, 78, 80, 81, 84, 85, 87, 90, 93, 95, 96, 99, 100, 102, 105, 108, 110, 111, 114, 115, 117, 120, 123, 125, 126, 129, 130, 132, 135, 138, 140, 141, 144, 145, 147, 150, 153, 155, 156, 159, 160, 162, 165, 168, 170, 171, 174, 175, 177, 180, 183, 185, 186, 189, 190, 192, 195, 198, 200, 201, 204, 205, 207, 210, 213, 215, 216, 219, 220, 222, 225, 228, 230, 231, 234, 235, 237, 240, 243, 245, 246, 249, 250, 252, 255, 258, 260, 261, 264, 265, 267, 270, 273, 275, 276, 279, 280, 282, 285, 288, 290, 291, 294, 295, 297, 300, 303, 305, 306, 309, 310, 312, 315, 318, 320, 321, 324, 325, 327, 330, 333, 335, 336, 339, 340, 342, 345, 348, 350, 351, 354, 355, 357, 360, 363, 365, 366, 369, 370, 372, 375, 378, 380, 381, 384, 385, 387, 390, 393, 395, 396, 399, 400, 402, 405, 408, 410, 411, 414, 415, 417, 420, 423, 425, 426, 429, 430, 432, 435, 438, 440, 441, 444, 445, 447, 450, 453, 455, 456, 459, 460, 462, 465, 468, 470, 471, 474, 475, 477, 480, 483, 485, 486, 489, 490, 492, 495, 498, 500, 501, 504, 505, 507, 510, 513, 515, 516, 519, 520, 522, 525, 528, 530, 531, 534, 535, 537, 540, 543, 545, 546, 549, 550, 552, 555, 558, 560, 561, 564, 565, 567, 570, 573, 575, 576, 579, 580, 582, 585, 588, 590, 591, 594, 595, 597, 600, 603, 605, 606, 609, 610, 612, 615, 618, 620, 621, 624, 625, 627, 630, 633, 635, 636, 639, 640, 642, 645, 648, 650, 651, 654, 655, 657, 660, 663, 665, 666, 669, 670, 672, 675, 678, 680, 681, 684, 685, 687, 690, 693, 695, 696, 699, 700, 702, 705, 708, 710, 711, 714, 715, 717, 720, 723, 725, 726, 729, 730, 732, 735, 738, 740, 741, 744, 745, 747, 750, 753, 755, 756, 759, 760, 762, 765, 768, 770, 771, 774, 775, 777, 780, 783, 785, 786, 789, 790, 792, 795, 798, 800, 801, 804, 805, 807, 810, 813, 815, 816, 819, 820, 822, 825, 828, 830, 831, 834, 835, 837, 840, 843, 845, 846, 849, 850, 852, 855, 858, 860, 861, 864, 865, 867, 870, 873, 875, 876, 879, 880, 882, 885, 888, 890, 891, 894, 895, 897, 900, 903, 905, 906, 909, 910, 912, 915, 918, 920, 921, 924, 925, 927, 930, 933, 935, 936, 939, 940, 942, 945, 948, 950, 951, 954, 955, 957, 960, 963, 965, 966, 969, 970, 972, 975, 978, 980, 981, 984, 985, 987, 990, 993, 995, 996, 999]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">target = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(Q_list)):</span><br><span class="line">  target = target + Q_list[i]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(target)</span><br></pre></td></tr></table></figure>

<pre><code>233168
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모범답안:</span></span><br><span class="line"><span class="built_in">sum</span>([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>) <span class="keyword">if</span> x%<span class="number">3</span>==<span class="number">0</span> <span class="keyword">or</span> x%<span class="number">5</span>==<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 리스트 컴프리헨션 적용한 코드</span></span><br></pre></td></tr></table></figure>




<pre><code>233168
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-08T00:00:00.000Z" title="2022. 4. 8. 오전 9:00:00">2022-04-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-08T04:54:27.371Z" title="2022. 4. 8. 오후 1:54:27">2022-04-08</time></span><span class="level-item"> woobin </span><span class="level-item">5 minutes read (About 762 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/08/0408_LSTM,GRU_Cell/">LSTM과 GRU셀</a></h1><div class="content"><h1 id="LSTM과-GPU셀"><a href="#LSTM과-GPU셀" class="headerlink" title="LSTM과 GPU셀"></a>LSTM과 GPU셀</h1><h1 id="LSTM-신경망-훈련하기"><a href="#LSTM-신경망-훈련하기" class="headerlink" title="LSTM 신경망 훈련하기"></a>LSTM 신경망 훈련하기</h1><ul>
<li>RNN은 실무에서 안씀.</li>
<li>LSTM이 나온 배경<ul>
<li>RNN -&gt; 문장이 길면, 학습 능력이 떨어지게됨</li>
<li>Long Short-Term Memory</li>
</ul>
</li>
<li>단기 기억을 오래 기억하기 위해 고안됨.<ul>
<li>메모장에 적듯이 업무 처리함.</li>
</ul>
</li>
</ul>
<h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">(train_input, train_target), (test_input, test_target) = imdb.load_data(</span><br><span class="line">    num_words=<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">train_input, val_input, train_target, val_target = train_test_split(</span><br><span class="line">    train_input, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
17465344/17464789 [==============================] - 0s 0us/step
17473536/17464789 [==============================] - 0s 0us/step
</code></pre>
<h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"></span><br><span class="line">train_seq = pad_sequences(train_input, maxlen=<span class="number">100</span>)</span><br><span class="line">val_seq = pad_sequences(val_input, maxlen=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<h2 id="모형-만들기"><a href="#모형-만들기" class="headerlink" title="모형 만들기"></a>모형 만들기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(keras.layers.Embedding(<span class="number">500</span>, <span class="number">16</span>, input_length= <span class="number">100</span>))</span><br><span class="line">model.add(keras.layers.LSTM(<span class="number">8</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">1</span>, activation= <span class="string">&#x27;sigmoid&#x27;</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 100, 16)           8000      
                                                                 
 lstm (LSTM)                 (None, 8)                 800       
                                                                 
 dense (Dense)               (None, 1)                 9         
                                                                 
=================================================================
Total params: 8,809
Trainable params: 8,809
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rmsprop = keras.optimizers.RMSprop(learning_rate=<span class="number">1e-4</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=rmsprop, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-lstm-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line">early_stopping_cb = keras.callbacks.EarlyStopping(patience=<span class="number">3</span>,</span><br><span class="line">                                                  restore_best_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 원본 epochs = 100</span></span><br><span class="line">history = model.fit(train_seq, train_target, epochs=<span class="number">10</span>, batch_size=<span class="number">64</span>,</span><br><span class="line">                    validation_data=(val_seq, val_target),</span><br><span class="line">                    callbacks=[checkpoint_cb, early_stopping_cb])</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/10
313/313 [==============================] - 20s 57ms/step - loss: 0.6929 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5706
Epoch 2/10
313/313 [==============================] - 15s 46ms/step - loss: 0.6914 - accuracy: 0.6021 - val_loss: 0.6902 - val_accuracy: 0.6312
Epoch 3/10
313/313 [==============================] - 16s 51ms/step - loss: 0.6869 - accuracy: 0.6435 - val_loss: 0.6816 - val_accuracy: 0.5628
Epoch 4/10
313/313 [==============================] - 14s 45ms/step - loss: 0.6530 - accuracy: 0.6578 - val_loss: 0.6313 - val_accuracy: 0.7128
Epoch 5/10
313/313 [==============================] - 13s 42ms/step - loss: 0.6149 - accuracy: 0.7222 - val_loss: 0.6105 - val_accuracy: 0.7282
Epoch 6/10
313/313 [==============================] - 13s 42ms/step - loss: 0.5949 - accuracy: 0.7358 - val_loss: 0.5939 - val_accuracy: 0.7382
Epoch 7/10
313/313 [==============================] - 13s 42ms/step - loss: 0.5780 - accuracy: 0.7503 - val_loss: 0.5786 - val_accuracy: 0.7452
Epoch 8/10
313/313 [==============================] - 13s 43ms/step - loss: 0.5623 - accuracy: 0.7577 - val_loss: 0.5654 - val_accuracy: 0.7466
Epoch 9/10
313/313 [==============================] - 13s 42ms/step - loss: 0.5480 - accuracy: 0.7663 - val_loss: 0.5516 - val_accuracy: 0.7574
Epoch 10/10
313/313 [==============================] - 13s 42ms/step - loss: 0.5343 - accuracy: 0.7711 - val_loss: 0.5400 - val_accuracy: 0.7602
</code></pre>
<h2 id="손실-곡선-추가"><a href="#손실-곡선-추가" class="headerlink" title="손실 곡선 추가"></a>손실 곡선 추가</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0408_LSTM,GRU_Cell/output_11_0.png" alt="png"></p>
<h2 id="순환층에-드롭아웃-적용하기"><a href="#순환층에-드롭아웃-적용하기" class="headerlink" title="순환층에 드롭아웃 적용하기"></a>순환층에 드롭아웃 적용하기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">model2 = keras.Sequential()</span><br><span class="line"></span><br><span class="line">model2.add(keras.layers.Embedding(<span class="number">500</span>, <span class="number">16</span>, input_length=<span class="number">100</span>))</span><br><span class="line"><span class="comment"># 드롭아웃 추가</span></span><br><span class="line">model2.add(keras.layers.LSTM(<span class="number">8</span>, dropout=<span class="number">0.3</span>))</span><br><span class="line">model2.add(keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">rmsprop = keras.optimizers.RMSprop(learning_rate=<span class="number">1e-4</span>)</span><br><span class="line">model2.<span class="built_in">compile</span>(optimizer=rmsprop, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, </span><br><span class="line">               metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-dropout-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line">early_stopping_cb = keras.callbacks.EarlyStopping(patience=<span class="number">3</span>,</span><br><span class="line">                                                  restore_best_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># epcohs = 100</span></span><br><span class="line">history = model2.fit(train_seq, train_target, epochs=<span class="number">5</span>, batch_size=<span class="number">64</span>,</span><br><span class="line">                     validation_data=(val_seq, val_target),</span><br><span class="line">                     callbacks=[checkpoint_cb, early_stopping_cb])</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/5
313/313 [==============================] - 26s 74ms/step - loss: 0.6925 - accuracy: 0.5351 - val_loss: 0.6917 - val_accuracy: 0.5744
Epoch 2/5
313/313 [==============================] - 14s 44ms/step - loss: 0.6902 - accuracy: 0.5934 - val_loss: 0.6881 - val_accuracy: 0.6306
Epoch 3/5
313/313 [==============================] - 14s 45ms/step - loss: 0.6817 - accuracy: 0.6486 - val_loss: 0.6711 - val_accuracy: 0.6736
Epoch 4/5
313/313 [==============================] - 14s 44ms/step - loss: 0.6357 - accuracy: 0.6889 - val_loss: 0.6024 - val_accuracy: 0.6984
Epoch 5/5
313/313 [==============================] - 14s 45ms/step - loss: 0.5847 - accuracy: 0.7155 - val_loss: 0.5686 - val_accuracy: 0.7286
</code></pre>
<p><img src="/Images/0408_LSTM,GRU_Cell/output_13_1.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li><strong>LSTM</strong>: 타임스텝이 긴 데이터를 효과적으로 학습하기 위해 고안된 순환층.</li>
<li><strong>셀 상태</strong>: LSTM셀은 은닉 상태 외에 셀상태를 출력. 셀 상태는 다음 층으로 전달되지 않으며 현재 셀에서만 순환됨.</li>
<li><strong>GPU</strong>: LSTM셀의 간소화 버전으로 생각 할 수 있지만 LSTM셀에 못지않는 성능을 냅니다.</li>
</ul>
</li>
<li><strong>TensorFlow 패키지</strong><ul>
<li><strong>LSTM</strong>: LSTM셀을 사용한 순환층 클래스</li>
<li><strong>GRU</strong>: GRU셀을 사용한 순환층 클래스</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-08T00:00:00.000Z" title="2022. 4. 8. 오전 9:00:00">2022-04-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-08T08:34:23.721Z" title="2022. 4. 8. 오후 5:34:23">2022-04-08</time></span><span class="level-item"> woobin </span><span class="level-item">14 minutes read (About 2079 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/08/0408_IMDB/">IMDB리뷰</a></h1><div class="content"><h1 id="순환-신경망으로-IMDB리뷰-분류"><a href="#순환-신경망으로-IMDB리뷰-분류" class="headerlink" title="순환 신경망으로 IMDB리뷰 분류"></a>순환 신경망으로 IMDB리뷰 분류</h1><ul>
<li><p>주제: 긍정리뷰, 부정리뷰 분류하기</p>
<ul>
<li>텍스트 자체는 신경망에 전달하지 않음. (문자열 –&gt; 수식에 적용 X)</li>
<li>문자열을 수식으로 정하는 규칙이 매우 가변적임.</li>
<li>if ex)<ul>
<li><p>He follows the cat. He loves the cat.</p>
</li>
<li><p>10- 11——- 12- 13– 10- 14—- 12- 13</p>
</li>
<li><p>고양이를 따라간다. He follows the cat.</p>
</li>
<li><p>10———– 11———- 12– 13——- 14- 15</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>RNN, LSTM 알고리즘</p>
<ul>
<li>영어권 사람들이 만듬</li>
<li>자연어 처리와 관련된 많은 알고리즘 또한 영어권 사람들이 만듬</li>
</ul>
</li>
<li><p>한글 !&#x3D; 영어 ( 언어가 다름을 인지 )</p>
<ul>
<li>성과 내려면 제품을 써야함 (&#x3D;돈) (네이버 &#x2F; 카카오쪽 제품)</li>
</ul>
</li>
</ul>
<h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line">(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words= <span class="number">500</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
17465344/17464789 [==============================] - 0s 0us/step
17473536/17464789 [==============================] - 0s 0us/step
</code></pre>
<ul>
<li>데이터 크기 확인 (1차원 배열)</li>
<li>텍스트의 길이가 다 다르기 때문에 1차원 배열로 정리되어 있음</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(25000,) (25000,)
</code></pre>
<ul>
<li>문장의 길이 확인<ul>
<li>문장의 길이가 다 다름</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_input[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_input[<span class="number">1</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_input[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>218
189
141
</code></pre>
<ul>
<li>Raw 데이터 전처리 -&gt; 토큰화 작업이 끝난 상황 (문자열이 숫자로 바뀜)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]
</code></pre>
<ul>
<li>Target 데이터 출력<ul>
<li>0은 부정 리뷰</li>
<li>1은 긍정 리뷰</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0번째에서 19번째까지의 데이터</span></span><br><span class="line"><span class="built_in">print</span>(train_target[:<span class="number">20</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]
</code></pre>
<h1 id="데이터셋-분리"><a href="#데이터셋-분리" class="headerlink" title="데이터셋 분리"></a>데이터셋 분리</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, val_input, train_target, val_target = train_test_split(</span><br><span class="line">    train_input, train_target, test_size= <span class="number">0.2</span>, random_state= <span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_input.shape, train_target.shape, val_input.shape, val_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((20000,), (20000,), (5000,), (5000,))
</code></pre>
<h1 id="데이터-시각화"><a href="#데이터-시각화" class="headerlink" title="데이터 시각화"></a>데이터 시각화</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#  컴프리헨션으로 길이를 표현하는 배열 만들기</span></span><br><span class="line">lengths= np.array([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> train_input])</span><br><span class="line"><span class="built_in">print</span>(np.mean(lengths), np.median(lengths), np.<span class="built_in">max</span>(lengths))</span><br></pre></td></tr></table></figure>

<pre><code>238.71364 178.0 2494
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.hist(lengths)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0408_IMDB/output_17_0.png" alt="png"></p>
<pre><code>- 250이하의 길이가 대부분임을 알 수 있음.
</code></pre>
<ul>
<li>짧은 단어 100개만 사용 할 예정</li>
<li>모든 길이를 100에 맞추는 ‘패딩’작업 실행</li>
<li>데이터의 갯수는 20000, 전체 길이는 100으로 맞춤</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line">train_seq= pad_sequences(train_input, maxlen= <span class="number">100</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_seq.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(25000, 100)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(train_input[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>




<pre><code>218
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_seq[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[  2  33   6  22  12 215  28  77  52   5  14 407  16  82   2   8   4 107
 117   2  15 256   4   2   7   2   5   2  36  71  43   2 476  26 400 317
  46   7   4   2   2  13 104  88   4 381  15 297  98  32   2  56  26 141
   6 194   2  18   4 226  22  21 134 476  26 480   5 144  30   2  18  51
  36  28 224  92  25 104   4 226  65  16  38   2  88  12  16 283   5  16
   2 113 103  32  15  16   2  19 178  32]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input[<span class="number">0</span>][-<span class="number">10</span>:])  <span class="comment"># 음수의 인덱스로 슬라이싱 하면 끝에서부터 세기 시작함.</span></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(train_input[<span class="number">0</span>][<span class="number">208</span>:])</span><br></pre></td></tr></table></figure>

<pre><code>[2, 113, 103, 32, 15, 16, 2, 19, 178, 32]

[2, 113, 103, 32, 15, 16, 2, 19, 178, 32]


- train_seq[0]의 길이는 218로 100보다 길기때문에 패딩이 안되었음을 확인 할 수 있음
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val_seq = pad_sequences(val_input, maxlen= <span class="number">100</span>)</span><br><span class="line">val_seq</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 32,   2, 225, ...,  14,  58,   2],
       [ 53,   2,   8, ...,   7,  32,   2],
       [  0,   0,   0, ...,   2,  33,  32],
       ...,
       [383,   2, 120, ...,  16,  99,  76],
       [106, 345,  12, ..., 120,   2, 156],
       [  4, 114,  21, ...,   4,   2,   2]], dtype=int32)
</code></pre>
<h1 id="순환신경망-만들기"><a href="#순환신경망-만들기" class="headerlink" title="순환신경망 만들기"></a>순환신경망 만들기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">model = keras.Sequential()</span><br><span class="line"><span class="comment"># 최대 길이는 100까지 패딩, imdb.load_data() 함수에서 500개의 단어만 사용하도록 지정했었음</span></span><br><span class="line">model.add(keras.layers.SimpleRNN(<span class="number">8</span>, input_shape= (<span class="number">100</span>, <span class="number">500</span>)))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">1</span>, activation= <span class="string">&#x27;sigmoid&#x27;</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li>원핫인코딩 적용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to_categorical(): 원핫인코딩된 배열로 반환해줌.</span></span><br><span class="line">train_oh = keras.utils.to_categorical(train_seq)</span><br><span class="line"><span class="built_in">print</span>(train_oh.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(20000, 100, 500)


- 정수 하나마다 500차원의 (20000, 100)의 크기로 들어가있음을 확인 할 수 있음
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_oh[<span class="number">0</span>][<span class="number">0</span>][:<span class="number">12</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 나머지 원소에 전부 0으로 들어가있는지 확인</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(train_oh[<span class="number">0</span>][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>1.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val_oh = keras.utils.to_categorical(val_seq)</span><br><span class="line"><span class="built_in">print</span>(val_oh.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(5000, 100, 500)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_3&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_3 (SimpleRNN)    (None, 8)                 4072      
                                                                 
 dense_3 (Dense)             (None, 1)                 9         
                                                                 
=================================================================
Total params: 4,081
Trainable params: 4,081
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">rmsprop = keras.optimizers.RMSprop(learning_rate=<span class="number">1e-4</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=rmsprop, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-simplernn-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line">early_stopping_cb = keras.callbacks.EarlyStopping(patience=<span class="number">3</span>,</span><br><span class="line">                                                  restore_best_weights=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 원본 epochs = 100</span></span><br><span class="line">history = model.fit(train_oh, train_target, epochs=<span class="number">100</span>, batch_size=<span class="number">64</span>,</span><br><span class="line">                    validation_data=(val_oh, val_target),</span><br><span class="line">                    callbacks=[checkpoint_cb, early_stopping_cb])</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/100
313/313 [==============================] - 15s 44ms/step - loss: 0.5339 - accuracy: 0.7710 - val_loss: 0.5444 - val_accuracy: 0.7566
Epoch 2/100
313/313 [==============================] - 11s 36ms/step - loss: 0.5241 - accuracy: 0.7762 - val_loss: 0.5373 - val_accuracy: 0.7528
Epoch 3/100
313/313 [==============================] - 12s 37ms/step - loss: 0.5160 - accuracy: 0.7796 - val_loss: 0.5296 - val_accuracy: 0.7576
Epoch 4/100
313/313 [==============================] - 11s 36ms/step - loss: 0.5079 - accuracy: 0.7828 - val_loss: 0.5231 - val_accuracy: 0.7592
Epoch 5/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4998 - accuracy: 0.7872 - val_loss: 0.5165 - val_accuracy: 0.7660
Epoch 6/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4931 - accuracy: 0.7887 - val_loss: 0.5115 - val_accuracy: 0.7666
Epoch 7/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4858 - accuracy: 0.7914 - val_loss: 0.5061 - val_accuracy: 0.7710
Epoch 8/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4801 - accuracy: 0.7949 - val_loss: 0.5015 - val_accuracy: 0.7690
Epoch 9/100
313/313 [==============================] - 11s 37ms/step - loss: 0.4742 - accuracy: 0.7972 - val_loss: 0.4985 - val_accuracy: 0.7684
Epoch 10/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4688 - accuracy: 0.7982 - val_loss: 0.4931 - val_accuracy: 0.7744
Epoch 11/100
313/313 [==============================] - 16s 50ms/step - loss: 0.4636 - accuracy: 0.8023 - val_loss: 0.4941 - val_accuracy: 0.7674
Epoch 12/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4595 - accuracy: 0.8023 - val_loss: 0.4893 - val_accuracy: 0.7732
Epoch 13/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4546 - accuracy: 0.8051 - val_loss: 0.4850 - val_accuracy: 0.7782
Epoch 14/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4512 - accuracy: 0.8065 - val_loss: 0.4837 - val_accuracy: 0.7760
Epoch 15/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4471 - accuracy: 0.8097 - val_loss: 0.4826 - val_accuracy: 0.7766
Epoch 16/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4438 - accuracy: 0.8109 - val_loss: 0.4789 - val_accuracy: 0.7796
Epoch 17/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4396 - accuracy: 0.8121 - val_loss: 0.4795 - val_accuracy: 0.7764
Epoch 18/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4367 - accuracy: 0.8133 - val_loss: 0.4792 - val_accuracy: 0.7760
Epoch 19/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4344 - accuracy: 0.8127 - val_loss: 0.4761 - val_accuracy: 0.7784
Epoch 20/100
313/313 [==============================] - 15s 47ms/step - loss: 0.4313 - accuracy: 0.8157 - val_loss: 0.4733 - val_accuracy: 0.7822
Epoch 21/100
313/313 [==============================] - 11s 37ms/step - loss: 0.4289 - accuracy: 0.8162 - val_loss: 0.4753 - val_accuracy: 0.7794
Epoch 22/100
313/313 [==============================] - 11s 35ms/step - loss: 0.4261 - accuracy: 0.8173 - val_loss: 0.4757 - val_accuracy: 0.7806
Epoch 23/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4241 - accuracy: 0.8167 - val_loss: 0.4717 - val_accuracy: 0.7826
Epoch 24/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4220 - accuracy: 0.8188 - val_loss: 0.4735 - val_accuracy: 0.7816
Epoch 25/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4197 - accuracy: 0.8202 - val_loss: 0.4696 - val_accuracy: 0.7820
Epoch 26/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4179 - accuracy: 0.8201 - val_loss: 0.4728 - val_accuracy: 0.7834
Epoch 27/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4160 - accuracy: 0.8210 - val_loss: 0.4736 - val_accuracy: 0.7830
Epoch 28/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4142 - accuracy: 0.8209 - val_loss: 0.4711 - val_accuracy: 0.7836
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0408_IMDB/output_37_0.png" alt="png"></p>
<h1 id="단어-임베딩을-사용"><a href="#단어-임베딩을-사용" class="headerlink" title="단어 임베딩을 사용"></a>단어 임베딩을 사용</h1><ul>
<li>문제점 발생: 토큰 1개를 500차원으로 늘림<ul>
<li>-&gt; 데이터 크기가 500배 커짐</li>
</ul>
</li>
<li>단어임베딩: 라벨인코딩과 비슷</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">model2 = keras.Sequential()</span><br><span class="line">model2.add(keras.layers.Embedding(<span class="number">500</span>, <span class="number">16</span>, input_length= <span class="number">100</span>))</span><br><span class="line">model2.add(keras.layers.SimpleRNN(<span class="number">8</span>))</span><br><span class="line">model2.add(keras.layers.Dense(<span class="number">1</span>, activation= <span class="string">&#x27;sigmoid&#x27;</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model2.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding_2 (Embedding)     (None, 100, 16)           8000      
                                                                 
 simple_rnn_4 (SimpleRNN)    (None, 8)                 200       
                                                                 
 dense_4 (Dense)             (None, 1)                 9         
                                                                 
=================================================================
Total params: 8,209
Trainable params: 8,209
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">rmsprop = keras.optimizers.RMSprop(learning_rate=<span class="number">1e-4</span>)</span><br><span class="line">model2.<span class="built_in">compile</span>(optimizer=rmsprop, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment"># 임베딩으로 Change</span></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-embedding-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line">early_stopping_cb = keras.callbacks.EarlyStopping(patience=<span class="number">3</span>,</span><br><span class="line">                                                  restore_best_weights=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 원본 epochs= 100</span></span><br><span class="line">history = model2.fit(train_seq, train_target, epochs=<span class="number">100</span>, batch_size=<span class="number">64</span>,</span><br><span class="line">                    validation_data=(val_seq, val_target),</span><br><span class="line">                    callbacks=[checkpoint_cb, early_stopping_cb])</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/100
313/313 [==============================] - 8s 22ms/step - loss: 0.6812 - accuracy: 0.5584 - val_loss: 0.6570 - val_accuracy: 0.6208
Epoch 2/100
313/313 [==============================] - 6s 19ms/step - loss: 0.6334 - accuracy: 0.6675 - val_loss: 0.6146 - val_accuracy: 0.6916
Epoch 3/100
313/313 [==============================] - 6s 19ms/step - loss: 0.5940 - accuracy: 0.7219 - val_loss: 0.5831 - val_accuracy: 0.7314
Epoch 4/100
313/313 [==============================] - 6s 19ms/step - loss: 0.5655 - accuracy: 0.7492 - val_loss: 0.5596 - val_accuracy: 0.7450
Epoch 5/100
313/313 [==============================] - 7s 21ms/step - loss: 0.5455 - accuracy: 0.7593 - val_loss: 0.5461 - val_accuracy: 0.7518
Epoch 6/100
313/313 [==============================] - 6s 20ms/step - loss: 0.5302 - accuracy: 0.7678 - val_loss: 0.5405 - val_accuracy: 0.7446
Epoch 7/100
313/313 [==============================] - 6s 19ms/step - loss: 0.5170 - accuracy: 0.7740 - val_loss: 0.5327 - val_accuracy: 0.7492
Epoch 8/100
313/313 [==============================] - 7s 21ms/step - loss: 0.5076 - accuracy: 0.7765 - val_loss: 0.5195 - val_accuracy: 0.7598
Epoch 9/100
313/313 [==============================] - 6s 19ms/step - loss: 0.4996 - accuracy: 0.7814 - val_loss: 0.5141 - val_accuracy: 0.7592
Epoch 10/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4908 - accuracy: 0.7845 - val_loss: 0.5085 - val_accuracy: 0.7642
Epoch 11/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4844 - accuracy: 0.7876 - val_loss: 0.5082 - val_accuracy: 0.7598
Epoch 12/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4782 - accuracy: 0.7904 - val_loss: 0.4958 - val_accuracy: 0.7722
Epoch 13/100
313/313 [==============================] - 6s 21ms/step - loss: 0.4711 - accuracy: 0.7937 - val_loss: 0.4989 - val_accuracy: 0.7644
Epoch 14/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4640 - accuracy: 0.7980 - val_loss: 0.4876 - val_accuracy: 0.7740
Epoch 15/100
313/313 [==============================] - 6s 19ms/step - loss: 0.4607 - accuracy: 0.7991 - val_loss: 0.4833 - val_accuracy: 0.7770
Epoch 16/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4541 - accuracy: 0.8021 - val_loss: 0.4896 - val_accuracy: 0.7682
Epoch 17/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4496 - accuracy: 0.8054 - val_loss: 0.4753 - val_accuracy: 0.7810
Epoch 18/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4458 - accuracy: 0.8079 - val_loss: 0.4748 - val_accuracy: 0.7790
Epoch 19/100
313/313 [==============================] - 6s 19ms/step - loss: 0.4421 - accuracy: 0.8102 - val_loss: 0.4753 - val_accuracy: 0.7786
Epoch 20/100
313/313 [==============================] - 6s 19ms/step - loss: 0.4390 - accuracy: 0.8127 - val_loss: 0.4717 - val_accuracy: 0.7772
Epoch 21/100
313/313 [==============================] - 6s 19ms/step - loss: 0.4351 - accuracy: 0.8131 - val_loss: 0.4823 - val_accuracy: 0.7732
Epoch 22/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4331 - accuracy: 0.8137 - val_loss: 0.4659 - val_accuracy: 0.7842
Epoch 23/100
313/313 [==============================] - 7s 22ms/step - loss: 0.4301 - accuracy: 0.8145 - val_loss: 0.4655 - val_accuracy: 0.7812
Epoch 24/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4260 - accuracy: 0.8174 - val_loss: 0.4771 - val_accuracy: 0.7754
Epoch 25/100
313/313 [==============================] - 6s 21ms/step - loss: 0.4243 - accuracy: 0.8185 - val_loss: 0.4637 - val_accuracy: 0.7846
Epoch 26/100
313/313 [==============================] - 6s 19ms/step - loss: 0.4208 - accuracy: 0.8205 - val_loss: 0.4658 - val_accuracy: 0.7834
Epoch 27/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4185 - accuracy: 0.8222 - val_loss: 0.4652 - val_accuracy: 0.7820
Epoch 28/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4161 - accuracy: 0.8236 - val_loss: 0.4609 - val_accuracy: 0.7866
Epoch 29/100
313/313 [==============================] - 7s 21ms/step - loss: 0.4136 - accuracy: 0.8249 - val_loss: 0.4642 - val_accuracy: 0.7860
Epoch 30/100
313/313 [==============================] - 6s 19ms/step - loss: 0.4113 - accuracy: 0.8254 - val_loss: 0.4601 - val_accuracy: 0.7876
Epoch 31/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4090 - accuracy: 0.8281 - val_loss: 0.4643 - val_accuracy: 0.7824
Epoch 32/100
313/313 [==============================] - 6s 20ms/step - loss: 0.4076 - accuracy: 0.8286 - val_loss: 0.4622 - val_accuracy: 0.7874
Epoch 33/100
313/313 [==============================] - 6s 19ms/step - loss: 0.4053 - accuracy: 0.8289 - val_loss: 0.4590 - val_accuracy: 0.7882
Epoch 34/100
313/313 [==============================] - 6s 21ms/step - loss: 0.4030 - accuracy: 0.8299 - val_loss: 0.4572 - val_accuracy: 0.7902
Epoch 35/100
313/313 [==============================] - 7s 21ms/step - loss: 0.4010 - accuracy: 0.8321 - val_loss: 0.4632 - val_accuracy: 0.7878
Epoch 36/100
313/313 [==============================] - 6s 19ms/step - loss: 0.3995 - accuracy: 0.8331 - val_loss: 0.4571 - val_accuracy: 0.7914
Epoch 37/100
313/313 [==============================] - 6s 19ms/step - loss: 0.3973 - accuracy: 0.8347 - val_loss: 0.4621 - val_accuracy: 0.7892
Epoch 38/100
313/313 [==============================] - 7s 21ms/step - loss: 0.3958 - accuracy: 0.8353 - val_loss: 0.4568 - val_accuracy: 0.7916
Epoch 39/100
313/313 [==============================] - 6s 20ms/step - loss: 0.3941 - accuracy: 0.8354 - val_loss: 0.4626 - val_accuracy: 0.7868
Epoch 40/100
313/313 [==============================] - 7s 22ms/step - loss: 0.3927 - accuracy: 0.8358 - val_loss: 0.4611 - val_accuracy: 0.7886
Epoch 41/100
313/313 [==============================] - 6s 20ms/step - loss: 0.3907 - accuracy: 0.8371 - val_loss: 0.4583 - val_accuracy: 0.7912
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0408_IMDB/output_42_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li><p>키워드</p>
<ul>
<li><strong>말뭉치</strong>: 자연어 처리에서 사용하는 텍스트 데이터의 모음. (&#x3D; 훈련 데이터셋)</li>
<li><strong>토큰</strong>: 텍스트에서 공백으로 구분되는 문자열 종종 소문자로 변환하고 구둣점은 삭제</li>
<li><strong>원-핫 인코딩</strong>: 어떤 클래스에 해당하는 원소만 1이고 나머지는 모두 0인 벡터</li>
<li><strong>단어 임베딩</strong>: 정수로 변환된 토큰을 비교적 작은 크기의 실수 밀집 벡터로 변환. 이런 밀집 벡터는 단어 사이의 관계를 표현 할 수 있기 때문에 자연어 처리에서 좋은 성능을 발휘</li>
</ul>
</li>
<li><p><strong>TensorFlow 패키지</strong></p>
<ul>
<li><strong>pad_sequences()</strong>: 시퀀스 길이를 맞추기 위해 패딩을 추가. (샘플 개수, 타임스텝 개수)크기의 2차원 배열로 나옴.<ul>
<li>매개변수 maxlen: 원하는 시퀀스 길이를 지정. 지정한 값보다 긴 시퀀스는 잘리고, 짧은 시퀀스는 패딩됨.</li>
</ul>
</li>
<li><strong>to_categorical()</strong>: 정수 시퀀스를 원 핫 인코딩으로 변환. 토큰이나 타깃값을 원핫 인코딩 할 때 사용</li>
<li><strong>SumpleRNN</strong>: 케라스의 기본 순환층 클래스</li>
<li><strong>Embedding</strong>: 단어 임베딩을 위한 클래스</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-07T00:00:00.000Z" title="2022. 4. 7. 오전 9:00:00">2022-04-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-07T07:59:31.522Z" title="2022. 4. 7. 오후 4:59:31">2022-04-07</time></span><span class="level-item"> woobin </span><span class="level-item">3 minutes read (About 463 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/07/0407_Sequentoal_Data,Recurrent_Neural_Network/">순차 데이터와 순환 신경망</a></h1><div class="content"><h1 id="순차-데이터와-순환-신경망"><a href="#순차-데이터와-순환-신경망" class="headerlink" title="순차 데이터와 순환 신경망"></a>순차 데이터와 순환 신경망</h1><ul>
<li>초급 레벨: 기초통계 (t.test, 분산분석, 회귀분석…)</li>
<li>중급 레벨: 시계열 분석 &#x2F; 베이지안 &#x2F; 비모수검정…</li>
</ul>
<h1 id="순차-데이터"><a href="#순차-데이터" class="headerlink" title="순차 데이터"></a>순차 데이터</h1><ul>
<li>텍스트나 시계열 데이터와 같이 순서에 의미가 있는 데이터를 뜻함<ul>
<li>시계열 데이터: 주식 &#x2F; 날씨 &#x2F; 매장 매출 등등<ul>
<li>시계열 데이터를 공부하고 싶다면 R 로 공부할 것 권장</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="텍스트"><a href="#텍스트" class="headerlink" title="텍스트"></a>텍스트</h1><ul>
<li><p>텍스트 마이닝 ( 데이터 분석가 )</p>
<ul>
<li>대표적으로 감정분석 ( 긍정, 부정 )</li>
<li>문자열: 인코딩하는 방법론이 존재</li>
</ul>
</li>
<li><p>자연어 처리 ( 개발자 )</p>
<ul>
<li>챗봇 ( 툴은 다 존재함 )</li>
<li>자동 번역</li>
</ul>
</li>
<li><p>기본 딥러닝 알고리즘 &#x2F; RNN &amp; LSTM</p>
<ul>
<li>현실에서 사용하지는 않음.</li>
</ul>
</li>
<li><p>자료</p>
<ul>
<li>딥러닝을 이용한 자연어 처리 입문 (텐서플로) : <a target="_blank" rel="noopener" href="https://wikidocs.net/book/2155">https://wikidocs.net/book/2155</a></li>
<li>Pytorch로 시작하는 딥러닝 입문 : <a target="_blank" rel="noopener" href="https://wikidocs.net/32471">https://wikidocs.net/32471</a></li>
</ul>
</li>
<li><p>딥러닝은 <strong>분야 선정</strong>이 중요</p>
<ul>
<li>영상인식, 이미지 분류, 음성, 자연어</li>
</ul>
</li>
</ul>
<h1 id="순환-신경망"><a href="#순환-신경망" class="headerlink" title="순환 신경망"></a>순환 신경망</h1><ul>
<li><p>일반적으로 완전 연결 신경망과 거의 비슷하지만, 완전 연결 신경망에 이전 데이터의 처리 흐름을 순환하는 고리 하나를 추가하는 형태</p>
</li>
<li><p>이미지는 픽셀값이 어느정도 고정이 되어있음</p>
<ul>
<li>if) 28 * 28 로 정의 –&gt; 모든 데이터를 28 * 28 로 맞출 수 있음</li>
</ul>
</li>
<li><p>텍스트</p>
<ul>
<li>값이 고정이 불가함</li>
<li>같은 의미</li>
</ul>
</li>
<li><p>p.494</p>
<ul>
<li>ex) i am boy (1, 4, 3)</li>
</ul>
</li>
</ul>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li><strong>순차 데이터</strong>: 텍스트나 시계열 데이터와 같이 순서에 의미가 있는 데이터</li>
<li><strong>순환 신경망</strong>: 순차 데이터에 잘 맞는 인공 신경망의 한 종류</li>
<li><strong>셀</strong>: 순환 신경망에서의 순환층</li>
<li><strong>은닉 상태</strong>: 순환 신경망에서의 셀의 출력</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-07T00:00:00.000Z" title="2022. 4. 7. 오전 9:00:00">2022-04-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-08T05:00:41.400Z" title="2022. 4. 8. 오후 2:00:41">2022-04-08</time></span><span class="level-item"> woobin </span><span class="level-item">15 minutes read (About 2185 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/07/0407_Convolution_Neural_Network_02/">합성곱 신경망_02</a></h1><div class="content"><h1 id="합성곱-신경망을-사용한-이미지-분류"><a href="#합성곱-신경망을-사용한-이미지-분류" class="headerlink" title="합성곱 신경망을 사용한 이미지 분류"></a>합성곱 신경망을 사용한 이미지 분류</h1><h1 id="패션-MNIST-데이터-불러오기"><a href="#패션-MNIST-데이터-불러오기" class="headerlink" title="패션 MNIST 데이터 불러오기"></a>패션 MNIST 데이터 불러오기</h1><ul>
<li><p>데이터 스케일 0 ~ 255의 데이터를 0 ~ 1로 표준화</p>
</li>
<li><p>훈련 데이터 &#x2F; 검증 데이터 분류</p>
</li>
<li><p>합성곱 신경망은 2차원 이미지를 그대로 사용하기 때문에 일렬로 펼치지 않아도 됨</p>
</li>
<li><p>완전 연결 신경망 (Fully Connected Layer)</p>
<ul>
<li>2차원 배열을 1차원 배열로 바꿔야함</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">(train_input, train_target), (test_input, test_target) = \</span><br><span class="line">    keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">train_scaled = train_input.reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>) / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">train_scaled, val_scaled, train_target, val_target = train_test_split(</span><br><span class="line">    train_scaled, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, train_scaled.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
40960/29515 [=========================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 0s 0us/step
26435584/26421880 [==============================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz
16384/5148 [===============================================================================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 0s 0us/step
4431872/4422102 [==============================] - 0s 0us/step
(60000, 28, 28) (48000, 28, 28, 1)


- (60000, 28, 28)크기였던 train_input이 (48000, 28, 28, 1)크기의 train_scaled가 됨.
</code></pre>
<h1 id="합성곱-신경망-만들기"><a href="#합성곱-신경망-만들기" class="headerlink" title="합성곱 신경망 만들기"></a>합성곱 신경망 만들기</h1><ul>
<li>합성곱 신경망의 전형적인 구조<ul>
<li>합성곱 층으로 이미지에서 특징을 감지 한 후 밀집층으로 클래스에 따른 분류 확률을 계산</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 실험 코드</span></span><br><span class="line">model = keras.Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 합성곱 층</span></span><br><span class="line">model.add(keras.layers.Conv2D(<span class="number">32</span>, kernel_size = <span class="number">3</span>, activation = <span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding = <span class="string">&#x27;same&#x27;</span>, input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 풀링층</span></span><br><span class="line"><span class="comment"># 평균 풀링을 사용, 풀링 크기는 (3, 3)로 지정</span></span><br><span class="line"><span class="comment"># # 최대 풀링의 함수: MaxPooling2D()</span></span><br><span class="line"><span class="comment"># # 평균 풀링의 함수: AveragePooling2D()</span></span><br><span class="line">model.add(keras.layers.AveragePooling2D(<span class="number">3</span>))  <span class="comment"># 1/3으로 줄이겠다는 의미</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 합성곱 층</span></span><br><span class="line">model.add(keras.layers.Conv2D(<span class="number">32</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, </span><br><span class="line">                              padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 풀링층</span></span><br><span class="line">model.add(keras.layers.AveragePooling2D(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 완전연결층 (밀집층 = Fully Connected Layer)</span></span><br><span class="line">model.add(keras.layers.Flatten())</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(keras.layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 28, 28, 32)        320       
                                                                 
 average_pooling2d (AverageP  (None, 9, 9, 32)         0         
 ooling2D)                                                       
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 32)          9248      
                                                                 
 average_pooling2d_1 (Averag  (None, 3, 3, 32)         0         
 ePooling2D)                                                     
                                                                 
 flatten (Flatten)           (None, 288)               0         
                                                                 
 dense (Dense)               (None, 100)               28900     
                                                                 
 dropout (Dropout)           (None, 100)               0         
                                                                 
 dense_1 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 39,478
Trainable params: 39,478
Non-trainable params: 0
_________________________________________________________________


                                        
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 합성곱 층</span></span><br><span class="line">model.add(keras.layers.Conv2D(<span class="number">32</span>, kernel_size = <span class="number">3</span>, activation = <span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding = <span class="string">&#x27;same&#x27;</span>, input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 풀링층</span></span><br><span class="line"><span class="comment"># 최대 풀링을 사용, 전형적인 풀링 크기인 (2,2)로 지정</span></span><br><span class="line"><span class="comment"># # 최대 풀링의 함수: MaxPooling2D()</span></span><br><span class="line"><span class="comment"># # 평균 풀링의 함수: AveragePooling2D()</span></span><br><span class="line">model.add(keras.layers.MaxPooling2D(<span class="number">2</span>))  <span class="comment"># 절반으로 줄이겠다는 의미</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 합성곱 층</span></span><br><span class="line">model.add(keras.layers.Conv2D(<span class="number">64</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, </span><br><span class="line">                              padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 풀링층</span></span><br><span class="line">model.add(keras.layers.MaxPooling2D(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 완전연결층 (밀집층 = Fully Connected Layer)</span></span><br><span class="line">model.add(keras.layers.Flatten())</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(keras.layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_2 (Conv2D)           (None, 28, 28, 32)        320       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         
 )                                                               
                                                                 
 conv2d_3 (Conv2D)           (None, 14, 14, 64)        18496     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         
 2D)                                                             
                                                                 
 flatten_1 (Flatten)         (None, 3136)              0         
                                                                 
 dense_2 (Dense)             (None, 100)               313700    
                                                                 
 dropout_1 (Dropout)         (None, 100)               0         
                                                                 
 dense_3 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 333,526
Trainable params: 333,526
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<ul>
<li>층의 구조를 그림으로 표현<ul>
<li>plot_model()함수</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.utils.plot_model(model)</span><br></pre></td></tr></table></figure>




<p><img src="/Images/0407_Convolution_Neural_Network_02/output_9_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 실험 코드</span></span><br><span class="line">keras.utils.plot_model(model, show_shapes=<span class="literal">True</span>,</span><br><span class="line">                       dpi= <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dpi로 크기를 조절 할 수 있음 [default: 96]</span></span><br></pre></td></tr></table></figure>




<p><img src="/Images/0407_Convolution_Neural_Network_02/output_10_0.png" alt="png"></p>
<ul>
<li>매개변수 show_shapes를 적용하여 입력과 출력의 크기를 표시</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.utils.plot_model(model, show_shapes=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<p><img src="/Images/0407_Convolution_Neural_Network_02/output_12_0.png" alt="png"></p>
<pre><code>- 지금까지 한 것은 모델 정의
</code></pre>
<ul>
<li>모델 컴파일 후, 훈련</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-cnn-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line">early_stopping_cb = keras.callbacks.EarlyStopping(patience=<span class="number">2</span>,</span><br><span class="line">                                                  restore_best_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># with tf.device(&#x27;/device:GPU:0&#x27;):</span></span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">10</span>,</span><br><span class="line">                    validation_data=(val_scaled, val_target),</span><br><span class="line">                    callbacks=[checkpoint_cb, early_stopping_cb])</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/10
1500/1500 [==============================] - 22s 7ms/step - loss: 0.5226 - accuracy: 0.8148 - val_loss: 0.3283 - val_accuracy: 0.8823
Epoch 2/10
1500/1500 [==============================] - 12s 8ms/step - loss: 0.3447 - accuracy: 0.8770 - val_loss: 0.2821 - val_accuracy: 0.8950
Epoch 3/10
1500/1500 [==============================] - 11s 7ms/step - loss: 0.2924 - accuracy: 0.8943 - val_loss: 0.2594 - val_accuracy: 0.8985
Epoch 4/10
1500/1500 [==============================] - 13s 8ms/step - loss: 0.2618 - accuracy: 0.9046 - val_loss: 0.2387 - val_accuracy: 0.9109
Epoch 5/10
1500/1500 [==============================] - 12s 8ms/step - loss: 0.2392 - accuracy: 0.9132 - val_loss: 0.2278 - val_accuracy: 0.9163
Epoch 6/10
1500/1500 [==============================] - 10s 7ms/step - loss: 0.2190 - accuracy: 0.9192 - val_loss: 0.2297 - val_accuracy: 0.9172
Epoch 7/10
1500/1500 [==============================] - 10s 7ms/step - loss: 0.2006 - accuracy: 0.9255 - val_loss: 0.2286 - val_accuracy: 0.9179
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"><span class="comment"># model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, </span></span><br><span class="line"><span class="comment">#               metrics=&#x27;accuracy&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-cnn-model.h5&#x27;, </span></span><br><span class="line"><span class="comment">#                                                 save_best_only=True)</span></span><br><span class="line"><span class="comment"># early_stopping_cb = keras.callbacks.EarlyStopping(patience=2,</span></span><br><span class="line"><span class="comment">#                                                   restore_best_weights=True)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># with tf.device(&#x27;/device:GPU:0&#x27;):</span></span><br><span class="line"><span class="comment">#   history = model.fit(train_scaled, train_target, epochs=10,</span></span><br><span class="line"><span class="comment">#                       validation_data=(val_scaled, val_target),</span></span><br><span class="line"><span class="comment">#                       callbacks=[checkpoint_cb, early_stopping_cb])</span></span><br></pre></td></tr></table></figure>

<ul>
<li>모델 학습 곡선 그리기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 연습 코드: plotly로 그려보기</span></span><br><span class="line"><span class="comment"># # 아래와 비슷한 결과를 얻었지만 블로그에 올리기 위해 주석 처리</span></span><br><span class="line"><span class="comment"># import plotly.express as px</span></span><br><span class="line"><span class="comment"># from plotly.subplots import make_subplots</span></span><br><span class="line"><span class="comment"># import plotly.graph_objects as go</span></span><br><span class="line"><span class="comment"># import matplotlib.pyplot as plt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig = make_subplots()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig.add_trace(go.Bar(y= history.history[&#x27;loss&#x27;]))</span></span><br><span class="line"><span class="comment"># fig.add_trace(go.Scatter(y= history.history[&#x27;val_loss&#x27;]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_19_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 그래픽 카드로 돌리는지 확인하는 방법</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">device_name = tf.test.gpu_device_name()</span><br><span class="line"><span class="keyword">if</span> device_name != <span class="string">&#x27;/device:GPU:0&#x27;</span>:</span><br><span class="line">  <span class="keyword">raise</span> SystemError(<span class="string">&#x27;GPU device not found&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Found GPU at: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(device_name))</span><br></pre></td></tr></table></figure>

<pre><code>Found GPU at: /device:GPU:0
</code></pre>
<h1 id="합성곱-신경망-시각화"><a href="#합성곱-신경망-시각화" class="headerlink" title="합성곱 신경망 시각화"></a>합성곱 신경망 시각화</h1><ul>
<li>model이 어떤 가중치를 학습했는지 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">model = keras.models.load_model(<span class="string">&#x27;best-cnn-model.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># keras.utils.plot_model(model2, show_shapes=True)</span></span><br><span class="line"></span><br><span class="line">model.layers  <span class="comment"># 리스트 형태로 저장되어 있음</span></span><br></pre></td></tr></table></figure>




<pre><code>[&lt;keras.layers.convolutional.Conv2D at 0x7fc7d81a7790&gt;,
 &lt;keras.layers.pooling.MaxPooling2D at 0x7fc8e00bfc10&gt;,
 &lt;keras.layers.convolutional.Conv2D at 0x7fc7f2f88490&gt;,
 &lt;keras.layers.pooling.MaxPooling2D at 0x7fc7d710d5d0&gt;,
 &lt;keras.layers.core.flatten.Flatten at 0x7fc8e023bb10&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7fc7f3fb5350&gt;,
 &lt;keras.layers.core.dropout.Dropout at 0x7fc86a7a7050&gt;,
 &lt;keras.layers.core.dense.Dense at 0x7fc86a793750&gt;]



- 2번의 합성곱과 풀링을 하고 Flatten층, Dense층, Dropout층, Dense층이 보임
</code></pre>
<ul>
<li>합성곱층의 가중치를 확인 가능</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv = model.layers[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(conv.weights[<span class="number">0</span>].shape, conv.weights[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>(3, 3, 1, 32) (32,)


- 깊이가 1이므로 실제 커널 크기: (3, 3, 1)
- 필터 개수가 32개이므로 weights의 첫번째 원소인 가중치의 크기: (3, 3, 1, 32)
- weights의 두번째 원소는 절편의 개수를 나타냄
- 필터마다 1개의 절편이 있으므로 (32,)크기가 됨.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv_weights = conv.weights[<span class="number">0</span>].numpy()</span><br><span class="line"><span class="built_in">print</span>(conv_weights.mean(), conv_weights.std())  <span class="comment"># 평균(mean), 표준편차(std)</span></span><br></pre></td></tr></table></figure>

<pre><code>-0.025856383 0.21591602
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(conv_weights.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_29_0.png" alt="png"></p>
<pre><code>- 0을 중심으로 종 모양 분포를 띄고 있음
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">16</span>, figsize=(<span class="number">15</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">        axs[i, j].imshow(conv_weights[:,:,<span class="number">0</span>,i*<span class="number">16</span> + j], vmin=-<span class="number">0.5</span>, vmax=<span class="number">0.5</span>)</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_31_0.png" alt="png"></p>
<ul>
<li>훈련하지 않은 빈 합성곱 신경망을 작성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">no_training_model = keras.Sequential()</span><br><span class="line"></span><br><span class="line">no_training_model.add(keras.layers.Conv2D(<span class="number">32</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, </span><br><span class="line">                                          padding=<span class="string">&#x27;same&#x27;</span>, input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">no_training_conv = no_training_model.layers[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(no_training_conv.weights[<span class="number">0</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>(3, 3, 1, 32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">no_training_weights = no_training_conv.weights[<span class="number">0</span>].numpy()</span><br><span class="line"><span class="built_in">print</span>(no_training_weights.mean(), no_training_weights.std())</span><br></pre></td></tr></table></figure>

<pre><code>0.0065383185 0.081879705
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(no_training_weights.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_36_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">16</span>, figsize=(<span class="number">15</span>,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">        axs[i, j].imshow(no_training_weights[:,:,<span class="number">0</span>,i*<span class="number">16</span> + j], vmin=-<span class="number">0.5</span>, vmax=<span class="number">0.5</span>)</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_37_0.png" alt="png"></p>
<pre><code>- 히스토그램에서 보앗듯이 전체적으로 가중치가 밋밋하게 초기화됨.
- 특징이 뚜렷하지 않음.
</code></pre>
<h1 id="함수형-API"><a href="#함수형-API" class="headerlink" title="함수형 API"></a>함수형 API</h1><ul>
<li>딥러닝에는 더 복잡한 모델이 많이 있음.<ul>
<li>입력이 2개일수도 있고 출력이 2개일수도 있는데 이런 경우엔 함수형API를 사용</li>
</ul>
</li>
</ul>
<h1 id="특성-맵-시각화"><a href="#특성-맵-시각화" class="headerlink" title="특성 맵 시각화"></a>특성 맵 시각화</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.<span class="built_in">input</span>)</span><br><span class="line">conv_acti = keras.Model(model.<span class="built_in">input</span>, model.layers[<span class="number">0</span>].output)</span><br><span class="line">(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()</span><br><span class="line">plt.imshow(train_input[<span class="number">0</span>], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=&#39;conv2d_2_input&#39;), name=&#39;conv2d_2_input&#39;, description=&quot;created by layer &#39;conv2d_2_input&#39;&quot;)
</code></pre>
<p><img src="/Images/0407_Convolution_Neural_Network_02/output_41_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inputs = train_input[<span class="number">0</span>:<span class="number">1</span>].reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)/<span class="number">255.0</span></span><br><span class="line">feature_maps = conv_acti.predict(inputs)</span><br><span class="line"><span class="built_in">print</span>(feature_maps.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(1, 28, 28, 32)
</code></pre>
<ul>
<li>32개의 필터로 인해 입력 이미지에서 강하게 활성화 된 부분을 보여줌.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">4</span>, <span class="number">8</span>, figsize=(<span class="number">15</span>,<span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">        axs[i, j].imshow(feature_maps[<span class="number">0</span>,:,:,i*<span class="number">8</span> + j])</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0407_Convolution_Neural_Network_02/output_44_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">conv2_acti = keras.Model(model.<span class="built_in">input</span>, model.layers[<span class="number">2</span>].output)</span><br><span class="line">feature_maps = conv2_acti.predict(train_input[<span class="number">0</span>:<span class="number">1</span>].reshape(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)/<span class="number">255.0</span>)</span><br><span class="line"><span class="built_in">print</span>(feature_maps.shape)</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(<span class="number">8</span>, <span class="number">8</span>, figsize=(<span class="number">12</span>,<span class="number">12</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">        axs[i, j].imshow(feature_maps[<span class="number">0</span>,:,:,i*<span class="number">8</span> + j])</span><br><span class="line">        axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>(1, 14, 14, 64)
</code></pre>
<p><img src="/Images/0407_Convolution_Neural_Network_02/output_45_1.png" alt="png"></p>
<ul>
<li><ul>
<li>합성곱 신경망의 앞부분에 있는 합성곱 층은 이미지의 시각적인 정보를 감지하고 뒤쪽에 있는 합성곱 층은 앞쪽에서 감지한 시각적인 정보를 바탕으로 추상적인 정보를 학습한다는 추론이 가능.</li>
</ul>
</li>
</ul>
<h1 id="마무리"><a href="#마무리" class="headerlink" title="마무리"></a>마무리</h1><ul>
<li><p>키워드</p>
<ul>
<li><strong>가중치 시각화</strong>: 합성곱 층의 가중치를 이미지로 출력하는것</li>
<li><strong>특성 맵 시각화</strong>: 합성곱 층의 활성화 출력을 이미지로 그리는 것</li>
<li><strong>함수형 API</strong>: 케라스에서 신경망 모델을 만드는 방법 중 하나. 전형적으로 입력은 Input()함수를 사용하고, 출력은 마지막 층의 출력으로 정의</li>
</ul>
</li>
<li><p><strong>TensolFlow</strong> 패키지</p>
<ul>
<li><strong>Conv2D</strong>: 입력의 너비와 높이 방향의 합성곱 연산을 구현한 클래스</li>
<li><strong>MaxPooling2D</strong>: 입력의 너비와 높이를 줄이는 풀링 연산을 구현한 클래스</li>
<li><strong>plot_model()</strong>: 케라스 모델 구조를 주피터 노트북에 그리거나 파일로 저장.</li>
<li><strong>Model</strong>: 케라스 모델을 만드는 클래스</li>
</ul>
</li>
<li><p><strong>matplotlib</strong> 패키지</p>
<ul>
<li><strong>bar()</strong>: 막대그래프를 출력</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-06T00:00:00.000Z" title="2022. 4. 6. 오전 9:00:00">2022-04-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-07T08:01:17.114Z" title="2022. 4. 7. 오후 5:01:17">2022-04-07</time></span><span class="level-item"> woobin </span><span class="level-item">8 minutes read (About 1135 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/06/0406_Convolution_Neural_Network/">합성곱 신경망_01</a></h1><div class="content"><h1 id="합성곱-신경망-CNN"><a href="#합성곱-신경망-CNN" class="headerlink" title="합성곱 신경망 ( CNN )"></a>합성곱 신경망 ( CNN )</h1><ul>
<li><p>로지스틱 회귀(일반 ML 모형): 81%</p>
<ul>
<li>1950년대</li>
</ul>
</li>
<li><p>인공신경망 (딥러닝 초기 모형): 87%</p>
<ul>
<li>1940 ~ 80년대</li>
</ul>
</li>
<li><p>합성곱(Convolution, CNN): 이미지 관련</p>
<ul>
<li>이미지의 특성을 잡아내는 알고리즘</li>
<li>코드보다는 용어에 초점</li>
<li>변천사: alexnet (2012) - &gt; resnet - &gt; efficientnet 기타 등등…</li>
<li>채널(색 성분), 이미지의 넓이, 크기[&#x3D;높이] (파라미터 튜닝)</li>
<li>Vision Transformer (논문): 이미지 분류 부분의 판도를 크게 바꾼 논문</li>
</ul>
</li>
<li><p>비디오</p>
<ul>
<li>객체인식 (Object Detection) 위주</li>
<li>Yolo (논문): 합성곱 신경망( CNN ) 기반으로 작성됨.</li>
</ul>
</li>
<li><p>순환 신경망(RNN) - LSTM (Long Short-Term Memory models)</p>
<ul>
<li>구글 2017년 Transformer (논문) [자연어 처리 관련]</li>
</ul>
</li>
</ul>
<h1 id="합성곱의-장점"><a href="#합성곱의-장점" class="headerlink" title="합성곱의 장점"></a>합성곱의 장점</h1><ul>
<li>기존: 1차원 배열에서만 연산이 가능</li>
<li>2차원 배열에도 연산을 할 수 있도록 구현돰<ul>
<li>선형대수: 행렬을 이용하여 선형적인 문제를 해결. 행렬의 연산만을 다루는 것이 아니라, 공학적인 문제를 행렬의 형태로 정의하고 그 해답을 구하는 과정과 방법</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">keras.layers.Conv2D(<span class="number">10</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation= <span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"><span class="comment"># 매개변수 명 filters를 적은 정식 명칭</span></span><br><span class="line"><span class="comment"># keras.layers.Conv2D(filters= 10, kernel_size=(3, 3), activation= &#x27;relu&#x27;)</span></span><br><span class="line"><span class="comment"># activation= &#x27;relu&#x27; ==&gt; 연산중 0으로 나오는 값들은 제외</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;keras.layers.convolutional.Conv2D at 0x7facca8a1410&gt;
</code></pre>
<h2 id="패딩의-목적"><a href="#패딩의-목적" class="headerlink" title="패딩의 목적"></a>패딩의 목적</h2><ul>
<li>배열의 크기를 조정하더라도 이미지의 원 특성이 손실되는것을 방지</li>
<li>패딩이 적용되지 않으면 각 모서리의 데이터는 한번씩밖에 읽히지 않음</li>
<li>세임(same) 패딩: 입력 주위에 0이나 1로 패딩하는것</li>
<li>밸리드(valid) 패딩: 패딩 없이 순수한 입력 배열에서만 합성곱을 진행. (특성 맵의 크기가 줄어듦)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 세임패딩 적용</span></span><br><span class="line">keras.layers.Conv2D(<span class="number">10</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                    activation= <span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                    padding= <span class="string">&#x27;same&#x27;</span>) </span><br></pre></td></tr></table></figure>




<pre><code>&lt;keras.layers.convolutional.Conv2D at 0x7facc9f66290&gt;
</code></pre>
<h2 id="풀링"><a href="#풀링" class="headerlink" title="풀링"></a>풀링</h2><ul>
<li><p>값을 추출</p>
</li>
<li><p>최대풀링: 필터마다의 최대값을 도출함</p>
</li>
<li><p>if ex) 100 * 100이미지 –&gt; 주요 이미지의 특성만 뽑은 후, 원이미지와 같게 만듬. 이때 크기는 줄어듬 (50 * 50)</p>
</li>
</ul>
<h1 id="합성곱-신경망의-전체-구조"><a href="#합성곱-신경망의-전체-구조" class="headerlink" title="합성곱 신경망의 전체 구조"></a>합성곱 신경망의 전체 구조</h1><ul>
<li><p>1단계: 이미지 데이터 입력</p>
</li>
<li><p>2단계: 합성곱 층</p>
<ul>
<li><ol>
<li>kernel_size + padding</li>
</ol>
</li>
<li><ol start="2">
<li>황설화 함수 적용</li>
</ol>
</li>
<li><ol start="3">
<li>각각의 특성맵을 산출</li>
</ol>
</li>
</ul>
</li>
<li><p>3단계: 풀링층</p>
<ul>
<li><ol>
<li>Max pooling: 최댓값 추출 (풀링 방법 중 하나)</li>
</ol>
</li>
<li><ol start="2">
<li>최종 특성맵</li>
</ol>
</li>
</ul>
</li>
<li><p>이 과정 (1~3단계) 을 계속 반복하는것이 CNN 알고리즘</p>
</li>
<li><p>4단계: 밀집층 (Fully Connected Layer)</p>
</li>
<li><p>5단계: 분류 &#x2F; 예측 값을 산출 (Softmax 활성화 함수)</p>
</li>
</ul>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li><strong>합성곱</strong>: 밀집층과 비슷하게 입력과 가중치를 곱하고 절편을 더하는 선형계산 (각 합성곱은 입력 전체가 아니라 일부만 사용)</li>
<li><strong>채널</strong>: 채널은 색 성분을 의미하며 흑백이미지는 1이며, 각 픽셀은 0 ~ 255사이의 값을 가짐. 이미지는 ‘높이’, ‘너비’, ‘채널’ 이라는 3차원 텐서로 정의됨.</li>
<li><strong>필터[&#x3D;커널]</strong>: 밀집층의 뉴련에 해당. 합성곱 신경망에서 부르는 명칭. (3 * 3) 과 (5 * 5)를 자주 사용</li>
<li><strong>특성 맵</strong>: 합성곱 층이나 풀링 층의 출력 ‘배열’을 의미</li>
<li><strong>패딩</strong>: 합성곱 층의 입력 주위에 추가한 0으로 채워진 픽셀</li>
<li><strong>스트라이드</strong>: 합성곱 층에서 필터가 입력(데이터) 위를 이동하는 간격. 일반적으로 1픽셀 사용</li>
<li><strong>풀링</strong>: 가중치가 없고 특성 맵의 가로 세로 크기를 줄이는 역할. 대표적으로 최대 풀링과 평균 풀링이 있음.</li>
<li><strong>사전학습 모델(Pre-Trained Model)</strong>: 풀고자하는 문제와 비슷하면서 사이즈가 큰 데이터로 이미 학습이 되어 있는 모델</li>
<li><strong>전이학습(Transfer Learning)</strong>: 특정 분야에서 학습된 신경망의 일부 능력을 유사하거나 전혀 새로운 분야에서 사용되는 신경망의 학습에 이용하는 방법</li>
<li><strong>파인튜닝(Fine tuning)</strong>: 기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적에 맞게 변형하고 이미 학습된 모델의 가중치를 미세하게 조정하여 학습시키는 방법<ul>
<li>-&gt; 캐글 경진대회에서 학습 &#x2F; 실습 가능 (클래스 공부 필요)</li>
</ul>
</li>
</ul>
</li>
<li><strong>TensorFlow 패키지</strong><ul>
<li><strong>Keras.layers</strong>: 케라스의 층, 합성곱 층<ul>
<li><strong>Conv2D</strong>: 특별히 위를 이동하는 합성곱<ul>
<li>매개변수 filters: 필터의 개수</li>
<li>매개변수 kernel_size: 필터(커널)의 크기</li>
<li>매개변수 activation: 활성화 함수.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-06T00:00:00.000Z" title="2022. 4. 6. 오전 9:00:00">2022-04-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-07T00:08:24.930Z" title="2022. 4. 7. 오전 9:08:24">2022-04-07</time></span><span class="level-item"> woobin </span><span class="level-item">19 minutes read (About 2791 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/06/0406_woob-s/">Kaggle 프로젝트</a></h1><div class="content"><h1 id="프로젝트-개요"><a href="#프로젝트-개요" class="headerlink" title="프로젝트 개요"></a>프로젝트 개요</h1><ul>
<li>강의명 : 2022년 K-디지털 직업훈련(Training) 사업 - AI데이터플랫폼을 활용한 빅데이터 분석전문가 과정</li>
<li>교과목명 : 빅데이터 분석 및 시각화, AI개발 기초, 인공지능 프로그래밍</li>
<li>프로젝트 주제 : Spaceship Titanic 데이터를 활용한 탑승유무 분류모형 개발</li>
<li>프로젝트 마감일 : 2022년 4월 12일 화요일</li>
<li>강사명 : 정지훈 강사</li>
<li>수강생명 : 황우빈</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This Python 3 environment comes with many helpful analytics libraries installed</span></span><br><span class="line"><span class="comment"># It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python</span></span><br><span class="line"><span class="comment"># For example, here&#x27;s several helpful packages to load</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input data files are available in the read-only &quot;../input/&quot; directory</span></span><br><span class="line"><span class="comment"># For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dirname, _, filenames <span class="keyword">in</span> os.walk(<span class="string">&#x27;/kaggle/input&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        <span class="built_in">print</span>(os.path.join(dirname, filename))</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; </span></span><br><span class="line"><span class="comment"># You can also write temporary files to /kaggle/temp/, but they won&#x27;t be saved outside of the current session</span></span><br></pre></td></tr></table></figure>

<h1 id="Step-1-라이브러리-및-데이터-불러오기"><a href="#Step-1-라이브러리-및-데이터-불러오기" class="headerlink" title="Step.1 라이브러리 및 데이터 불러오기"></a>Step.1 라이브러리 및 데이터 불러오기</h1><ul>
<li>라이브러리 버전 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">from</span> plotly.subplots <span class="keyword">import</span> make_subplots</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objects <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> make_column_transformer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> uniform, randint</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;success&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">    <span class="comment"># PassengerId: 승객 번호, Transported: 전송</span></span><br><span class="line">sample = pd.read_csv(<span class="string">&quot;/kaggle/input/spaceship-titanic/sample_submission.csv&quot;</span>)</span><br><span class="line"><span class="comment"># print(sample.head())</span></span><br><span class="line">test = pd.read_csv(<span class="string">&quot;/kaggle/input/spaceship-titanic/test.csv&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(test.head())</span><br><span class="line">train = pd.read_csv(<span class="string">&quot;/kaggle/input/spaceship-titanic/train.csv&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(train.head())</span><br></pre></td></tr></table></figure>

<h2 id="칼럼-별-설명"><a href="#칼럼-별-설명" class="headerlink" title="칼럼 별 설명:"></a>칼럼 별 설명:</h2><ul>
<li><p>PassengerId: 각 승객의 고유 ID</p>
</li>
<li><p>HomePlanet: 승객이 출발한 행성</p>
</li>
<li><p>CryoSleep: 승객이 항해 기간 동안 애니메이션을 일시 중단하도록 선택했는지 여부를 나타냄</p>
</li>
<li><p>Cabin: 승객이 머물고 있는 객실 번호입니다.</p>
</li>
<li><p>Destination: 승객이 출발할 행성입니다.</p>
</li>
<li><p>Age: 승객의 나이</p>
</li>
<li><p>VIP: 승객이 항해 중 특별 VIP 서비스 비용을 지불했는지 여부.</p>
</li>
<li><p>RoomService: 승객이 룸서비스에 대해 청구한 금액입니다.</p>
</li>
<li><p>Name: 승객의 이름</p>
</li>
<li><p>Transported: 승객이 다른 차원으로 운송되었는지 여부. 예측하려는 대상인 열</p>
</li>
<li><p>train데이터 결측치 유무, 통계 확인</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train.info()</span><br><span class="line">train.describe()</span><br></pre></td></tr></table></figure>

<ul>
<li>test데이터 결측치 유무, 통계 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 결측치 확인</span></span><br><span class="line">test.info()</span><br><span class="line">test.describe()</span><br></pre></td></tr></table></figure>

<h1 id="Step-2-탐색적-자료-분석-EDA"><a href="#Step-2-탐색적-자료-분석-EDA" class="headerlink" title="Step.2 탐색적 자료 분석(EDA)"></a>Step.2 탐색적 자료 분석(EDA)</h1><ul>
<li><p>데이터 시각화</p>
</li>
<li><p>산점도, 막대 그래프 등</p>
</li>
<li><p>그래프 해석해서 설명을 달아야 함.</p>
</li>
<li><p>약간의 데이터 전처리</p>
</li>
<li><p>시각화하기 위한 함수 작성.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># text = &quot;Age&quot;</span></span><br><span class="line"><span class="comment"># train_series = train[text].value_counts()</span></span><br><span class="line"><span class="comment"># train_df = pd.DataFrame(train_series).sort_index()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># test_series = test[text].value_counts()</span></span><br><span class="line"><span class="comment"># test_df = pd.DataFrame(test_series).sort_index()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig = make_subplots(rows= 1,</span></span><br><span class="line"><span class="comment">#                    cols= 1,</span></span><br><span class="line"><span class="comment">#                    column_titles= [&quot;Target Values&quot;],</span></span><br><span class="line"><span class="comment">#                    y_title= &quot;Values&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig.add_trace(go.Scatter(x= df.index, y= train_df[text],</span></span><br><span class="line"><span class="comment">#                     orientation=&quot;v&quot;,</span></span><br><span class="line"><span class="comment">#                         name= &quot;train&quot;),</span></span><br><span class="line"><span class="comment">#                     1, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig.add_trace(go.Scatter(x= df.index, y= test_df[text],</span></span><br><span class="line"><span class="comment">#                     orientation=&quot;v&quot;),</span></span><br><span class="line"><span class="comment">#                     1, 1)          </span></span><br><span class="line"><span class="comment"># fig.update_layout()</span></span><br><span class="line"><span class="comment"># fig.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">visual</span>(<span class="params">train, test, text</span>):</span><br><span class="line">    </span><br><span class="line">    train_series = train[text].value_counts()</span><br><span class="line">    train_df = pd.DataFrame(train_series).sort_index()</span><br><span class="line">    </span><br><span class="line">    test_series = test[text].value_counts()</span><br><span class="line">    test_df = pd.DataFrame(test_series).sort_index()</span><br><span class="line"></span><br><span class="line">    fig = make_subplots(rows= <span class="number">1</span>,</span><br><span class="line">                       cols= <span class="number">1</span>,</span><br><span class="line">                       column_titles= [<span class="string">&quot;Target Values&quot;</span>],</span><br><span class="line">                       y_title= <span class="string">&quot;Values&quot;</span>)</span><br><span class="line"></span><br><span class="line">    fig.add_trace(go.Scatter(x= train_df.index, y= train_df[text],</span><br><span class="line">                        orientation=<span class="string">&quot;v&quot;</span>,</span><br><span class="line">                            name= <span class="string">&quot;train_data&quot;</span>),</span><br><span class="line">                        <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    fig.add_trace(go.Scatter(x= test_df.index, y= test_df[text],</span><br><span class="line">                        orientation=<span class="string">&quot;v&quot;</span>,</span><br><span class="line">                            name= <span class="string">&quot;test_data&quot;</span>),</span><br><span class="line">                        <span class="number">1</span>, <span class="number">1</span>)          </span><br><span class="line">    fig.update_layout()</span><br><span class="line">    fig.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;Age&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>- 10대 후반에서 30대 후반의 비율이 높은것을 확인 할 수 있음.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;RoomService&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;FoodCourt&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;ShoppingMall&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;Spa&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;VRDeck&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>- RoomService, FoodCourt, ShoppingMall, Spa, VRDeck의 데이터중 10 미만의 값들이 압도적으로 많은것을 확인 할 수 있다.
</code></pre>
<ul>
<li>결측값들의 개수 찾기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_null = pd.DataFrame(train.isna().<span class="built_in">sum</span>())</span><br><span class="line">train_null= train_null.sort_values(by= <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(train_null)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">test_null = pd.DataFrame(test.isna().<span class="built_in">sum</span>())</span><br><span class="line">test_null= test_null.sort_values(by= <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(test_null)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 결측치데이터 - 시각화</span></span><br><span class="line">fig = make_subplots(rows= <span class="number">1</span>,</span><br><span class="line">                   cols= <span class="number">2</span>,</span><br><span class="line">                   column_titles= [<span class="string">&quot;train data&quot;</span>, <span class="string">&quot;test data&quot;</span>],</span><br><span class="line">                   x_title= <span class="string">&quot;Missing Values&quot;</span>)</span><br><span class="line"></span><br><span class="line">fig.add_trace(go.Bar(x= train_null[<span class="number">0</span>], y= train_null.index,</span><br><span class="line">                    orientation=<span class="string">&quot;h&quot;</span>,),</span><br><span class="line">                    <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">              </span><br><span class="line">fig.add_trace(go.Bar(x= test_null[<span class="number">0</span>], y= test_null.index,</span><br><span class="line">                    orientation=<span class="string">&quot;h&quot;</span>),</span><br><span class="line">                    <span class="number">1</span>, <span class="number">2</span>)          </span><br><span class="line"></span><br><span class="line">fig.update_layout()</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>

<pre><code>- Transported와 PassengerId를 제외하고는 결측치가 존재하는걸 확인 할 수 있음.
</code></pre>
<h1 id="Step-3-데이터-전처리"><a href="#Step-3-데이터-전처리" class="headerlink" title="Step.3 데이터 전처리"></a>Step.3 데이터 전처리</h1><ul>
<li><p>Feature Engineering</p>
</li>
<li><p>머신러닝(ML) 모형을 돌리기 위해 표준화 등 &#x2F; 원핫-인코딩</p>
</li>
<li><p>파생변수(도출변수) 만들기</p>
<ul>
<li>왜 이 변수를 만들었는지에 대한 설명 필요</li>
</ul>
</li>
<li><p>필요한 데이터를 제외하고는 제외</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.head()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target = train[<span class="string">&#x27;Transported&#x27;</span>]</span><br><span class="line">target</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train[<span class="string">&#x27;PassengerId&#x27;</span>].value_counts())  <span class="comment"># x</span></span><br><span class="line"><span class="comment"># train[&#x27;HomePlanet&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;CryoSleep&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="built_in">print</span>(train[<span class="string">&#x27;Cabin&#x27;</span>].value_counts())  <span class="comment"># x</span></span><br><span class="line"><span class="comment"># train[&#x27;Destination&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;Age&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;VIP&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;RoomService&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;FoodCourt&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;ShoppingMall&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;Spa&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;VRDeck&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="built_in">print</span>(train[<span class="string">&#x27;Name&#x27;</span>].value_counts())  <span class="comment"># x</span></span><br></pre></td></tr></table></figure>

<pre><code>- 확인 해 본 결과 PassengerId, Cabin, Name의 특성은 예측에 영향을 안줄것으로 추정하여 제외하도록 함.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_data = train.drop([&#x27;PassengerId&#x27;, &#x27;Name&#x27;], axis= 1)</span></span><br><span class="line"><span class="comment"># test_data = test.drop([&#x27;PassengerId&#x27;, &#x27;Name&#x27;], axis= 1)</span></span><br><span class="line"></span><br><span class="line">train_data = train.drop([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>], axis= <span class="number">1</span>)</span><br><span class="line">test_data = test.drop([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>], axis= <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line"><span class="built_in">print</span>(test_data.shape)</span><br></pre></td></tr></table></figure>

<ul>
<li>결측치를 float 타입은 mean()으로 object 타입은 최빈값으로 채우기 위해 각각의 데이터를 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.info()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># float</span></span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;Age&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;RoomService&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;FoodCourt&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;ShoppingMall&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;Spa&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;VRDeck&quot;</span>].mean())</span><br><span class="line"><span class="comment"># object</span></span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;HomePlanet&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;CryoSleep&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;Destination&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;VIP&quot;</span>].mode())</span><br></pre></td></tr></table></figure>

<ul>
<li>train데이터 결측값 대체하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># float</span></span><br><span class="line">train_data[<span class="string">&#x27;Age&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;Age&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;RoomService&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;RoomService&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;FoodCourt&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;FoodCourt&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;ShoppingMall&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;ShoppingMall&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;Spa&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;Spa&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;VRDeck&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;VRDeck&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># object</span></span><br><span class="line">train_data[<span class="string">&#x27;HomePlanet&#x27;</span>].replace(np.nan, <span class="string">&#x27;Earth&#x27;</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;Destination&#x27;</span>].replace(np.nan, <span class="string">&#x27;TRAPPIST-1e&#x27;</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;CryoSleep&#x27;</span>].replace(np.nan, <span class="literal">False</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;VIP&#x27;</span>].replace(np.nan, <span class="literal">False</span>, inplace= <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_data.isna().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_data.info()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># float</span></span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;Age&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;RoomService&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;FoodCourt&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;ShoppingMall&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;Spa&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;VRDeck&quot;</span>].mean())</span><br><span class="line"><span class="comment"># object</span></span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;HomePlanet&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;CryoSleep&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;Destination&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;VIP&quot;</span>].mode())</span><br></pre></td></tr></table></figure>

<ul>
<li>test데이터 결측값 대체하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># float</span></span><br><span class="line">test_data[<span class="string">&#x27;Age&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;Age&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;RoomService&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;RoomService&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;FoodCourt&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;FoodCourt&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;ShoppingMall&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;ShoppingMall&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;Spa&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;Spa&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;VRDeck&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;VRDeck&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># object</span></span><br><span class="line">test_data[<span class="string">&#x27;HomePlanet&#x27;</span>].replace(np.nan, <span class="string">&#x27;Earth&#x27;</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;Destination&#x27;</span>].replace(np.nan, <span class="string">&#x27;TRAPPIST-1e&#x27;</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;CryoSleep&#x27;</span>].replace(np.nan, <span class="literal">False</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;VIP&#x27;</span>].replace(np.nan, <span class="literal">False</span>, inplace= <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_data.isna().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>

<pre><code> -결측값들 성공적으로 제거!
</code></pre>
<h2 id="원핫인코딩"><a href="#원핫인코딩" class="headerlink" title="원핫인코딩"></a>원핫인코딩</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Transported의 True는 1로, False는 0으로 대체</span></span><br><span class="line">train_data[<span class="string">&#x27;Transported&#x27;</span>] = train_data[<span class="string">&#x27;Transported&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="literal">True</span>: <span class="number">1</span>, <span class="literal">False</span>: <span class="number">0</span>&#125;)</span><br><span class="line">categorical = [<span class="string">&#x27;HomePlanet&#x27;</span>, <span class="string">&#x27;Destination&#x27;</span>, <span class="string">&#x27;CryoSleep&#x27;</span>, <span class="string">&#x27;VIP&#x27;</span>]</span><br><span class="line"></span><br><span class="line">transformer = make_column_transformer(</span><br><span class="line">(OneHotEncoder(), categorical),</span><br><span class="line">remainder = <span class="string">&#x27;passthrough&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_transformed = transformer.fit_transform(train_data[categorical])</span><br><span class="line">train_transformed_df = pd.DataFrame(train_transformed, columns= transformer.get_feature_names_out())</span><br><span class="line">train_data = pd.concat([train_data, train_transformed_df], axis= <span class="number">1</span>)</span><br><span class="line">train_data = train_data.drop(categorical, axis= <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">test_transformed = transformer.fit_transform(test_data[categorical])</span><br><span class="line">test_transformed_df = pd.DataFrame(test_transformed, columns= transformer.get_feature_names_out())</span><br><span class="line">test_data = pd.concat([test_data, test_transformed_df], axis= <span class="number">1</span>)</span><br><span class="line">test_data = test_data.drop(categorical, axis= <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;success&quot;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Step-4-머신러닝-모형-개발"><a href="#Step-4-머신러닝-모형-개발" class="headerlink" title="Step.4 머신러닝 모형 개발"></a>Step.4 머신러닝 모형 개발</h1><ul>
<li><p>모형에 대한 설명 필요</p>
</li>
<li><p>모형 1~2개 사용 권장</p>
</li>
<li><p>교차 검증</p>
</li>
<li><p>하이퍼 파라미터 튜닝</p>
<ul>
<li>랜덤서치(매개변수(max_depth))</li>
<li>그래드서치</li>
</ul>
</li>
<li><p>독립변수와 종속변수를 구분</p>
<ul>
<li>독립변수: x</li>
<li>종속변수: Transported &#x3D;&#x3D; y</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_cols = test_data.columns</span><br><span class="line">x = train_data[x_cols].to_numpy()</span><br><span class="line">y = train_data[<span class="string">&#x27;Transported&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련데이터를 검증데이터로 분리<ul>
<li>검증데이터: val</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_val, y_train, y_val = train_test_split(x, y, test_size= <span class="number">0.3</span>, random_state= <span class="number">42</span>)</span><br><span class="line">x_train.shape,x_val.shape,y_train.shape,y_val.shape</span><br></pre></td></tr></table></figure>

<h2 id="랜덤서치"><a href="#랜덤서치" class="headerlink" title="랜덤서치"></a>랜덤서치</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span>: uniform(<span class="number">0.0001</span>, <span class="number">0.001</span>),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: randint(<span class="number">20</span>, <span class="number">50</span>),</span><br><span class="line">    <span class="string">&#x27;min_samples_split&#x27;</span>: randint(<span class="number">2</span>, <span class="number">25</span>),</span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: randint(<span class="number">1</span>, <span class="number">25</span>),&#125;</span><br><span class="line">gs = RandomizedSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>), params,  <span class="comment"># n_iter: 파라미터 검색 횟수</span></span><br><span class="line">                        n_iter= <span class="number">100</span>, n_jobs= -<span class="number">1</span>, random_state= <span class="number">42</span>)  <span class="comment"># n_jobs: cpu코어 수</span></span><br><span class="line"></span><br><span class="line">gs.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">max</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt.score(x_val, y_val))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;success&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="교차검증"><a href="#교차검증" class="headerlink" title="교차검증"></a>교차검증</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_validate(dt, x_train, y_train)</span><br><span class="line">scores</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="comment"># 평균 점수 0.7903040262941661</span></span><br></pre></td></tr></table></figure>

<ul>
<li>StratifiedKFold()로 Fold 교차검증을 높여봄.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_validate(dt, x_train, y_train, cv= StratifiedKFold())</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">splitter = StratifiedKFold(n_splits=<span class="number">200</span>, shuffle= <span class="literal">True</span>, random_state= <span class="number">42</span>)</span><br><span class="line">scores = cross_validate(dt, x_train, y_train, cv= splitter)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<p>GridSearchCV()의 하이퍼 파라미터를 이용해봄.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">&#x27;min_impurity_decrease&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>]&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>),params, n_jobs= -<span class="number">1</span>)</span><br><span class="line">gs.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>

<ul>
<li>gs로 x,y train데이터 훈련</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt= gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt)</span><br><span class="line"><span class="built_in">print</span>(dt.score(x_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li>gs로 x,y val데이터 훈련</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>),params, n_jobs= -<span class="number">1</span>)</span><br><span class="line">gs.fit(x_val, y_val)</span><br><span class="line"></span><br><span class="line">dt= gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt)</span><br><span class="line"><span class="built_in">print</span>(dt.score(x_val, y_val))</span><br><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">&#x27;min_impurity_decrease&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>],</span><br><span class="line">          <span class="string">&#x27;max_depth&#x27;</span>: <span class="built_in">range</span>(<span class="number">5</span>, <span class="number">20</span>, <span class="number">1</span>),</span><br><span class="line">         <span class="string">&#x27;min_samples_split&#x27;</span>: <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">100</span>, <span class="number">10</span>)&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">max</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<ul>
<li>LightGBM 사용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lgb = LGBMClassifier(random_state= <span class="number">42</span>)</span><br><span class="line">lgb</span><br></pre></td></tr></table></figure>

<h1 id="Step-5-모형-평가"><a href="#Step-5-모형-평가" class="headerlink" title="Step.5 모형 평가"></a>Step.5 모형 평가</h1><ul>
<li><p>훈련데이터를 쪼개어 훈련데이터 + 검증데이터 분리</p>
</li>
<li><p>정확도 비교</p>
</li>
<li><p>혼동행렬(confusion Matrix) 설명</p>
</li>
<li><p>cross_validate() 활용</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 1st challenge</span></span><br><span class="line">splitter = StratifiedKFold(n_splits = <span class="number">5</span>, shuffle = <span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(lgb, x_train, y_train, return_train_score = <span class="literal">True</span>, cv=splitter)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train Acc.&quot;</span>, np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test Acc.&quot;</span>, np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<ul>
<li>검증데이터를 활용하여 정확도를 예상해본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1st challenge</span></span><br><span class="line"></span><br><span class="line">lgb.fit(x_train, y_train)</span><br><span class="line">y_pred = lgb.predict(x_val)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Acc.&quot;</span>, accuracy_score(y_val, y_pred))</span><br><span class="line"><span class="comment"># Acc. 0.7864263803680982</span></span><br></pre></td></tr></table></figure>

<h2 id="혼동행렬-오분류-비용"><a href="#혼동행렬-오분류-비용" class="headerlink" title="혼동행렬 - 오분류 비용"></a>혼동행렬 - 오분류 비용</h2><ul>
<li><p><strong>나무위키 정의</strong>: 어떤 개인이나 모델, 검사도구, 알고리즘의 ‘진단’, ‘분류’, ‘판별’, ‘예측’능력을 평가하기 위해 고안된 표. 오류행렬(error matrix)이라고도 하며, 국내에는 오분류표라고 번역되기도 한다.</p>
</li>
<li><p>표로 나타내기.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">confusion_matrix</span>():</span><br><span class="line">    col = [<span class="string">&quot;실제로 맞았다  &quot;</span>, <span class="string">&quot;  실제로 틀렸다&quot;</span>]</span><br><span class="line">    ind = [<span class="string">&quot;맞을것이다&quot;</span>, <span class="string">&quot;틀릴것이다&quot;</span>]</span><br><span class="line">    con = [[<span class="string">&quot;예측 성공&quot;</span>, <span class="string">&quot;예측 실패&quot;</span>], [<span class="string">&quot;예측 실패&quot;</span>, <span class="string">&quot;예측 성공&quot;</span>]]</span><br><span class="line">    matrix = pd.DataFrame(con, columns=col, index=ind)</span><br><span class="line">    <span class="built_in">print</span>(matrix)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">confusion_matrix()</span><br></pre></td></tr></table></figure>

<pre><code>- True, False 기준에서 작성했기에 2 by 2의 모습
- 기준을 어떻게 잡느냐에 따라서 3 by 3 이상의 다등급 분류를 나타내는 혼동행렬로 나타낼 수 있다.
</code></pre>
<h1 id="Step-6-제출"><a href="#Step-6-제출" class="headerlink" title="Step.6 제출"></a>Step.6 제출</h1><ul>
<li>제출 양식 샘플은 만들어줌.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1st challenge</span></span><br><span class="line">test_preds = lgb.predict(test_data.to_numpy())</span><br><span class="line">sample[<span class="string">&#x27;Transported&#x27;</span>] = test_preds.astype(<span class="string">&quot;bool&quot;</span>)</span><br><span class="line">sample.to_csv(<span class="string">&quot;submission.csv&quot;</span>,index=<span class="literal">False</span>)</span><br><span class="line">sample.head()</span><br></pre></td></tr></table></figure>

<h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><ul>
<li>다른 사람의 code 설명을 쭉 따라치는경우<ul>
<li>노트북 표절 방지 위해서, 참조한 코드는 반드시 링크 걸어둘것</li>
<li>저자 이름, 글 제목, 링크 주소</li>
</ul>
</li>
</ul>
<h1 id="마감일"><a href="#마감일" class="headerlink" title="마감일"></a>마감일</h1><ul>
<li>4월 12일 17시 40분</li>
<li>제출 형태<ul>
<li>Leaderboard 랭킹 사진 캡처</li>
<li>고용노동부 보고 양식 (다음주에 확인하고 알려주실 예정)</li>
</ul>
</li>
</ul>
<h1 id="My-Note"><a href="#My-Note" class="headerlink" title="My_Note"></a>My_Note</h1><ul>
<li>value_counts(): 값 별 개수 세기</li>
<li>Pandas라이브러리<ul>
<li>fillna(): 결측값을 지정한 값으로 채움</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-05T00:00:00.000Z" title="2022. 4. 5. 오전 9:00:00">2022-04-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-05T11:04:20.049Z" title="2022. 4. 5. 오후 8:04:20">2022-04-05</time></span><span class="level-item"> woobin </span><span class="level-item">14 minutes read (About 2104 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/05/0405_Neural_Network_Model/">신경망_모델_훈련</a></h1><div class="content"><h1 id="신경망-모델-훈련"><a href="#신경망-모델-훈련" class="headerlink" title="신경망 모델 훈련"></a>신경망 모델 훈련</h1><h1 id="손실곡선"><a href="#손실곡선" class="headerlink" title="손실곡선"></a>손실곡선</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">(train_input, train_target), (test_input, test_target) = \</span><br><span class="line">    keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">train_scaled = train_input / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">train_scaled, val_scaled, train_target, val_target = train_test_split(</span><br><span class="line">    train_scaled, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>사용자 정의 함수를 작성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model_fn</span>(<span class="params">a_layer=<span class="literal">None</span></span>):</span><br><span class="line">  model = keras.Sequential()</span><br><span class="line">  model.add(keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">  model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">  <span class="keyword">if</span> a_layer:</span><br><span class="line">    model.add(a_layer)</span><br><span class="line">  model.add(keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">model = model_fn()</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 784)               0         
                                                                 
 dense (Dense)               (None, 100)               78500     
                                                                 
 dense_1 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<ul>
<li>모델 정의 후, 학습</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics= <span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">5</span>, verbose= <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/5
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3084 - accuracy: 0.8907
Epoch 2/5
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2963 - accuracy: 0.8947
Epoch 3/5
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2866 - accuracy: 0.8985
Epoch 4/5
1500/1500 [==============================] - 4s 3ms/step - loss: 0.2826 - accuracy: 0.9015
Epoch 5/5
1500/1500 [==============================] - 4s 3ms/step - loss: 0.2754 - accuracy: 0.9037
</code></pre>
<ul>
<li>history 객체 무슨 값이 있나??</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(history.history.keys())</span><br></pre></td></tr></table></figure>

<pre><code>dict_keys([&#39;loss&#39;, &#39;accuracy&#39;])
</code></pre>
<ul>
<li>그래프 작성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0405_Neural_Network_Model/output_10_0.png" alt="png"></p>
<ul>
<li>정확도 출력</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0405_Neural_Network_Model/output_12_0.png" alt="png"></p>
<ul>
<li>손실그래프</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn()</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">0</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0405_Neural_Network_Model/output_14_0.png" alt="png"></p>
<ul>
<li>검증 손실</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 중요</span></span><br><span class="line"><span class="comment"># history = model.fit(train_scaled, train_target, epochs=10, verbose=1, </span></span><br><span class="line"><span class="comment">#                     validation_data=(val_scaled, val_target))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.plot(history.history[&#x27;loss&#x27;])</span></span><br><span class="line"><span class="comment"># plt.plot(history.history[&#x27;val_loss&#x27;])</span></span><br><span class="line"><span class="comment"># plt.xlabel(&#x27;epoch&#x27;)</span></span><br><span class="line"><span class="comment"># plt.ylabel(&#x27;loss&#x27;)</span></span><br><span class="line"><span class="comment"># plt.legend([&#x27;train&#x27;, &#x27;val&#x27;])</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn()</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">10</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target))</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/10
1500/1500 [==============================] - 4s 2ms/step - loss: 0.5272 - accuracy: 0.8130 - val_loss: 0.4003 - val_accuracy: 0.8572
Epoch 2/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3944 - accuracy: 0.8576 - val_loss: 0.3871 - val_accuracy: 0.8617
Epoch 3/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3568 - accuracy: 0.8729 - val_loss: 0.3542 - val_accuracy: 0.8726
Epoch 4/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3324 - accuracy: 0.8805 - val_loss: 0.3576 - val_accuracy: 0.8765
Epoch 5/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3198 - accuracy: 0.8861 - val_loss: 0.3562 - val_accuracy: 0.8795
Epoch 6/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.8910 - val_loss: 0.3875 - val_accuracy: 0.8758
Epoch 7/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2966 - accuracy: 0.8956 - val_loss: 0.3722 - val_accuracy: 0.8764
Epoch 8/10
1500/1500 [==============================] - 4s 2ms/step - loss: 0.2872 - accuracy: 0.8982 - val_loss: 0.3690 - val_accuracy: 0.8783
Epoch 9/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2840 - accuracy: 0.8990 - val_loss: 0.3649 - val_accuracy: 0.8838
Epoch 10/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2745 - accuracy: 0.9041 - val_loss: 0.4154 - val_accuracy: 0.8708
</code></pre>
<p><img src="/Images/0405_Neural_Network_Model/output_17_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 에포크 20으로 늘림</span></span><br><span class="line">model = model_fn()</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target))</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1500/1500 [==============================] - 4s 2ms/step - loss: 0.5319 - accuracy: 0.8131 - val_loss: 0.4284 - val_accuracy: 0.8492
Epoch 2/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3936 - accuracy: 0.8571 - val_loss: 0.3844 - val_accuracy: 0.8645
Epoch 3/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3560 - accuracy: 0.8704 - val_loss: 0.3669 - val_accuracy: 0.8715
Epoch 4/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3353 - accuracy: 0.8792 - val_loss: 0.3503 - val_accuracy: 0.8792
Epoch 5/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3200 - accuracy: 0.8857 - val_loss: 0.3798 - val_accuracy: 0.8707
Epoch 6/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3089 - accuracy: 0.8902 - val_loss: 0.3681 - val_accuracy: 0.8759
Epoch 7/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2984 - accuracy: 0.8945 - val_loss: 0.4130 - val_accuracy: 0.8653
Epoch 8/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2925 - accuracy: 0.8955 - val_loss: 0.3637 - val_accuracy: 0.8847
Epoch 9/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2822 - accuracy: 0.9012 - val_loss: 0.3923 - val_accuracy: 0.8762
Epoch 10/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2762 - accuracy: 0.9031 - val_loss: 0.3755 - val_accuracy: 0.8808
Epoch 11/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2726 - accuracy: 0.9040 - val_loss: 0.3748 - val_accuracy: 0.8794
Epoch 12/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2631 - accuracy: 0.9085 - val_loss: 0.3988 - val_accuracy: 0.8809
Epoch 13/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2600 - accuracy: 0.9087 - val_loss: 0.4310 - val_accuracy: 0.8813
Epoch 14/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2549 - accuracy: 0.9116 - val_loss: 0.4131 - val_accuracy: 0.8844
Epoch 15/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2533 - accuracy: 0.9139 - val_loss: 0.4343 - val_accuracy: 0.8820
Epoch 16/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2479 - accuracy: 0.9151 - val_loss: 0.4254 - val_accuracy: 0.8862
Epoch 17/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2406 - accuracy: 0.9166 - val_loss: 0.4298 - val_accuracy: 0.8858
Epoch 18/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2369 - accuracy: 0.9176 - val_loss: 0.4401 - val_accuracy: 0.8852
Epoch 19/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2347 - accuracy: 0.9192 - val_loss: 0.4332 - val_accuracy: 0.8883
Epoch 20/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2316 - accuracy: 0.9211 - val_loss: 0.4471 - val_accuracy: 0.8796
</code></pre>
<p><img src="/Images/0405_Neural_Network_Model/output_18_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 옵티마이저 적용</span></span><br><span class="line">model = model_fn()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= <span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target))</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.5265 - accuracy: 0.8185 - val_loss: 0.4242 - val_accuracy: 0.8491
Epoch 2/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3969 - accuracy: 0.8575 - val_loss: 0.3747 - val_accuracy: 0.8667
Epoch 3/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3550 - accuracy: 0.8715 - val_loss: 0.3502 - val_accuracy: 0.8747
Epoch 4/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3292 - accuracy: 0.8795 - val_loss: 0.3671 - val_accuracy: 0.8695
Epoch 5/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3079 - accuracy: 0.8876 - val_loss: 0.3563 - val_accuracy: 0.8748
Epoch 6/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2941 - accuracy: 0.8918 - val_loss: 0.3482 - val_accuracy: 0.8759
Epoch 7/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2816 - accuracy: 0.8972 - val_loss: 0.3568 - val_accuracy: 0.8693
Epoch 8/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2702 - accuracy: 0.9002 - val_loss: 0.3165 - val_accuracy: 0.8883
Epoch 9/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2575 - accuracy: 0.9045 - val_loss: 0.3286 - val_accuracy: 0.8808
Epoch 10/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2501 - accuracy: 0.9072 - val_loss: 0.3677 - val_accuracy: 0.8698
Epoch 11/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2387 - accuracy: 0.9115 - val_loss: 0.3232 - val_accuracy: 0.8850
Epoch 12/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2338 - accuracy: 0.9126 - val_loss: 0.3256 - val_accuracy: 0.8865
Epoch 13/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2259 - accuracy: 0.9145 - val_loss: 0.3364 - val_accuracy: 0.8852
Epoch 14/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2178 - accuracy: 0.9184 - val_loss: 0.3426 - val_accuracy: 0.8797
Epoch 15/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2121 - accuracy: 0.9204 - val_loss: 0.3343 - val_accuracy: 0.8855
Epoch 16/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2076 - accuracy: 0.9230 - val_loss: 0.3224 - val_accuracy: 0.8903
Epoch 17/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2025 - accuracy: 0.9222 - val_loss: 0.3432 - val_accuracy: 0.8807
Epoch 18/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.1963 - accuracy: 0.9260 - val_loss: 0.3421 - val_accuracy: 0.8889
Epoch 19/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.1904 - accuracy: 0.9277 - val_loss: 0.3387 - val_accuracy: 0.8859
Epoch 20/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.1869 - accuracy: 0.9308 - val_loss: 0.3481 - val_accuracy: 0.8863
</code></pre>
<p><img src="/Images/0405_Neural_Network_Model/output_19_1.png" alt="png"></p>
<h1 id="드롭아웃"><a href="#드롭아웃" class="headerlink" title="드롭아웃"></a>드롭아웃</h1><ul>
<li>제프리 힌턴</li>
<li>기본적으로 모든 파라미터를 연산하는것이 원칙<ul>
<li>but. 일부 뉴런에서 출력이 없는 뉴런 발생</li>
<li>–&gt; 기존 일부 뉴런은 계산에서 제외 시킴</li>
</ul>
</li>
<li>인공신경망 (뇌과학)<ul>
<li>값이 쏠림 현상이 발생 %&#x3D; 뇌에 피가 고인 현상 %&#x3D; 뇌출혈</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn(keras.layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_6&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_6 (Flatten)         (None, 784)               0         
                                                                 
 dense_12 (Dense)            (None, 100)               78500     
                                                                 
 dropout (Dropout)           (None, 100)               0         
                                                                 
 dense_13 (Dense)            (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 드롭아웃 적용</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= <span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target))</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.5938 - accuracy: 0.7927 - val_loss: 0.4280 - val_accuracy: 0.8453
Epoch 2/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.4419 - accuracy: 0.8411 - val_loss: 0.4036 - val_accuracy: 0.8522
Epoch 3/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.4047 - accuracy: 0.8537 - val_loss: 0.3683 - val_accuracy: 0.8670
Epoch 4/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3828 - accuracy: 0.8608 - val_loss: 0.3504 - val_accuracy: 0.8707
Epoch 5/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3714 - accuracy: 0.8635 - val_loss: 0.3404 - val_accuracy: 0.8767
Epoch 6/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3539 - accuracy: 0.8703 - val_loss: 0.3410 - val_accuracy: 0.8760
Epoch 7/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3483 - accuracy: 0.8721 - val_loss: 0.3377 - val_accuracy: 0.8776
Epoch 8/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3357 - accuracy: 0.8763 - val_loss: 0.3315 - val_accuracy: 0.8807
Epoch 9/20
1500/1500 [==============================] - 4s 3ms/step - loss: 0.3314 - accuracy: 0.8773 - val_loss: 0.3301 - val_accuracy: 0.8771
Epoch 10/20
1500/1500 [==============================] - 4s 2ms/step - loss: 0.3214 - accuracy: 0.8812 - val_loss: 0.3274 - val_accuracy: 0.8787
Epoch 11/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3180 - accuracy: 0.8831 - val_loss: 0.3325 - val_accuracy: 0.8813
Epoch 12/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3121 - accuracy: 0.8852 - val_loss: 0.3194 - val_accuracy: 0.8821
Epoch 13/20
1500/1500 [==============================] - 4s 2ms/step - loss: 0.3078 - accuracy: 0.8860 - val_loss: 0.3408 - val_accuracy: 0.8773
Epoch 14/20
1500/1500 [==============================] - 4s 3ms/step - loss: 0.3026 - accuracy: 0.8865 - val_loss: 0.3316 - val_accuracy: 0.8817
Epoch 15/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2940 - accuracy: 0.8890 - val_loss: 0.3322 - val_accuracy: 0.8831
Epoch 16/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2955 - accuracy: 0.8900 - val_loss: 0.3196 - val_accuracy: 0.8870
Epoch 17/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2919 - accuracy: 0.8908 - val_loss: 0.3243 - val_accuracy: 0.8853
Epoch 18/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2835 - accuracy: 0.8925 - val_loss: 0.3362 - val_accuracy: 0.8830
Epoch 19/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2844 - accuracy: 0.8926 - val_loss: 0.3243 - val_accuracy: 0.8819
Epoch 20/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2812 - accuracy: 0.8943 - val_loss: 0.3184 - val_accuracy: 0.8881
</code></pre>
<p><img src="/Images/0405_Neural_Network_Model/output_22_1.png" alt="png"></p>
<pre><code>- 드롭아웃을 적용했더니 과대적합 되던 모형이 많이 완화됨.
</code></pre>
<h1 id="모댈-저장과-복원"><a href="#모댈-저장과-복원" class="headerlink" title="모댈 저장과 복원"></a>모댈 저장과 복원</h1><ul>
<li>개발자: 정확도는 중요하지 않음<ul>
<li>딥러닝 모델 활용해서 웹앱을 개발하는게 목적</li>
</ul>
</li>
<li>분석가 &amp; 머신러닝 엔지니어: 캐글 대회 (정확도 검증 필수)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save_weights(<span class="string">&#x27;model-weights.h5&#x27;</span>)</span><br><span class="line">model.save(<span class="string">&#x27;model-whole.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>모델 불러오기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn(keras.layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.load_weights(<span class="string">&#x27;model-weights.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">val_labels = np.argmax(model.predict(val_scaled), axis=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(val_labels == val_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8810833333333333
</code></pre>
<h1 id="콜백"><a href="#콜백" class="headerlink" title="콜백"></a>콜백</h1><ul>
<li>model.checkpoint(): 체크포인트를 기록</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn(keras.layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">0</span>, </span><br><span class="line">          validation_data=(val_scaled, val_target),</span><br><span class="line">          callbacks=[checkpoint_cb])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;keras.callbacks.History at 0x7f673a848ad0&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = keras.models.load_model(<span class="string">&#x27;best-model.h5&#x27;</span>)</span><br><span class="line">model.evaluate(val_scaled, val_target)</span><br></pre></td></tr></table></figure>

<pre><code>375/375 [==============================] - 1s 1ms/step - loss: 0.3137 - accuracy: 0.8893





[0.31372642517089844, 0.8893333077430725]
</code></pre>
<ul>
<li>Early Stopping<ul>
<li>조기 종료</li>
<li>에포크를 많이 주면 많이 줄수록 성능이 좋아야 하는 것이 원리 (가중치 업데이트 &#x2F; 기울기가 계속 미분)</li>
<li>if) 에포크 100 &#x2F; 50 에포크 시점과 90에포크 시점 성능 차이 없음</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn(keras.layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line">early_stopping_cb = keras.callbacks.EarlyStopping(patience=<span class="number">2</span>,</span><br><span class="line">                                                  restore_best_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">0</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target),</span><br><span class="line">                    callbacks=[checkpoint_cb, early_stopping_cb])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(early_stopping_cb.stopped_epoch)</span><br></pre></td></tr></table></figure>

<pre><code>14
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0405_Neural_Network_Model/output_35_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li><p>키워드:</p>
<ul>
<li>드롭아웃: 은닉층에 있는 뉴런의 출력을 랜덤하게 꺼서 과대적합을 막는 기법</li>
<li>콜백: 케라스 모델을 훈련하는 도중에 어떤 작업을 수행 할 수 있도록 도와주는 도구</li>
<li>조기종료: 검증점수가 더 이상 감소하지 않고 상승하여 과대적합이 일어나면 훈련을 계속 진행하지 않고 멈추는 기법</li>
</ul>
</li>
<li><p>TensorFlow 패키지</p>
<ul>
<li>Dropout: 드롭아웃 층</li>
<li>save_weights(): 모든 층의 가중치와 절편을 파일에 저장</li>
<li>load_weights(): 모든 층의 가중치와 절편을 파일에 읽음</li>
<li>save(): 모델 구조와 모든 가중치와 절편을 파일에 저장</li>
<li>load_model(): model.save()로 저장된 모델을 로드</li>
<li>ModelCheckpoint: 케라스 모델과 가중치를 일정 간격으로 저장</li>
<li>EarlyStopping: 관심지표가 더이상 향상하지 않으면 훈련을 중지</li>
</ul>
</li>
<li><p>NumPy 패키지</p>
<ul>
<li>argmax: 배열에서 축을 따라 최댓값의 인덱스 반환<ul>
<li>매개변수 axis: 어떤축을 따라 최댓값을 찾을지 지정 [default: None] (전체 배열에서 최댓값)</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-05T00:00:00.000Z" title="2022. 4. 5. 오전 9:00:00">2022-04-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-04-05T11:02:40.946Z" title="2022. 4. 5. 오후 8:02:40">2022-04-05</time></span><span class="level-item"> woobin </span><span class="level-item">6 minutes read (About 830 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/05/0405_Pipeline/">파이프_라인_(데이터_전처리)</a></h1><div class="content"><h1 id="데이터-누수-방지-위한-모델링-기법"><a href="#데이터-누수-방지-위한-모델링-기법" class="headerlink" title="데이터 누수 방지 위한 모델링 기법:"></a>데이터 누수 방지 위한 모델링 기법:</h1><h3 id="파이프라인-구축"><a href="#파이프라인-구축" class="headerlink" title="파이프라인 구축"></a>파이프라인 구축</h3><ul>
<li>수능시험 &#x3D; 최종테스트 데이터</li>
<li>모의고사 or 기출문제 &#x3D; 검증데이터</li>
<li>교과서 문제지 &#x3D; 훈련데이터</li>
<li>머신러닝 엔지니어 : MLOps (선행되어야 하는 코드 조건, Pipeline 형태로 구축)<ul>
<li>머신러닝 코드 자동화 가능, 운영 가능</li>
<li>개발 업계의 최상위 연봉자</li>
</ul>
</li>
</ul>
<h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/data/daily-bike-share.csv&#x27;</span>)</span><br><span class="line">data.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 731 entries, 0 to 730
Data columns (total 14 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   instant     731 non-null    int64  
 1   dteday      731 non-null    object 
 2   season      731 non-null    int64  
 3   yr          731 non-null    int64  
 4   mnth        731 non-null    int64  
 5   holiday     731 non-null    int64  
 6   weekday     731 non-null    int64  
 7   workingday  731 non-null    int64  
 8   weathersit  731 non-null    int64  
 9   temp        731 non-null    float64
 10  atemp       731 non-null    float64
 11  hum         731 non-null    float64
 12  windspeed   731 non-null    float64
 13  rentals     731 non-null    int64  
dtypes: float64(4), int64(9), object(1)
memory usage: 80.1+ KB
</code></pre>
<h1 id="데이터-추출"><a href="#데이터-추출" class="headerlink" title="데이터 추출"></a>데이터 추출</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cols = [<span class="string">&#x27;season&#x27;</span>, <span class="string">&#x27;mnth&#x27;</span>, <span class="string">&#x27;holiday&#x27;</span>, <span class="string">&#x27;weekday&#x27;</span>, <span class="string">&#x27;workingday&#x27;</span>, <span class="string">&#x27;weathersit&#x27;</span>, <span class="string">&#x27;temp&#x27;</span>, <span class="string">&#x27;atemp&#x27;</span>, <span class="string">&#x27;hum&#x27;</span>, <span class="string">&#x27;windspeed&#x27;</span>, <span class="string">&#x27;rentals&#x27;</span>]</span><br><span class="line">data = data[cols]</span><br><span class="line">data.info()</span><br><span class="line"><span class="comment"># data[&#x27;mnth&#x27;].value_counts()</span></span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 731 entries, 0 to 730
Data columns (total 11 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   season      731 non-null    int64  
 1   mnth        731 non-null    int64  
 2   holiday     731 non-null    int64  
 3   weekday     731 non-null    int64  
 4   workingday  731 non-null    int64  
 5   weathersit  731 non-null    int64  
 6   temp        731 non-null    float64
 7   atemp       731 non-null    float64
 8   hum         731 non-null    float64
 9   windspeed   731 non-null    float64
 10  rentals     731 non-null    int64  
dtypes: float64(4), int64(7)
memory usage: 62.9 KB
</code></pre>
<ul>
<li><p>기존: 데이터 불러오기 -&gt; 데이터 전처리 -&gt; 피처공학(원핫인코딩) -&gt; 데이터셋 분리 -&gt; 모델링 코드 -&gt; 모델평가</p>
</li>
<li><p>파이프라인: 데이터 불러오기 -&gt; 데이터 전처리 -&gt; 데이터셋 분리 -&gt; 파이프라인 구축 (피처공학, 모델링 코드) -&gt; 모델평가</p>
</li>
</ul>
<h1 id="데이터셋-분리"><a href="#데이터셋-분리" class="headerlink" title="데이터셋 분리"></a>데이터셋 분리</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X = data.drop(<span class="string">&#x27;rentals&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line">y = data[<span class="string">&#x27;rentals&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>Data Prepocessing</p>
<ul>
<li>결측치 수동으로 채우거나</li>
<li>불필요한 변수를 제거하거나</li>
<li>이상치를 제거하거나</li>
<li>파생변수를 만들거나 등등</li>
</ul>
</li>
<li><p>Feature Engineering</p>
<ul>
<li>기존: 개별적으로 코드 작성</li>
<li>현재: Pipeline 코드로 추가할것</li>
</ul>
</li>
</ul>
<h1 id="Pipeline-구축"><a href="#Pipeline-구축" class="headerlink" title="Pipeline 구축"></a>Pipeline 구축</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, OrdinalEncoder, OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 타입 3가지</span></span><br><span class="line"><span class="comment"># 수치형 데이터, 무자열 데이터</span></span><br><span class="line"><span class="comment"># 문자열 데이터: 범주형(명목형, 서열형 데이터 구분)</span></span><br><span class="line">numeric_transformer = Pipeline(steps=[</span><br><span class="line">       (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;mean&#x27;</span>))</span><br><span class="line">      ,(<span class="string">&#x27;scaler&#x27;</span>, StandardScaler())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">ordinal_transformer = Pipeline(steps=[</span><br><span class="line">       (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;constant&#x27;</span>))</span><br><span class="line">      ,(<span class="string">&#x27;ordEncoder&#x27;</span>, OrdinalEncoder())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">onehot_transformer = Pipeline(steps=[</span><br><span class="line">       (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;constant&#x27;</span>))</span><br><span class="line">      ,(<span class="string">&#x27;oheEncoder&#x27;</span>, OneHotEncoder())                                   </span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 수치형 데이터 및 Categorical 데이터 컬럼 분리</span></span><br><span class="line"></span><br><span class="line">numeric_features = [<span class="string">&#x27;temp&#x27;</span>, <span class="string">&#x27;atemp&#x27;</span>, <span class="string">&#x27;hum&#x27;</span>, <span class="string">&#x27;windspeed&#x27;</span>]</span><br><span class="line">ordinal_features = [<span class="string">&#x27;holiday&#x27;</span>, <span class="string">&#x27;weekday&#x27;</span>, <span class="string">&#x27;workingday&#x27;</span>, <span class="string">&#x27;weathersit&#x27;</span>]</span><br><span class="line">onehot_features  = [<span class="string">&#x27;season&#x27;</span>, <span class="string">&#x27;mnth&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># numeric_features = data.select_dtypes(include=[&#x27;int64&#x27;, &#x27;float64&#x27;]).columns</span></span><br><span class="line"><span class="comment"># categorical_features = data.select_dtypes(include=[&#x27;object&#x27;]).drop([&#x27;Loan_Status&#x27;], axis=1).columns</span></span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">   transformers=[</span><br><span class="line">     (<span class="string">&#x27;numeric&#x27;</span>, numeric_transformer, numeric_features)</span><br><span class="line">   , (<span class="string">&#x27;ord_categorical&#x27;</span>, ordinal_transformer, ordinal_features)</span><br><span class="line">   , (<span class="string">&#x27;ohe_categorical&#x27;</span>, onehot_transformer, onehot_features)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h1 id="모델-적용"><a href="#모델-적용" class="headerlink" title="모델 적용"></a>모델 적용</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"></span><br><span class="line">pipeline = Pipeline(steps = [</span><br><span class="line">               (<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor)</span><br><span class="line">              ,(<span class="string">&#x27;regressor&#x27;</span>, RandomForestRegressor())</span><br><span class="line">           ])</span><br><span class="line"></span><br><span class="line">rf_model = pipeline.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(rf_model)</span><br></pre></td></tr></table></figure>

<pre><code>Pipeline(steps=[(&#39;preprocessor&#39;,
                 ColumnTransformer(transformers=[(&#39;numeric&#39;,
                                                  Pipeline(steps=[(&#39;imputer&#39;,
                                                                   SimpleImputer()),
                                                                  (&#39;scaler&#39;,
                                                                   StandardScaler())]),
                                                  [&#39;temp&#39;, &#39;atemp&#39;, &#39;hum&#39;,
                                                   &#39;windspeed&#39;]),
                                                 (&#39;ord_categorical&#39;,
                                                  Pipeline(steps=[(&#39;imputer&#39;,
                                                                   SimpleImputer(strategy=&#39;constant&#39;)),
                                                                  (&#39;ordEncoder&#39;,
                                                                   OrdinalEncoder())]),
                                                  [&#39;holiday&#39;, &#39;weekday&#39;,
                                                   &#39;workingday&#39;,
                                                   &#39;weathersit&#39;]),
                                                 (&#39;ohe_categorical&#39;,
                                                  Pipeline(steps=[(&#39;imputer&#39;,
                                                                   SimpleImputer(strategy=&#39;constant&#39;)),
                                                                  (&#39;oheEncoder&#39;,
                                                                   OneHotEncoder())]),
                                                  [&#39;season&#39;, &#39;mnth&#39;])])),
                (&#39;regressor&#39;, RandomForestRegressor())])
</code></pre>
<h1 id="모델-평가"><a href="#모델-평가" class="headerlink" title="모델 평가"></a>모델 평가</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">predictions = rf_model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span> (r2_score(y_test, predictions))</span><br></pre></td></tr></table></figure>

<pre><code>0.7623870644942855
</code></pre>
<h1 id="다중모형-개발"><a href="#다중모형-개발" class="headerlink" title="다중모형 개발"></a>다중모형 개발</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">regressors = [</span><br><span class="line">    RandomForestRegressor()</span><br><span class="line">   ,DecisionTreeRegressor()</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># regressors = [pipe_rf, pipe_dt]</span></span><br><span class="line"><span class="keyword">for</span> regressor <span class="keyword">in</span> regressors:</span><br><span class="line">    pipeline = Pipeline(steps = [</span><br><span class="line">               (<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor)</span><br><span class="line">              ,(<span class="string">&#x27;regressor&#x27;</span>,regressor)</span><br><span class="line">           ])</span><br><span class="line">    model = pipeline.fit(X_train, y_train)</span><br><span class="line">    predictions = model.predict(X_test)</span><br><span class="line">    <span class="built_in">print</span>(regressor)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Model r2 score:<span class="subst">&#123;r2_score(predictions, y_test)&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>RandomForestRegressor()
Model r2 score:0.7385832717833691
DecisionTreeRegressor()
Model r2 score:0.6033264470675421
</code></pre>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">Previous</a></div><div class="pagination-next"><a href="/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><a class="pagination-link" href="/page/5/">5</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">50</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-19T00:00:00.000Z">2022-04-19</time></p><p class="title"><a href="/2022/04/19/0419_Apache_Spark_install/">Apache Spark 설치</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-19T00:00:00.000Z">2022-04-19</time></p><p class="title"><a href="/2022/04/19/0419_Java_install/">Java 설치</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-18T00:00:00.000Z">2022-04-18</time></p><p class="title"><a href="/2022/04/18/0418_kibana_install/">Kibana 설치</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-18T00:00:00.000Z">2022-04-18</time></p><p class="title"><a href="/2022/04/18/0418_Elasticsearch_install/">Elasticsearch 설치</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-18T00:00:00.000Z">2022-04-18</time></p><p class="title"><a href="/2022/04/18/0418_Ubuntu_install/">Ubuntu 설치</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">28</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="WB&#039;blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>