<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>WB&#39;blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="WB&#39;blog">
<meta property="og:url" content="https://woobinhwang.github.io/index.html">
<meta property="og:site_name" content="WB&#39;blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="WB'blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">WB&#39;blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://woobinhwang.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-0331_Principar_Component_Analysis_01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/31/0331_Principar_Component_Analysis_01/" class="article-date">
  <time class="dt-published" datetime="2022-03-31T00:00:00.000Z" itemprop="datePublished">2022-03-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/31/0331_Principar_Component_Analysis_01/">주성분_분석_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h1><h3 id="중요"><a href="#중요" class="headerlink" title="중요"></a><em><strong>중요</strong></em></h3><ul>
<li><p>차원 축소의 개념</p>
</li>
<li><p>PCA개념</p>
</li>
<li><p>과일 사진의 경우, 10000개의 픽셀 (높이 * 너비)</p>
<ul>
<li>10000개의 특성이 있는 셈(차원)</li>
</ul>
</li>
<li><p>정형데이터에서도 활용 가능</p>
<ul>
<li>문자열 데이터, 수치형 데이터 (연속형 데이터, 비연속형 데이터)</li>
<li>캐글 대회: 수치형 데이터 304개<ul>
<li>연산은 RAM에서 처리</li>
<li>라면을 5개 끓여야하는데 냄비 크기는 3개분량의 크기인 상황</li>
</ul>
</li>
</ul>
</li>
<li><p>차원축소 &#x3D; 일부 특성을 선택하여 데이터 크기를 줄임</p>
</li>
<li><p>머신러닝 측면: 과대적합 방지 &amp; 성능 향상</p>
</li>
<li><p>양적 데이터 사이의 분산-공분산 관계를 이용해서 선형결합으로 표시되는 주성분을 찾음</p>
</li>
<li><p>2-3개의 주성분으로 전체 변동을 찾는것이 PCA</p>
</li>
<li><p>알고리즘 구성 할 때, 필요한 데이터 픽셀 수</p>
<ul>
<li>300* 10000개 픽셀</li>
<li>300 * PCA 10주성분으로 줄임</li>
<li>기존 1시간 걸리던게 10분으로 줄어듦</li>
<li>그럼에도 불구하고, 분류가 더 잘됨</li>
</ul>
</li>
</ul>
<h1 id="PCA-클래스"><a href="#PCA-클래스" class="headerlink" title="PCA 클래스"></a>PCA 클래스</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-03-31 06:16:41--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11
Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-03-31 06:16:41--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 140.82.114.4
Connecting to github.com (github.com)|140.82.114.4|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-03-31 06:16:41--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.02s   

2022-03-31 06:16:41 (169 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fruits = np.load(<span class="string">&#x27;fruits_300.npy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(fruits.shape)  <span class="comment"># fruits: 3차원 배열</span></span><br><span class="line">fruits_2d = fruits.reshape(-<span class="number">1</span>, <span class="number">100</span>*<span class="number">100</span>)</span><br><span class="line">fruits_2d.shape  <span class="comment"># fruits_2d: 2차원 배열</span></span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)





(300, 10000)
</code></pre>
<ul>
<li>sklaern.decomposition 모듈</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components= <span class="number">50</span>)</span><br><span class="line"><span class="comment"># PCA 50개 성분으로 300 * 10000픽셀값을 압축</span></span><br><span class="line">pca.fit(fruits_2d)</span><br></pre></td></tr></table></figure>




<pre><code>PCA(n_components=50)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pca.components_.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(50, 10000)
</code></pre>
<ul>
<li>그래프 그리기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_fruits</span>(<span class="params">arr, ratio=<span class="number">1</span></span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)    <span class="comment"># n은 샘플 개수입니다</span></span><br><span class="line">    <span class="comment"># 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. </span></span><br><span class="line">    rows = <span class="built_in">int</span>(np.ceil(n/<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.</span></span><br><span class="line">    cols = n <span class="keyword">if</span> rows &lt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">10</span></span><br><span class="line">    fig, axs = plt.subplots(rows, cols, </span><br><span class="line">                            figsize=(cols*ratio, rows*ratio), squeeze=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">            <span class="keyword">if</span> i*<span class="number">10</span> + j &lt; n:    <span class="comment"># n 개까지만 그립니다.</span></span><br><span class="line">                axs[i, j].imshow(arr[i*<span class="number">10</span> + j], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">            axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># draw_fruits(fruits[km.labels_ == 0])</span></span><br><span class="line">draw_fruits(pca.components_.reshape(-<span class="number">1</span>, <span class="number">100</span>, <span class="number">100</span>))</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_12_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_pca = pca.transform(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(fruits_pca.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 50)
</code></pre>
<ul>
<li>데이터의 원래 크기 대비해서 1&#x2F;200 줄임</li>
<li>용량이 줄었다는 것과 똑같음</li>
</ul>
<h1 id="원본-데이터-재구성"><a href="#원본-데이터-재구성" class="headerlink" title="원본 데이터 재구성"></a>원본 데이터 재구성</h1><ul>
<li>10000개의 특성을 50개로 줄임</li>
<li>100% 재구성은 어렵지만, 그래도 쓸만하다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inverse_transform(): 축소시킨 데이터를 다시 복원</span></span><br><span class="line">fruits_inverse = pca.inverse_transform(fruits_pca)</span><br><span class="line"><span class="built_in">print</span>(fruits_inverse.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 10000)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_reconstruct = fruits_inverse.reshape(-<span class="number">1</span>, <span class="number">100</span>, <span class="number">100</span>)  <span class="comment"># 다시 3차원으로 재배열</span></span><br><span class="line"><span class="built_in">print</span>(fruits_reconstruct.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>  start <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">100</span>, <span class="number">200</span>]:</span><br><span class="line">  draw_fruits(fruits_reconstruct[start:start+<span class="number">100</span>])</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_18_0.png" alt="png"></p>
<p><img src="/Images/0331_Principar_Component_Analysis_01/output_18_2.png" alt="png"></p>
<p><img src="/Images/0331_Principar_Component_Analysis_01/output_18_4.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ## 주성분을 2개로 지정했을때 나오는 형태</span></span><br><span class="line"><span class="comment"># pca = PCA(n_components= 2)</span></span><br><span class="line"><span class="comment"># pca.fit(fruits_2d)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fruits_pca = pca.transform(fruits_2d)</span></span><br><span class="line"><span class="comment"># # print(fruits_pca.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fruits_inverse = pca.inverse_transform(fruits_pca)</span></span><br><span class="line"><span class="comment"># # print(fruits_inverse.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fruits_reconstruct = fruits_inverse.reshape(-1, 100, 100)</span></span><br><span class="line"><span class="comment"># # print(fruits_reconstruct.shape)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># for  start in [0, 100, 200]:</span></span><br><span class="line"><span class="comment">#   draw_fruits(fruits_reconstruct[start:start+100])</span></span><br><span class="line"><span class="comment">#   print(&quot;\n&quot;)</span></span><br></pre></td></tr></table></figure>

<h1 id="설명된-분산"><a href="#설명된-분산" class="headerlink" title="설명된 분산"></a>설명된 분산</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># explained_variance_ratio_: 분산의 비율</span></span><br><span class="line">plt.plot(pca.explained_variance_ratio_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_21_0.png" alt="png"></p>
<ul>
<li>처음 10개의 주성분이 대부분의 분산을 표현한다.</li>
<li>11개 주성분부터 ~50개까지는 잘 설명이 안됨.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 92퍼센트정도 설명이 가능하다는걸 확인</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(pca.explained_variance_ratio_))</span><br></pre></td></tr></table></figure>

<pre><code>0.9215689086016662
</code></pre>
<h1 id="다른-알고리즘과-함께-사용하기"><a href="#다른-알고리즘과-함께-사용하기" class="headerlink" title="다른 알고리즘과 함께 사용하기"></a>다른 알고리즘과 함께 사용하기</h1><ul>
<li>3개의 과일 사진 분류 위해 로지스틱 회귀</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"></span><br><span class="line">target = np.array([<span class="number">0</span>]* <span class="number">100</span> + [<span class="number">1</span>]* <span class="number">100</span> + [<span class="number">2</span>]* <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br></pre></td></tr></table></figure>

<pre><code>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores = cross_validate(lr, fruits_2d, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9966666666666667
1.3491935729980469
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PCA 수행 후, 학습 시간 비교</span></span><br><span class="line">scores = cross_validate(lr, fruits_pca, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>1.0
0.023451614379882812
</code></pre>
<ul>
<li>주성분의 매개변수 개수 지정, 분산 비율 지정</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components= <span class="number">0.5</span>)</span><br><span class="line">pca.fit(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(pca.n_components_)</span><br></pre></td></tr></table></figure>

<pre><code>2
</code></pre>
<ul>
<li>주성분을 2개로 압축</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_pca = pca.transform(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(fruits_pca.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 2)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_validate(lr, fruits_pca, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9933333333333334
0.03700056076049805


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">km = KMeans(n_clusters=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">km.fit(fruits_pca)</span><br><span class="line"><span class="built_in">print</span>(np.unique(km.labels_, return_counts=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<pre><code>(array([0, 1, 2], dtype=int32), array([110,  99,  91]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">  draw_fruits(fruits[km.labels_== label])</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;/n&quot;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_34_0.png" alt="png"></p>
<pre><code>/n
</code></pre>
<p><img src="/Images/0331_Principar_Component_Analysis_01/output_34_2.png" alt="png"></p>
<pre><code>/n
</code></pre>
<p><img src="/Images/0331_Principar_Component_Analysis_01/output_34_4.png" alt="png"></p>
<pre><code>/n
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">  data = fruits_pca[km.labels_== label]</span><br><span class="line">  plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>])</span><br><span class="line">plt.legend([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;pineapple&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_35_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>차원 축소: 원본 데이터의 특성을 적은 수의 새로운 특성으로 변환하는 비지도 학습의 한 종류. 저장공간을 줄이고 시각화 하기 쉽다. 다른 알고리즘의 성능을 높임.</li>
<li>주성분 분석: 차원 축소의 알고리즘의 하나로 데이터에서 가장 분산이 큰 방향을 찾는 방법</li>
<li>설명된 분석: 주성분 분석에서 주성분이 얼마나 원본 데이터의 분산을 잘 나타내는지 기록한것</li>
</ul>
</li>
<li>Scikit-learn 패키지<ul>
<li>PCA: 주성분 분석을 수행하는 클래스<ul>
<li>n_components: 주성분의 개수를 지정 [default: None](샘플 개수와 특성 개수중에서 작은 것의 값을 사용)</li>
<li>random_state: 넘파이 난수 시드값을 지정</li>
<li>속성 components_: 훈련세트에서 찾은 주성분이 저장</li>
<li>속성 explained_variance_ : 설명된 분산이 저장</li>
<li>속성 explained_variance_ratio_: 설명된 분산의 비율이 저장</li>
<li>inverse_transform(): transfrom()메서드로 차원을 축소시킨 데이터를 다시 원본 차원으로 복원함.</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/31/0331_Principar_Component_Analysis_01/" data-id="cl1ewiwzi0000d0nh12tud94l" data-title="주성분_분석_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0331_Unsupervised_Learning" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/31/0331_Unsupervised_Learning/" class="article-date">
  <time class="dt-published" datetime="2022-03-31T00:00:00.000Z" itemprop="datePublished">2022-03-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/31/0331_Unsupervised_Learning/">비지도_학습_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="비지도-학습"><a href="#비지도-학습" class="headerlink" title="비지도 학습"></a>비지도 학습</h1><ul>
<li>vs 지도학습</li>
<li>종속변수 &#x3D; 타겟</li>
<li>비짇 학습은 종속변수 및 타겟이 없음</li>
<li>분류<ul>
<li>다중분류</li>
<li>전제조건이 (다양한 유형) 데이터가 많아야 함</li>
<li>딥러닝과 연관이 됨 (자연어 처리, 이미지)</li>
</ul>
</li>
</ul>
<h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-03-31 01:10:43--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10
Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-03-31 01:10:43--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 140.82.112.3
Connecting to github.com (github.com)|140.82.112.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-03-31 01:10:43--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.01s   

2022-03-31 01:10:43 (210 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<ul>
<li>numpy 파일을 불러옴</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fruits = np.load(<span class="string">&#x27;fruits_300.npy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(fruits.shape)</span><br><span class="line"><span class="built_in">print</span>(fruits.ndim)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)
3
</code></pre>
<ul>
<li>첫번째 차원 &#x3D; 샘플의 개수</li>
<li>두번째 차원 &#x3D; 이미지 높이</li>
<li>세번째 차원 &#x3D; 이미지 넓이</li>
<li>이미지 크기 100 * 100</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fruits[<span class="number">0</span>, <span class="number">0</span>, :]</span><br></pre></td></tr></table></figure>




<pre><code>array([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,
         1,   1,   1,   2,   1,   2,   2,   2,   2,   2,   2,   1,   1,
         1,   1,   1,   1,   1,   1,   2,   3,   2,   1,   2,   1,   1,
         1,   1,   2,   1,   3,   2,   1,   3,   1,   4,   1,   2,   5,
         5,   5,  19, 148, 192, 117,  28,   1,   1,   2,   1,   4,   1,
         1,   3,   1,   1,   1,   1,   1,   2,   2,   1,   1,   1,   1,
         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,
         1,   1,   1,   1,   1,   1,   1,   1,   1], dtype=uint8)
</code></pre>
<ul>
<li>이미지 시각화<ul>
<li>흑백사진을 담고 있다.</li>
<li>0 ~ 255까지의 정수값을 가진다.<ul>
<li>0에 가까우면 검게 나타남</li>
<li>255에 가까우면 밝게 나타남</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(fruits[<span class="number">0</span>], cmap= <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<pre><code>/Images/0331_Unsupervised_Learning
</code></pre>
<p><img src="/Images/0331_Unsupervised_Learning/output_8_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cmap = &#x27;gray_r&#x27; 일 경우 반대로 나타남</span></span><br><span class="line">plt.imshow(fruits[<span class="number">0</span>], cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_9_0.png" alt="png"></p>
<ul>
<li>여러 이미지 시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">axs[<span class="number">0</span>].imshow(fruits[<span class="number">100</span>], cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].imshow(fruits[<span class="number">200</span>], cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_11_0.png" alt="png"></p>
<h1 id="픽셀값-분석"><a href="#픽셀값-분석" class="headerlink" title="픽셀값 분석"></a>픽셀값 분석</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">apple = fruits[<span class="number">0</span>: <span class="number">100</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)</span><br><span class="line">pineapple = fruits[<span class="number">100</span>: <span class="number">200</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)</span><br><span class="line">banana = fruits[<span class="number">200</span>: <span class="number">300</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(apple.shape, banana.shape, pineapple.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(100, 10000) (100, 10000) (100, 10000)
</code></pre>
<ul>
<li><p>axis &#x3D; 0 vs axis &#x3D; 1 차이 확인(p,293)</p>
</li>
<li><p>각 이미지에 대한 픽셀 평균값 비교</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># axis= 1  : 행 기준</span></span><br><span class="line"><span class="built_in">print</span>(apple.mean(axis= <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[ 88.3346  97.9249  87.3709  98.3703  92.8705  82.6439  94.4244  95.5999
  90.681   81.6226  87.0578  95.0745  93.8416  87.017   97.5078  87.2019
  88.9827 100.9158  92.7823 100.9184 104.9854  88.674   99.5643  97.2495
  94.1179  92.1935  95.1671  93.3322 102.8967  94.6695  90.5285  89.0744
  97.7641  97.2938 100.7564  90.5236 100.2542  85.8452  96.4615  97.1492
  90.711  102.3193  87.1629  89.8751  86.7327  86.3991  95.2865  89.1709
  96.8163  91.6604  96.1065  99.6829  94.9718  87.4812  89.2596  89.5268
  93.799   97.3983  87.151   97.825  103.22    94.4239  83.6657  83.5159
 102.8453  87.0379  91.2742 100.4848  93.8388  90.8568  97.4616  97.5022
  82.446   87.1789  96.9206  90.3135  90.565   97.6538  98.0919  93.6252
  87.3867  84.7073  89.1135  86.7646  88.7301  86.643   96.7323  97.2604
  81.9424  87.1687  97.2066  83.4712  95.9781  91.8096  98.4086 100.7823
 101.556  100.7027  91.6098  88.8976]
</code></pre>
<ul>
<li>각 과일에 대한 히스토그램</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="comment"># ax.hist(np.mean(apple, axis= 1), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(banana, axis= 1), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(pineapple, axis= 1), alpha= 0.8)</span></span><br><span class="line"></span><br><span class="line">ax.hist(apple.mean(axis= <span class="number">1</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line">ax.hist(pineapple.mean(axis= <span class="number">1</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line">ax.hist(banana.mean(axis= <span class="number">1</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line"><span class="comment"># ax.hist(np.mean(apple, axis= 0), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(banana, axis= 0), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(pineapple, axis= 0), alpha= 0.8)</span></span><br><span class="line"></span><br><span class="line">ax.legend([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;pineapple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_18_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="comment"># ax.hist(np.mean(apple, axis= 1), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(banana, axis= 1), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(pineapple, axis= 1), alpha= 0.8)</span></span><br><span class="line"></span><br><span class="line">ax.hist(np.mean(apple, axis= <span class="number">0</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line">ax.hist(np.mean(banana, axis= <span class="number">0</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line">ax.hist(np.mean(pineapple, axis= <span class="number">0</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">ax.legend([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;pineapple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_19_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize= (<span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line">axs[<span class="number">0</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(apple, axis= <span class="number">0</span>))</span><br><span class="line">axs[<span class="number">1</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(pineapple, axis= <span class="number">0</span>))</span><br><span class="line">axs[<span class="number">2</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(banana, axis= <span class="number">0</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_20_0.png" alt="png"></p>
<ul>
<li>대표 이미지</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apple_mean = np.mean(apple, axis= <span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">pineapple_mean = np.mean(pineapple, axis= <span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">banana_mean = np.mean(banana, axis= <span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize= (<span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line">axs[<span class="number">0</span>].imshow(apple_mean, cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].imshow(pineapple_mean, cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">2</span>].imshow(banana_mean, cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line"><span class="comment"># axs[3].imshow(apple_mean, cmap= &#x27;gray_r&#x27;)</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_22_0.png" alt="png"></p>
<h1 id="평균값과-가까운-사진-고르기"><a href="#평균값과-가까운-사진-고르기" class="headerlink" title="평균값과 가까운 사진 고르기"></a>평균값과 가까운 사진 고르기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">abs_diff = np.<span class="built_in">abs</span>(fruits- apple_mean)</span><br><span class="line">abs_mean = np.mean(abs_diff, axis=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(abs_mean.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300,)
</code></pre>
<ul>
<li>오차의 값이 가장 작은 순서대로 100개를 골라본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apple_index = np.argsort(abs_mean)[:<span class="number">100</span>]</span><br><span class="line">fig, axs= plt.subplots(<span class="number">10</span>, <span class="number">10</span>, figsize= (<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    axs[i, j].imshow(fruits[apple_index[i*<span class="number">10</span> + j]], cmap= <span class="string">&#x27;gray_r&#x27;</span>)  <span class="comment"># imshow(): 크기에 맞게 이미지 출력</span></span><br><span class="line">    axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)  <span class="comment"># 축 지우기</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_26_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">3</span>, figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># axs[0].imshow(apple_mean, cmap= &#x27;gray_r&#x27;) </span></span><br><span class="line"><span class="comment"># axs[1].imshow(pineapple_mean, cmap= &#x27;gray_r&#x27;)</span></span><br><span class="line"><span class="comment"># axs[2].imshow(banana_mean, cmap= &#x27;gray_r&#x27;)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fig, axs = plt.subplots()</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_27_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>비지도 학습: 머신러닝의 한 종류로 훈련 데이터에 타깃이 없음. 타깃이 없기 때문에 외부의 도움 없이 스스로 유용한 무언가를 학습해야함.</li>
<li>히스토그램: 구간별로 값이 발생한 빈도를 그래프로 표시</li>
<li>군집: 비슷한 샘플끼리 하나의 그룹으로 모으는 대표적인 비지도 학습 작업</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/31/0331_Unsupervised_Learning/" data-id="cl1ewiwzv0001d0nhfboydkj9" data-title="비지도_학습_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0331_K_Means_01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/31/0331_K_Means_01/" class="article-date">
  <time class="dt-published" datetime="2022-03-31T00:00:00.000Z" itemprop="datePublished">2022-03-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/31/0331_K_Means_01/">K-평균_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="K-평균"><a href="#K-평균" class="headerlink" title="K-평균"></a>K-평균</h1><ul>
<li><p>각각의 픽셀값 (3차원 -&gt; 1차원 배열) 평균 구함</p>
<ul>
<li>픽셀의 평균값을 활용해서 사과, 바나나, 파인애플에 근사한 이미지를 추출하는 것</li>
</ul>
</li>
<li><p>어떻게 평균값을 구할 수 있을까?</p>
<ul>
<li>K-평균 알고리즘(K-Means) 알고리즘</li>
<li>평균값 &#x3D; Cluster Center &#x3D; Centroid</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-03-31 02:14:27--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10
Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-03-31 02:14:27--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 140.82.114.3
Connecting to github.com (github.com)|140.82.114.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-03-31 02:14:28--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.07s   

2022-03-31 02:14:28 (43.0 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fruits = np.load(<span class="string">&#x27;fruits_300.npy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(fruits.shape)</span><br><span class="line"><span class="built_in">print</span>(fruits.ndim)  <span class="comment"># ndim: n차원인지 알아냄</span></span><br><span class="line"><span class="comment"># print(fruits[:5])</span></span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)
3
</code></pre>
<ul>
<li>3차원 (샘플개수, 넓이, 높이)</li>
<li>2차원 (샘플개수, 넓이* 높이)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_2d = fruits.reshape(-<span class="number">1</span>, <span class="number">100</span>* <span class="number">100</span>)</span><br><span class="line">fruits_2d.shape</span><br></pre></td></tr></table></figure>




<pre><code>(300, 10000)
</code></pre>
<ul>
<li>K-평균 알고리즘 활용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">km = KMeans(n_clusters= <span class="number">3</span>, random_state= <span class="number">42</span>)</span><br><span class="line">km.fit(fruits_2d)</span><br></pre></td></tr></table></figure>




<pre><code>KMeans(n_clusters=3, random_state=42)
</code></pre>
<ul>
<li>모형학습 후, labels 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(km.labels_)</span><br></pre></td></tr></table></figure>

<pre><code>[2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1]
</code></pre>
<ul>
<li>직접 샘플의 개수 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.unique(km.labels_, return_counts= <span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<pre><code>(array([0, 1, 2], dtype=int32), array([111,  98,  91]))
</code></pre>
<ul>
<li>그래프를 그려본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_fruits</span>(<span class="params">arr, ratio=<span class="number">1</span></span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)    <span class="comment"># n은 샘플 개수입니다</span></span><br><span class="line">    <span class="comment"># 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. </span></span><br><span class="line">    rows = <span class="built_in">int</span>(np.ceil(n/<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.</span></span><br><span class="line">    cols = n <span class="keyword">if</span> rows &lt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">10</span></span><br><span class="line">    fig, axs = plt.subplots(rows, cols, </span><br><span class="line">                            figsize=(cols*ratio, rows*ratio), squeeze=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">            <span class="keyword">if</span> i*<span class="number">10</span> + j &lt; n:    <span class="comment"># n 개까지만 그립니다.</span></span><br><span class="line">                axs[i, j].imshow(arr[i*<span class="number">10</span> + j], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">            axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_fruits(fruits[km.labels_ == <span class="number">0</span>])</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_K_Means_01/output_14_0.png" alt="png"></p>
<h1 id="크러스터-중심"><a href="#크러스터-중심" class="headerlink" title="크러스터 중심"></a>크러스터 중심</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_fruits(km.cluster_centers_.reshape(-<span class="number">1</span>, <span class="number">100</span>, <span class="number">100</span>), ratio= <span class="number">3</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_K_Means_01/output_16_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(km.transform(fruits_2d[<span class="number">100</span>:<span class="number">101</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[[3393.8136117  8837.37750892 5267.70439881]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(km.predict(fruits_2d[<span class="number">100</span>:<span class="number">101</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_fruits(fruits[<span class="number">100</span>:<span class="number">101</span>])</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_K_Means_01/output_19_0.png" alt="png"></p>
<h1 id="최적의-K-찾기"><a href="#최적의-K-찾기" class="headerlink" title="최적의 K 찾기"></a>최적의 K 찾기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inertia= []</span></span><br><span class="line"><span class="comment"># for k in range(2,7):</span></span><br><span class="line"><span class="comment">#   km= KMeans(n_clusters= k, random_state= 42)</span></span><br><span class="line"><span class="comment">#   km.fit(fruits_2d)</span></span><br><span class="line"><span class="comment">#   inertia.append(km.inertia_)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.plot(range(2,7), inertia)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">inertia= []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,<span class="number">7</span>):</span><br><span class="line">  km= KMeans(n_clusters= k, random_state= <span class="number">42</span>)</span><br><span class="line">  km.fit(fruits_2d)</span><br><span class="line">  inertia.append(km.inertia_)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(<span class="built_in">range</span>(<span class="number">2</span>,<span class="number">7</span>), inertia)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_K_Means_01/output_22_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>K-평균: 처음에 랜덤하게 클러스터 중심을 정하고 클러스터를 만듬. 그 후에 클러스터의 중심을 이동하고 다시 클러스터를 만드는 식으로 반복해서 최적의 클러스터를 구성하는 알고리즘.</li>
<li>클러스터 중심: K-평균 알고리즘이 만든 클러스터에 속한 샘플의 특성 평균값. 센트로이드라고도 부름</li>
<li>엘보우 방법: 최적의 클러스터 개수를 정하는 방법 중 하나</li>
</ul>
</li>
<li>Scikit-Learn 패키지<ul>
<li>KMeans: K-평균 알고리즘 클래스<ul>
<li>n_clusters: 클러스터 개수를 지정. [default: 8]</li>
<li>n_init: 반복 횟수를 지정. [default: 10]</li>
<li>max_iter: K-평균 알고리즘의 한 번 실행에서 최적의 센트로이드를 찾기 위해 반복 할 수 있는 최대 횟수. [default: 200]</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/31/0331_K_Means_01/" data-id="cl1ewiwzw0002d0nhgzdzcf01" data-title="K-평균_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0330_Cross_Validation01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/30/0330_Cross_Validation01/" class="article-date">
  <time class="dt-published" datetime="2022-03-30T00:00:00.000Z" itemprop="datePublished">2022-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/30/0330_Cross_Validation01/">교차검증과_랜덤서치_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="교차-검증과-그리드-서치"><a href="#교차-검증과-그리드-서치" class="headerlink" title="교차 검증과 그리드 서치"></a>교차 검증과 그리드 서치</h1><ul>
<li>키워드: 하이퍼 파라미터</li>
<li>데이터가 작을 때, 주로 사용</li>
<li>하이퍼 파라미터<ul>
<li>max_depth: 3일때, 정확도가 84%</li>
</ul>
</li>
<li>결론<ul>
<li>모르면 default만 쓸것</li>
<li>가성비 (시간 대비 성능 보장 안됨)</li>
</ul>
</li>
</ul>
<h1 id="검증-세트"><a href="#검증-세트" class="headerlink" title="검증 세트"></a>검증 세트</h1><ul>
<li>테스트 세트 (1회성)</li>
<li>훈련 데이터를 훈련데이터 + 검증 데이터로 재분할</li>
</ul>
<h2 id="현실"><a href="#현실" class="headerlink" title="현실"></a>현실</h2><ul>
<li>테스트 데이터가 별도로 존재안함</li>
<li>ex) 전체 데이터 &#x3D; 훈련(6) : 검증(2) : 테스트(2)<ul>
<li>테스트 데이터는 모르는 데이터로 간주</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&quot;https://bit.ly/wine_csv_data&quot;</span>)</span><br><span class="line"></span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target= wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br><span class="line">wine.head()</span><br></pre></td></tr></table></figure>





  <div id="df-7bbb17c4-c2ff-4a49-b897-7cc39b6d3337">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.8</td>
      <td>2.6</td>
      <td>3.20</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9.8</td>
      <td>2.3</td>
      <td>3.26</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9.8</td>
      <td>1.9</td>
      <td>3.16</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7bbb17c4-c2ff-4a49-b897-7cc39b6d3337')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-7bbb17c4-c2ff-4a49-b897-7cc39b6d3337 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-7bbb17c4-c2ff-4a49-b897-7cc39b6d3337&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size= <span class="number">0.2</span>, random_state= <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(5197, 3) (1300, 3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train 데이터의 20%를 val 데이터로 분류</span></span><br><span class="line">sub_input, val_input, sub_target, val_target = train_test_split(</span><br><span class="line">    train_input, train_target, test_size= <span class="number">0.2</span>, random_state= <span class="number">42</span>  <span class="comment"># random_state: 추출값 고정이 목적</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(sub_input.shape, val_input.shape, val_target.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(4157, 3) (1040, 3) (1040,)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(sub_input, sub_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(sub_input, sub_target))  <span class="comment"># 0.9971133028626413</span></span><br><span class="line"><span class="built_in">print</span>(dt.score(val_input, val_target))  <span class="comment"># 0.864423076923077</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9971133028626413
0.864423076923077
</code></pre>
<h1 id="교차검증"><a href="#교차검증" class="headerlink" title="교차검증"></a>교차검증</h1><ul>
<li>교차검증의 목적: 좋은 모델이 만들어진다!<ul>
<li>좋은 모델 &#x3D; 과대적합이 아닌 모델 &#x3D; 모형의 오차가 적은 모델 &#x3D; 안정적인 모델</li>
<li>성능 좋은 모델이 좋은 모델이란게 아님</li>
</ul>
</li>
<li>교재 245p<ul>
<li>모델평가1: 90% (소요시간: 1시간)</li>
<li>모델평가2: 85%</li>
<li>모델평가3: 80%</li>
</ul>
</li>
<li>단점: 시간이 오래 걸림</li>
</ul>
<h1 id="교차검증-함수"><a href="#교차검증-함수" class="headerlink" title="교차검증 함수"></a>교차검증 함수</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores = cross_validate(dt, train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.0083735 , 0.00927544, 0.00848556, 0.00817442, 0.00816131]), &#39;score_time&#39;: array([0.00126314, 0.00097775, 0.00073361, 0.00077486, 0.00080872]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125;
</code></pre>
<ul>
<li>최종점수 평균 구하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.855300214703487
</code></pre>
<ul>
<li>훈련 세트 섞은 후, 10-폴드 교차검증</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line">splitter = StratifiedKFold(n_splits = <span class="number">10</span>, shuffle = <span class="literal">True</span>, random_state = <span class="number">42</span>)</span><br><span class="line">scores = cross_validate(dt, train_input, train_target, cv= splitter)</span><br><span class="line"><span class="built_in">print</span>(scores[<span class="string">&#x27;test_score&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[0.84807692 0.89423077 0.87115385 0.85576923 0.86346154 0.87884615
 0.87692308 0.86319846 0.87668593 0.87475915]
0.8703105083740921
</code></pre>
<h1 id="하이퍼파라미터-튜닝"><a href="#하이퍼파라미터-튜닝" class="headerlink" title="하이퍼파라미터 튜닝"></a>하이퍼파라미터 튜닝</h1><ul>
<li>그리드 서치 vs 랜덤 서치</li>
<li>꼭 사용하고 싶다면 -&gt; 랜덤 서치 사용</li>
<li>자동으로 잡아주는 라이브러리 등장<ul>
<li>hyperopt 등등…</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.core.common <span class="keyword">import</span> random_state</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">params = &#123;<span class="string">&#x27;min_impurity_decrease&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>],</span><br><span class="line">          <span class="comment"># &#x27;max_depth&#x27;: [3, 4, 5, 6, 7]</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># dt = DecisionTreeClassifier(random_state= 42)</span></span><br><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>),params, n_jobs= -<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,
             param_grid=&#123;&#39;min_impurity_decrease&#39;: [0.0001, 0.0002, 0.0003,
                                                   0.0004, 0.0005]&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt= gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_input, train_target))</span><br><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>

<pre><code>DecisionTreeClassifier(min_impurity_decrease=0.0001, random_state=42)
0.9615162593804117
&#123;&#39;min_impurity_decrease&#39;: 0.0001&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]
</code></pre>
<h1 id="랜덤서치"><a href="#랜덤서치" class="headerlink" title="랜덤서치"></a>랜덤서치</h1><ul>
<li>매개변수 값의 목록을 전달하는것이 아니라 매개변수를 샘플링 할 수 있도록 확률 분포 객체를 전달</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># scipy라이브러리: 적분, 보간, 선형대수, 확률 등을 포함한 수치 계산 전용으로 파이썬의 핵심 과학 라이브러리</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> uniform, randint  <span class="comment"># randint: 정수값을 뽑음,  uniform: 실수값을 뽑음.</span></span><br><span class="line">rgen = randint(<span class="number">0</span>,<span class="number">10</span>)</span><br><span class="line">rgen.rvs(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 4, 9, 5, 9, 9, 1, 0, 2, 1])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.unique(rgen.rvs(<span class="number">1000</span>), return_counts= <span class="literal">True</span>)  <span class="comment"># 각각 추출된 숫자의 갯수</span></span><br></pre></td></tr></table></figure>




<pre><code>(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
 array([ 99, 116,  90,  99,  87, 118, 104, 101,  81, 105]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ugen= uniform(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">ugen.rvs(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([0.4111007 , 0.57571785, 0.55554775, 0.58827729, 0.92876842,
       0.98869391, 0.87016065, 0.51721186, 0.54686086, 0.97925777])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span>: uniform(<span class="number">0.0001</span>, <span class="number">0.001</span>),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: randint(<span class="number">20</span>, <span class="number">50</span>),</span><br><span class="line">    <span class="string">&#x27;min_samples_split&#x27;</span>: randint(<span class="number">2</span>, <span class="number">25</span>),</span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: randint(<span class="number">1</span>, <span class="number">25</span>),&#125;</span><br><span class="line">gs = RandomizedSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>), params,  <span class="comment"># n_iter: 파라미터 검색 횟수</span></span><br><span class="line">                        n_iter= <span class="number">100</span>, n_jobs= -<span class="number">1</span>, random_state= <span class="number">42</span>)  <span class="comment"># n_jobs: cpu코어 수</span></span><br><span class="line"></span><br><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42),
                   n_iter=100, n_jobs=-1,
                   param_distributions=&#123;&#39;max_depth&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6ec0604a90&gt;,
                                        &#39;min_impurity_decrease&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6ec0604910&gt;,
                                        &#39;min_samples_leaf&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6ec0604e90&gt;,
                                        &#39;min_samples_split&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6ec0604a50&gt;&#125;,
                   random_state=42)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)  <span class="comment"># 최고의 교차검증 점수</span></span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;max_depth&#39;: 39, &#39;min_impurity_decrease&#39;: 0.00034102546602601173, &#39;min_samples_leaf&#39;: 7, &#39;min_samples_split&#39;: 13&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 검증 점수</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">max</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8695428296438884
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 테스트 세트로 성능 확인</span></span><br><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_input, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.86
</code></pre>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li><p>키워드</p>
<ul>
<li>검증세트: 하이퍼파라미터 튜닝을 위해 모델을 평가 할 때, 테스트 세트를 사용하지 않기 위해 훈련세트에서 다시 떼어 낸 데이터 세트</li>
<li>교차검증: 훈련세트를 여러 폴드로 나눈 다음 한 폴드가 검증 세트의 역할을 하고 나머지 폴드에서는 모델을 훈련</li>
<li>그리드 서치: 하이퍼파라미터 탐색을 자동화해주는 도구. 탐색할 매개변수를 나열하면 교차 거증을 수행하여 가장 좋은 검증 점수의 매개변수 조합을 선택. 이 매개변수 조합으로 최종 모델을 훈련</li>
<li>랜덤 서치: 연속된 매개변수 값을 탐색할 때 유용함. 탐색할 값을 직접 나열하는것이 아니고 탐색값을 샘플링 할 수 있는 확률 분포 객체를 전달</li>
</ul>
</li>
<li><p>Scikit-learn 패키지</p>
<ul>
<li>crpss_va;odate(): 교차 검증을 수행하는 함수</li>
<li>GridSerchCV: 교차검증으로 하이퍼파라미터 탐색을 수행</li>
<li>RandomizedSearchCV: 교차검증으로 랜덤한 하이퍼파라미터 탐색을 수행</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/30/0330_Cross_Validation01/" data-id="cl1dhk3ww0000hknhb8ob3ee9" data-title="교차검증과_랜덤서치_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0330_Decision_Tree_01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/30/0330_Decision_Tree_01/" class="article-date">
  <time class="dt-published" datetime="2022-03-30T00:00:00.000Z" itemprop="datePublished">2022-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/30/0330_Decision_Tree_01/">결정_트리_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><ul>
<li>와인데이터<ul>
<li>alcohol(알코올 도수), sugar(당도), pH(산도), class(0&#x3D; 레드 와인, 1&#x3D; 화이트 와인)</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&quot;https://bit.ly/wine_csv_data&quot;</span>)</span><br><span class="line">wine.head()</span><br></pre></td></tr></table></figure>





  <div id="df-3ff52dca-19e0-496c-b891-4e13de664c47">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.8</td>
      <td>2.6</td>
      <td>3.20</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9.8</td>
      <td>2.3</td>
      <td>3.26</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9.8</td>
      <td>1.9</td>
      <td>3.16</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-3ff52dca-19e0-496c-b891-4e13de664c47')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-3ff52dca-19e0-496c-b891-4e13de664c47 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-3ff52dca-19e0-496c-b891-4e13de664c47&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;/Images/0330_Decision_Tree_01/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<ul>
<li>info()<ul>
<li>결측치 확인 &#x2F; 변수 타입</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 6497 entries, 0 to 6496
Data columns (total 4 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   alcohol  6497 non-null   float64
 1   sugar    6497 non-null   float64
 2   pH       6497 non-null   float64
 3   class    6497 non-null   float64
dtypes: float64(4)
memory usage: 203.2 KB
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine.describe()  <span class="comment"># 간단한 통계를 출력</span></span><br></pre></td></tr></table></figure>





  <div id="df-187f8402-85e9-484f-9ccb-82e7f257f44a">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>10.491801</td>
      <td>5.443235</td>
      <td>3.218501</td>
      <td>0.753886</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.192712</td>
      <td>4.757804</td>
      <td>0.160787</td>
      <td>0.430779</td>
    </tr>
    <tr>
      <th>min</th>
      <td>8.000000</td>
      <td>0.600000</td>
      <td>2.720000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>9.500000</td>
      <td>1.800000</td>
      <td>3.110000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>10.300000</td>
      <td>3.000000</td>
      <td>3.210000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>11.300000</td>
      <td>8.100000</td>
      <td>3.320000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>14.900000</td>
      <td>65.800000</td>
      <td>4.010000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-187f8402-85e9-484f-9ccb-82e7f257f44a')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-187f8402-85e9-484f-9ccb-82e7f257f44a button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-187f8402-85e9-484f-9ccb-82e7f257f44a&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;/Images/0330_Decision_Tree_01/output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<h1 id="표준화-작업"><a href="#표준화-작업" class="headerlink" title="표준화 작업"></a>표준화 작업</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()  <span class="comment"># &#x27;alcohol&#x27;, &#x27;sugar&#x27;, &#x27;pH&#x27;기준으로 재배열</span></span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()  <span class="comment"># &#x27;class&#x27;기준으로 재배열</span></span><br></pre></td></tr></table></figure>

<h1 id="훈련데이터와-테스트데이터로-분리"><a href="#훈련데이터와-테스트데이터로-분리" class="headerlink" title="훈련데이터와 테스트데이터로 분리"></a>훈련데이터와 테스트데이터로 분리</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size= <span class="number">0.2</span>, random_state= <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(5197, 3) (1300, 3)
</code></pre>
<ul>
<li>표준화 진행</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss= StandardScaler()</span><br><span class="line">ss.fit(train_input)  <span class="comment"># 변환 전 훈련시키기</span></span><br><span class="line">train_scaled= ss.transform(train_input)</span><br><span class="line">test_scaled= ss.transform(test_input)</span><br></pre></td></tr></table></figure>

<h1 id="모델-만들기"><a href="#모델-만들기" class="headerlink" title="모델 만들기"></a>모델 만들기</h1><h2 id="로지스틱회귀"><a href="#로지스틱회귀" class="headerlink" title="로지스틱회귀"></a>로지스틱회귀</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled, train_target))  <span class="comment"># 0.7808350971714451</span></span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled, test_target))  <span class="comment"># 0.7776923076923077</span></span><br><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)  <span class="comment"># lr.coef_: 기울기, lr.intercept_: 절편</span></span><br></pre></td></tr></table></figure>

<pre><code>0.7808350971714451
0.7776923076923077
[[ 0.51270274  1.6733911  -0.68767781]] [1.81777902]
</code></pre>
<h1 id="의사결정트리"><a href="#의사결정트리" class="headerlink" title="의사결정트리"></a>의사결정트리</h1><ul>
<li><p>1975년도 등장</p>
</li>
<li><p>다양한 산업에서 많이 쓰임</p>
</li>
<li><p>2001년즈음 랜덤 포레스트</p>
<ul>
<li>캐글대회</li>
<li>2017~2018년까지 정형데이터 대회는 랜덤포래스트가 메인 이론인적이 있었음.</li>
</ul>
</li>
</ul>
<h1 id="로지스틱-회귀"><a href="#로지스틱-회귀" class="headerlink" title="로지스틱 회귀"></a>로지스틱 회귀</h1><ul>
<li><p>수식</p>
</li>
<li><p>의사결정트리의 기본 알고리즘을 활용해서 MS, 구글 등 이런 회사들이 신규 알고리즘을 만듬.</p>
</li>
<li><p>XGBoost, LightGBM, CatBoost</p>
</li>
<li><p>캐글 정형데이터<br>  LIghtGBM (지금 현재 실무에서 많이 쓰임)</p>
</li>
<li><p>4월 말까지는 코드에 집중, 대회 나감</p>
</li>
<li><p>PPT (알고리즘 소개)</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))  <span class="comment"># 0.996921300750433</span></span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))  <span class="comment"># 0.8592307692307692</span></span><br></pre></td></tr></table></figure>

<pre><code>0.996921300750433
0.8592307692307692
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 객체지향으로 불가</span></span><br><span class="line"><span class="comment"># 결정트리 모델</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plot_tree(dt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<pre><code>/Images/0330_Decision_Tree_01/
</code></pre>
<p><img src="/Images/0330_Decision_Tree_01/output_15_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize= (<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt, max_depth= <span class="number">1</span>, filled= <span class="literal">True</span>,  <span class="comment"># max_depth: 최대깊이 ,  filled: 색 입히는 매개변수</span></span><br><span class="line">          feature_names=[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0330_Decision_Tree_01/output_16_0.png" alt="png"></p>
<h1 id="가지치기"><a href="#가지치기" class="headerlink" title="가지치기"></a>가지치기</h1><ul>
<li>과대적합을 방지하기 위한 것</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(max_depth=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))</span><br><span class="line"><span class="comment"># 비슷하게 나오는 결과를 확인 할 수 있음.</span></span><br></pre></td></tr></table></figure>

<pre><code>0.8454877814123533
0.8415384615384616
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy.ma.core <span class="keyword">import</span> filled</span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">15</span>))</span><br><span class="line">plot_tree(dt, filled= <span class="literal">True</span>, feature_names=[<span class="string">&#x27;alchol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0330_Decision_Tree_01/output_19_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># graph.render(&quot;decision_tree_graphivz&quot;)</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap, to_rgb</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">15</span>))</span><br><span class="line">artists = plot_tree(dt, filled = <span class="literal">True</span>, </span><br><span class="line">          feature_names = [<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> artist, impurity, value <span class="keyword">in</span> <span class="built_in">zip</span>(artists, dt.tree_.impurity, dt.tree_.value):</span><br><span class="line">    r, g, b = to_rgb(colors[np.argmax(value)])</span><br><span class="line">    f = impurity * <span class="number">2</span></span><br><span class="line">    artist.get_bbox_patch().set_facecolor((f + (<span class="number">1</span>-f)*r, f + (<span class="number">1</span>-f)*g, f + (<span class="number">1</span>-f)*b))</span><br><span class="line">    artist.get_bbox_patch().set_edgecolor(<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0330_Decision_Tree_01/output_21_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>결정 트리: yes &#x2F; no 에 대한 질무능ㄹ 이어나가면서 정답을 찾아 학습하는 알고리즘. 성능이 뛰어남.</li>
<li>불순도: 결정트리가 최적의 질문을 찾기 위한 기준. (사이킷런은 지니 불순도와 엔트로피 불순도를 제공)</li>
<li>정보이득: 부모 노드와 자식 노드의 불순도 차이</li>
<li>가지치기: 결정트리의 성장을 제한하는 방법</li>
<li>특성중요도: 결정트리에 사용된 특성이 불순도를 감소하는데 기여한 정도를 나타내는 값</li>
</ul>
</li>
<li>Pandas 패키지<ul>
<li>info(): 데이터프레임의 요약된 정보를 출력. 결측치가 있는지 알기위해 사용</li>
<li>describe(): 데이터 프레임 열의 통계 값을 제공</li>
</ul>
</li>
<li>Scikit-learn 패키지<ul>
<li>DecisionTreeClassifier: 결정트리 분류 클래스.<ul>
<li>매개변수 criterion: 불순도를 지정 [default: gini]</li>
<li>매개변수 splitter: 노트를 분할하는 전략을 선택 [defalt: best]</li>
<li>max_depth: 트리가 성장 할 최대 깊이를 지정 [defalt: None]</li>
<li>min_samples_split: 노드를 나누기 위한 최소 샘플 개수 [default: 2]</li>
<li>매개변수 max_features: 최적의 분할을 위해 탐색 할 특성의 개수를 지정. [defalt: None]</li>
</ul>
</li>
<li>plot_tree(): 결정 트리 모델을 시각화<ul>
<li>매개변수 max_depth: 나타낼 트리의 깊이를 지정. [defalt: None]</li>
<li>매개변수 feature_names: 특성의 이름을 지정</li>
<li>매개변수 filled: True로 지정하면 타깃값에 따라 노드 안에 색을 채움</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/30/0330_Decision_Tree_01/" data-id="cl1dhk3x90001hknhfe91e9p9" data-title="결정_트리_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0330_Ensemble_Learning01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/30/0330_Ensemble_Learning01/" class="article-date">
  <time class="dt-published" datetime="2022-03-30T00:00:00.000Z" itemprop="datePublished">2022-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/30/0330_Ensemble_Learning01/">앙상블_학습_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="트리의-앙상블"><a href="#트리의-앙상블" class="headerlink" title="트리의 앙상블"></a>트리의 앙상블</h1><ul>
<li>LightGBM ( 중요 )<ul>
<li>GBM –&gt; XGBoost –&gt; LightGBM</li>
<li>참고1. 모델 개발 속도가 빨라졌나?</li>
<li>참고2. 모델의 성능이 좋아졌나?</li>
</ul>
</li>
<li>TabNet (2019)<ul>
<li>딥러닝  컨셉</li>
</ul>
</li>
</ul>
<h2 id="랜덤-포레스트-Forest"><a href="#랜덤-포레스트-Forest" class="headerlink" title="랜덤 포레스트(Forest)"></a>랜덤 포레스트(Forest)</h2><ul>
<li>결정 트리 나무를 500갸 심기</li>
<li>최종적인 결정은 투표 방식<ul>
<li>나무 1 : 양성</li>
<li>나무 2 : 음성</li>
<li>나무 3 : 양성</li>
<li>…</li>
<li>나무 n : 양성</li>
<li>최종 판단 : 양성입니다!</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br><span class="line"></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(data, </span><br><span class="line">                                                                      target, </span><br><span class="line">                                                                      test_size=<span class="number">0.2</span>, </span><br><span class="line">                                                                      random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>267p<ul>
<li>cross_validate() 교차 검증 수행</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">rf = RandomForestClassifier(n_jobs= -<span class="number">1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scores= cross_validate(rf, train_input, train_target,</span><br><span class="line">                      return_train_score= <span class="literal">True</span>, n_jobs= -<span class="number">1</span>)  <span class="comment"># return_train_score: 훈련세트의 점수도 같이 반환됨.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9973541965122431 0.8905151032797809
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rf.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(rf.feature_importances_)</span><br><span class="line"><span class="comment"># feature_importances_: 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여</span></span><br></pre></td></tr></table></figure>

<pre><code>[0.23167441 0.50039841 0.26792718]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rf= RandomForestClassifier(oob_score= <span class="literal">True</span>, n_jobs= -<span class="number">1</span>, random_state= <span class="number">42</span>)</span><br><span class="line">rf.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(rf.oob_score_)</span><br><span class="line"><span class="comment"># oob샘플: 훈련세트에 중복을 허용하여 푸트스트랩 샘플을 만들때 포함되지 않고 남는 샘플 (=검증 세트의 역할)</span></span><br><span class="line"><span class="comment"># oob_score_: 검증 점수와 비슷한 값을 얻을 수 있음</span></span><br></pre></td></tr></table></figure>

<pre><code>0.8934000384837406
</code></pre>
<h1 id="그레이디언트-부스팅"><a href="#그레이디언트-부스팅" class="headerlink" title="그레이디언트 부스팅"></a>그레이디언트 부스팅</h1><ul>
<li>이전트리의 오차를 보완하는 방식으로 사용</li>
<li>깊이가 얕은 트리를 사용</li>
<li>학습률 매개변수로 속도를 조절</li>
<li>단점: 속도가 느림.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier <span class="comment"># 깊이가 얕은 결정 트리를 사용</span></span><br><span class="line">gb = GradientBoostingClassifier(random_state= <span class="number">42</span>)</span><br><span class="line">scores= cross_validate(gb, train_input, train_target,</span><br><span class="line">                      return_train_score= <span class="literal">True</span>, n_jobs= -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8881086892152563 0.8720430147331015
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gb = GradientBoostingClassifier(n_estimators= <span class="number">500</span>, learning_rate= <span class="number">0.2</span>, random_state= <span class="number">42</span>)</span><br><span class="line">scores= cross_validate(gb, train_input, train_target,</span><br><span class="line">                      return_train_score= <span class="literal">True</span>, n_jobs= -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9464595437171814 0.8780082549788999
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gb.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(gb.feature_importances_)</span><br><span class="line"><span class="comment">#  랜덤포레스트보다 일부 특성(당도)에 더 집중하는게 보임.</span></span><br></pre></td></tr></table></figure>

<pre><code>[0.15872278 0.68010884 0.16116839]
</code></pre>
<ul>
<li>흐름<ul>
<li>데이터 전처리&#x2F; 시각화</li>
<li>기본 모형으로 전체 흐름을 설계</li>
<li>여러모형으로 비교 대조</li>
<li>교차 검증, 하이퍼 파라미터 성능 비교</li>
<li>…</li>
<li>1등하는 그날까지…??</li>
</ul>
</li>
</ul>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>앙상블 학습: 더 좋은 예측 결과를 만들기 위해 여러 개의 모델을 훈련하는 머신러닝 알고리즘을 말함.</li>
<li>랜덤 포레스트: 대표적인 결정트리ㅇ 기반의 앙상블 학습 방법으로 부트스트랩 샘플을 사용하고 랜덤하게 일부 특성을 선택하여 트리를 만드는것이 특징</li>
<li>엑스트라 트리: 랜덤포레스트와 비슷하게 결정 트리를 사용하여 앙상블 모델을 만들지만 부트스트랩 샘플을 사용하지 않음.</li>
<li>그레이디언트 부스팅: 결정트리를 연속적으로 추가하여 손실 함수를 최소화 하는 앙상블 방법</li>
<li>히스토그램 기반 그레이디언트 부스팅: 그레이디언트 부스팅의 속도를 개선했으ㅜ며, 안정적인 결과와 높은 성능으로 매우 인기가 높음.</li>
</ul>
</li>
<li>Scikit-learn<ul>
<li>RandomForestClassifier: 랜덤 포레스트 분류 클래스<ul>
<li>매개변수 n_estimators: 앙상블을 구성할 트리의 개수를 지정 [defalt: 100]</li>
<li>매개변수 criterion: 불순도를 지정 [defalt: gini]</li>
<li>max_depth: 트리가 성장할 최대 깊이를 지정 [defalt: None]</li>
<li>min_samples_split: 노드를 나누기 위한 최소 샘플 개수 [defalt: 2]</li>
<li>메게변수 max_features: 최적의 분할을 위해 탐색할 특성의 개수를 지정 [defalt: auto](특성 개수의 제곱근)</li>
<li>매개변수 bootstrap: 부트스트랩 샘플을 사용할지 지정 [defalt: True]</li>
<li>oob_score: OOB샘플을 사용하여 훈련한 모델을 평가할지 지정 [defalt: False]</li>
<li>매개변수 n_jobs: 병렬 실행에 사용할 CPU코어 수를 지정 [defalt: 1](-1로 지정하면 시스템에 있는 모든 코어를 사용)</li>
<li>GrandientBoostingClassifier: 그레이디언트 부스팅 분류 클래스</li>
<li>매개변수 loss: 손실 함수를 지정 [defalt: deviance]</li>
<li>매개변수 learning_rate: 트리가 앙상블에 기여하는 정도를 조절 [defalt: 0.1]</li>
<li>매개변수 n_estimators: 부스팅 단계를 수행하는 트리의 개수</li>
<li>매개변수 subsample: 사용할 훈련 세트의 샘플 비율을 지정 [defalt: 1]</li>
<li>매개변수 max_depth: 개별 회귀 트리의 최대 깊이 [defalt: 3]</li>
</ul>
</li>
<li>HistGradientBoostingClassifier: 히스토그램 기반 그레이디언트 부스팅 분류 클래스<ul>
<li>매개변수 learning_rate: 학습률 또는 감쇠율 [defalt: 0.1]</li>
<li>max_iter: 부스팅 단계를 수행하는 트리의 개수 [defalt: 100]</li>
<li>max_bins: 입력 데이터를 나눌 구간의 개수. [defalt: 255]</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/30/0330_Ensemble_Learning01/" data-id="cl1dhk3xa0002hknha9d4gut9" data-title="앙상블_학습_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0329_LogisticRegression_01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/29/0329_LogisticRegression_01/" class="article-date">
  <time class="dt-published" datetime="2022-03-29T00:00:00.000Z" itemprop="datePublished">2022-03-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/29/0329_LogisticRegression_01/">로지스틱 회귀 01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="로지스틱-회귀-Logistic-Regression"><a href="#로지스틱-회귀-Logistic-Regression" class="headerlink" title="로지스틱 회귀(Logistic Regression)"></a>로지스틱 회귀(Logistic Regression)</h1><h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"></span><br><span class="line">fish = pd.read_csv(<span class="string">&#x27;https://bit.ly/fish_csv_data&#x27;</span>)</span><br><span class="line">fish.head()</span><br></pre></td></tr></table></figure>





  <div id="df-933200f5-54dd-47e4-9481-6ae409c19d41">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Weight</th>
      <th>Length</th>
      <th>Diagonal</th>
      <th>Height</th>
      <th>Width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bream</td>
      <td>242.0</td>
      <td>25.4</td>
      <td>30.0</td>
      <td>11.5200</td>
      <td>4.0200</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bream</td>
      <td>290.0</td>
      <td>26.3</td>
      <td>31.2</td>
      <td>12.4800</td>
      <td>4.3056</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bream</td>
      <td>340.0</td>
      <td>26.5</td>
      <td>31.1</td>
      <td>12.3778</td>
      <td>4.6961</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bream</td>
      <td>363.0</td>
      <td>29.0</td>
      <td>33.5</td>
      <td>12.7300</td>
      <td>4.4555</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bream</td>
      <td>430.0</td>
      <td>29.0</td>
      <td>34.0</td>
      <td>12.4440</td>
      <td>5.1340</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-933200f5-54dd-47e4-9481-6ae409c19d41')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-933200f5-54dd-47e4-9481-6ae409c19d41 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-933200f5-54dd-47e4-9481-6ae409c19d41&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<h1 id="데이터-변환"><a href="#데이터-변환" class="headerlink" title="데이터 변환"></a>데이터 변환</h1><ul>
<li>배열로 변환</li>
<li>to_numpy(): 이용하여 넘파이 배열로 새로 저장</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fish_input = fish[[<span class="string">&quot;Weight&quot;</span>, <span class="string">&quot;Length&quot;</span>, <span class="string">&quot;Diagonal&quot;</span>, <span class="string">&quot;Height&quot;</span>, <span class="string">&quot;Width&quot;</span>]].to_numpy()  <span class="comment"># 특성별로 구분해서 저장</span></span><br><span class="line"><span class="built_in">print</span>(fish_input[:<span class="number">5</span>])</span><br><span class="line">fish_input.shape</span><br></pre></td></tr></table></figure>

<pre><code>[[242.      25.4     30.      11.52     4.02  ]
 [290.      26.3     31.2     12.48     4.3056]
 [340.      26.5     31.1     12.3778   4.6961]
 [363.      29.      33.5     12.73     4.4555]
 [430.      29.      34.      12.444    5.134 ]]





(159, 5)
</code></pre>
<ul>
<li>종류를 target 배열로 변환</li>
<li>종속변수</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_target= fish[<span class="string">&quot;Species&quot;</span>].to_numpy()</span><br><span class="line"><span class="comment"># fish_target.shape</span></span><br></pre></td></tr></table></figure>

<h1 id="훈련-데이터와-테스트-데이터"><a href="#훈련-데이터와-테스트-데이터" class="headerlink" title="훈련 데이터와 테스트 데이터"></a>훈련 데이터와 테스트 데이터</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from sklearn.model_selection import train_test_split</span></span><br><span class="line"><span class="comment"># train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state= 42)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state= <span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>표준화 전처리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)  <span class="comment"># 변환 전 훈련</span></span><br><span class="line">train_scaled = ss.transform(train_input)  <span class="comment"># 변환</span></span><br><span class="line">test_scaled = ss.transform(test_input)  <span class="comment"># 변환</span></span><br><span class="line">test_scaled[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([[-0.88741352, -0.91804565, -1.03098914, -0.90464451, -0.80762518],
       [-1.06924656, -1.50842035, -1.54345461, -1.58849582, -1.93803151],
       [-0.54401367,  0.35641402,  0.30663259, -0.8135697 , -0.65388895],
       [-0.34698097, -0.23396068, -0.22320459, -0.11905019, -0.12233464],
       [-0.68475132, -0.51509149, -0.58801052, -0.8998784 , -0.50124996]])
</code></pre>
<p>k최근접 이웃 분류기 확률 예측</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">kn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)  <span class="comment"># 3개의 이웃 데이터의 평균으로 유추</span></span><br><span class="line">kn.fit(train_scaled, train_target)  <span class="comment"># 흔랸</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(kn.score(train_scaled, train_target))  <span class="comment"># 훈련 후 점수 확인</span></span><br><span class="line"><span class="built_in">print</span>(kn.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8907563025210085
0.85
</code></pre>
<p>182p</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">proba = kn.predict_proba(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals= <span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(kn.classes_)</span><br></pre></td></tr></table></figure>

<pre><code>[[0.     0.     1.     0.     0.     0.     0.    ]
 [0.     0.     0.     0.     0.     1.     0.    ]
 [0.     0.     0.     1.     0.     0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]]
[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
</code></pre>
<h1 id="로지스틱-회귀-분류모델"><a href="#로지스틱-회귀-분류모델" class="headerlink" title="로지스틱 회귀 (분류모델)"></a>로지스틱 회귀 (분류모델)</h1><ul>
<li>중요도: 최상</li>
<li>*** 로지스틱 회귀의 이론이 나온 이유: ***</li>
<li>범주형( True, False ) 의 경우 선형함수로 표현하기엔 오류가 발생하여 굴곡이 있는 모델을 제시함.</li>
<li>유튜브 시청 필요</li>
<li><a target="_blank" rel="noopener" href="https://youtu.be/zASrGSHoqL4">https://youtu.be/zASrGSHoqL4</a></li>
<li>개념 재복습 필수</li>
<li>중요한 이유:<ul>
<li>기초통계로도 활용(의학통계)</li>
<li>머신러닝 분류모형의 기초 모형인데, 성능이 나쁘지 않음.<ul>
<li>데이터셋, 수치 데이터 기반</li>
</ul>
</li>
<li>딥러닝: 초기모형에 해당됨.</li>
</ul>
</li>
<li>시그모이드 함수:</li>
<li>z &#x3D; phi &#x3D; 1 &#x2F; (1 + np.exp(-z))</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 원본</span></span><br><span class="line"><span class="comment"># import numpy as np</span></span><br><span class="line"><span class="comment"># import matplotlib.pyplot as plt</span></span><br><span class="line"><span class="comment"># z = np.arange(-5, 5, 0.1)</span></span><br><span class="line"><span class="comment"># phi = 1 / (1 + np.exp(-z))</span></span><br><span class="line"><span class="comment"># # phi</span></span><br><span class="line"><span class="comment"># plt.plot(z, phi)</span></span><br><span class="line"><span class="comment"># plt.xlabel(&quot;z&quot;)</span></span><br><span class="line"><span class="comment"># plt.ylabel(&quot;phi&quot;)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">z = np.arange(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">0.1</span>)  <span class="comment"># -5와 5 사이에서 0.1간격으로 배열</span></span><br><span class="line">phi = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))  <span class="comment"># 지수함수 계산은 np.exp() 함수를 이용</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(z, phi)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;z&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;phi&quot;</span>)</span><br><span class="line">plt.show</span><br></pre></td></tr></table></figure>




<pre><code>&lt;function matplotlib.pyplot.show&gt;
</code></pre>
<p><img src="/Images/0329_LogisticRegression_01/output_17_1.png" alt="png"></p>
<pre><code>    시그모이드 함수의 출력이 0.5보다 크면 양성 클래스, 0.5보다 작으면 음성 클래스로 판단
    0.5일때는 라이브러리마다 다르지만 사이킷런은 음성클래스로 판단.
</code></pre>
<h1 id="로지스틱-회귀로-이진-분류-수행하기"><a href="#로지스틱-회귀로-이진-분류-수행하기" class="headerlink" title="로지스틱 회귀로 이진 분류 수행하기"></a>로지스틱 회귀로 이진 분류 수행하기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">char_arr = np.array([<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>, <span class="string">&quot;C&quot;</span>, <span class="string">&quot;D&quot;</span>, <span class="string">&quot;E&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(char_arr[[<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>]])  <span class="comment"># True, False로 원하는 데이터만 추출</span></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;A&#39; &#39;C&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bream_smelt_indexes = (train_target == <span class="string">&#x27;Bream&#x27;</span>) | (train_target == <span class="string">&#x27;Smelt&#x27;</span>)  <span class="comment"># | : OR연산자</span></span><br><span class="line">train_bream_smelt = train_scaled[bream_smelt_indexes]</span><br><span class="line">target_bream_smelt = train_target[bream_smelt_indexes]</span><br><span class="line">target_bream_smelt</span><br></pre></td></tr></table></figure>




<pre><code>array([&#39;Bream&#39;, &#39;Smelt&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Smelt&#39;, &#39;Bream&#39;,
       &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Smelt&#39;,
       &#39;Bream&#39;, &#39;Smelt&#39;, &#39;Smelt&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;,
       &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Bream&#39;, &#39;Smelt&#39;, &#39;Bream&#39;, &#39;Smelt&#39;,
       &#39;Smelt&#39;, &#39;Bream&#39;, &#39;Smelt&#39;, &#39;Bream&#39;, &#39;Bream&#39;], dtype=object)
</code></pre>
<ul>
<li>186p</li>
<li>모형 만들고 예측하기!</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"><span class="comment">#             독립변수          종속변수</span></span><br><span class="line">lr.fit(train_bream_smelt, target_bream_smelt)</span><br></pre></td></tr></table></figure>




<pre><code>LogisticRegression()
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 예측하기</span></span><br><span class="line"><span class="comment"># 클래스로 분류</span></span><br><span class="line"><span class="comment"># 확률값 -&gt; 0.5</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.predict(train_bream_smelt[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Smelt&#39; &#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict_proba(train_bream_smelt[:<span class="number">5</span>]))</span><br><span class="line"><span class="built_in">print</span>(lr.classes_)  <span class="comment"># smelt: 양성 클래스 , bream: 음성 클래스</span></span><br></pre></td></tr></table></figure>

<pre><code>[[0.99759855 0.00240145]
 [0.02735183 0.97264817]
 [0.99486072 0.00513928]
 [0.98584202 0.01415798]
 [0.99767269 0.00232731]]
[&#39;Bream&#39; &#39;Smelt&#39;]
</code></pre>
<ul>
<li>방정식의 각 기울기와 상수를 구하는 코드</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print(lr.coef_, lr.intercept_)</span></span><br><span class="line"><span class="built_in">print</span>(lr.coef_)</span><br><span class="line"><span class="built_in">print</span>(lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]]
[-2.16155132]
</code></pre>
<ul>
<li>결론 z식<br>  z &#x3D; -0.4037798 * weight - 0.57620209 *length - -0.66280298 * diagonal -1.01290277 * height -0.73168947 * width - 2.16155132<br>  라는 식이 도출됨</li>
<li>z값을 출력하자</li>
<li>predict_proba()</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decisions = lr.decision_function(train_bream_smelt[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(decisions)</span><br></pre></td></tr></table></figure>

<pre><code>[-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> expit</span><br><span class="line"><span class="built_in">print</span>(expit(decisions))</span><br></pre></td></tr></table></figure>

<pre><code>[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
</code></pre>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li><p>키워드</p>
<ul>
<li>로지스틱 회귀: 선형 방정식을 사용한 분류 알고리즘 (시그모이드를 사용하여 클래스 학률을 출력할수 있다.)</li>
<li>다중분류<ul>
<li>타깃 클래스가 2개 이상인 분류 문제</li>
</ul>
</li>
<li>시그모이드:<br>0~1사이의 값으로</li>
</ul>
</li>
<li><p>Scikit-learn 패키지</p>
<ul>
<li>LogisticRegression:<br>선형분류의 알고리즘인 로지스틱 회귀를 위한 클래스<ul>
<li>매개변수 solver: 사용할 알고리즘을 선택 [default: lbfgs]</li>
<li>매개변수 penalty: L2규제(릿지 방식)와 L1규제(라쏘 방식)를 선택 [default: l2]</li>
<li>매개변수 C: 규제의 강도를 제어. 작을수록 규제가 강함 [default: 1.0]</li>
</ul>
</li>
<li>predict_proba(): 예측 확률을 반환</li>
<li>decision_function(): 모델이 학습한 선형 방정식의 출력을 반환</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/29/0329_LogisticRegression_01/" data-id="cl1bvqxx10000f0nh5k0s58rg" data-title="로지스틱 회귀 01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0329_SGDClassifier01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/29/0329_SGDClassifier01/" class="article-date">
  <time class="dt-published" datetime="2022-03-29T00:00:00.000Z" itemprop="datePublished">2022-03-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/29/0329_SGDClassifier01/">확률적 경사 하강법 01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="경사-하강법이-쓰인-여러-알고리즘"><a href="#경사-하강법이-쓰인-여러-알고리즘" class="headerlink" title="경사 하강법이 쓰인 여러 알고리즘"></a>경사 하강법이 쓰인 여러 알고리즘</h1><pre><code>    - (이미지, 택스트) 딥러닝 기초 알고리즘
    - 트리 알고리즘 + 경사하강법 융합 = 부스팅계열
      - LightGBM, Xgboost, Catboost
        ex 1등으로 자주 쓰인 알고리즘: LightGBM, Xgboost
        - 하이퍼 파라미터의 개수가 80개가 넘음
</code></pre>
<h1 id="SGDClassifier"><a href="#SGDClassifier" class="headerlink" title="SGDClassifier"></a>SGDClassifier</h1><ul>
<li><p>확률적 경사하강법 분류기</p>
</li>
<li><p>1회에 1개의 데이터씩 뽑기: 확률적 경사 하강법</p>
</li>
<li><p>1회에 여러개의 데이터씩 뽑기: 미니배치 경사 하강법</p>
</li>
<li><p>1회에 모든 데이터를 뽑기: 배치 경사 하강법</p>
</li>
<li><p>에포크: 훈련세트를 한번 모두 사용하는 과정</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">fish = pd.read_csv(<span class="string">&quot;https://bit.ly/fish_csv_data&quot;</span>)</span><br><span class="line">fish.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 159 entries, 0 to 158
Data columns (total 6 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Species   159 non-null    object 
 1   Weight    159 non-null    float64
 2   Length    159 non-null    float64
 3   Diagonal  159 non-null    float64
 4   Height    159 non-null    float64
 5   Width     159 non-null    float64
dtypes: float64(5), object(1)
memory usage: 7.6+ KB
</code></pre>
<ul>
<li>배열로 변환하는 코드<ul>
<li>독립변수 &#x3D; fish_input</li>
<li>종속변수 &#x3D; fish_target</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_input = fish[[<span class="string">&quot;Weight&quot;</span>, <span class="string">&quot;Length&quot;</span>, <span class="string">&quot;Diagonal&quot;</span>, <span class="string">&quot;Height&quot;</span>, <span class="string">&quot;Width&quot;</span>]].to_numpy()</span><br><span class="line">fish_target= fish[<span class="string">&quot;Species&quot;</span>].to_numpy()</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련세트와 테스트세트로 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state= <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape,</span><br></pre></td></tr></table></figure>




<pre><code>((119, 5), (40, 5), (119,), (40,))
</code></pre>
<ul>
<li>표준화 처리<ul>
<li>다시 한번 강조하지만 꼭 훈련 세트로 학습한 통계값으로 테스트 세트도 변환한다.</li>
<li>키워드: Data Leakage 방지 (나중에 찾아볼것)</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)  <span class="comment"># 변환 전 훈련세트 학습</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ss훈련 데이터만 활용해서 학습이 끝난 상태</span></span><br><span class="line"><span class="comment"># 표준화 처리를 훈련데이터와 테스트데이터에 동시 적용</span></span><br><span class="line">train_scaled = ss.transform(train_input)  <span class="comment"># 변환</span></span><br><span class="line">test_scaled = ss.transform(test_input)  <span class="comment"># 변환</span></span><br></pre></td></tr></table></figure>

<h1 id="모델-학습"><a href="#모델-학습" class="headerlink" title="모델 학습"></a>모델 학습</h1><ul>
<li>2개의 매개 변수 지정</li>
<li>loss&#x3D; “log”&#x3D;  로지스틱 손실 함수로 지정</li>
<li>max_iter &#x3D; 에포크 횟수 지정</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 매개변수 지정</span></span><br><span class="line"><span class="comment"># 하이퍼파라미터 설정</span></span><br><span class="line"><span class="comment"># 매개변수 값을 dictionary 형태로 추가하는 코드 작성 가능</span></span><br><span class="line"><span class="comment"># 입문자들에게는 비추천</span></span><br><span class="line">sc = SGDClassifier(loss=<span class="string">&quot;log&quot;</span>, max_iter= <span class="number">100</span>, random_state= <span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8403361344537815
0.8
</code></pre>
<ul>
<li>적절한 에포크 숫자 찾기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sc = SGDClassifier(loss= <span class="string">&quot;log&quot;</span>, max_iter=<span class="number">100</span>, tol=<span class="literal">None</span>, random_state= <span class="number">42</span>)</span><br><span class="line">train_score=[]</span><br><span class="line">test_score= []</span><br><span class="line">classes = np.unique(train_target)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">300</span>):  <span class="comment"># 에포크값 0 ~ 300  , # &quot;_&quot;도 변수가 될 수 있음</span></span><br><span class="line">  sc.partial_fit(train_scaled, train_target, classes= classes)  <span class="comment"># 훈련</span></span><br><span class="line">  train_score.append(sc.score(train_scaled, train_target))  <span class="comment"># 점수로 나오는 값들을 append()</span></span><br><span class="line">  test_score.append(sc.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_score[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(test_score[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0.5294117647058824, 0.6218487394957983, 0.6386554621848739, 0.7310924369747899, 0.7226890756302521]
[0.65, 0.55, 0.575, 0.7, 0.7]
</code></pre>
<ul>
<li>모형학습 시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(train_score)</span><br><span class="line">ax.plot(test_score)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Epoch&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0329_SGDClassifier01/output_14_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sc = SGDClassifier(loss=<span class="string">&quot;log&quot;</span>, max_iter=<span class="number">100</span>, tol=<span class="literal">None</span>, random_state=<span class="number">42</span>)  <span class="comment"># 반복횟수 100 , # tol(): 반복을 멈추는 기준</span></span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.957983193277311
0.925
</code></pre>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>확률적 경사 하강법: 훈련세트에서 샘플 하나씩 꺼내 손실 함수의 경사를 따라 최적의 모델링을 찾는 알고리즘</li>
<li>손실함수: 확률적 경사 하강법이 최적화 할 대상<ul>
<li>ex) 이진분류에는 로지스틱 회귀 손실함수를 사용</li>
</ul>
</li>
<li>에포크: 확률적 경사 하강법에서 전체 샘플을 모두 사용하는 한 번 반복을 의미</li>
</ul>
</li>
<li>Scikit-Learn 패키지<ul>
<li>SGDClassifier: 확률적 경사 하강법을 사용한 분류모델을 만듬<ul>
<li>매개변수 loss: 최적화 할 손실함수를 지정. 로지스틱 회귀를 위해서는 log로 지정. [default: hinge](서포트 벡터 머신)</li>
<li>매개변수 max_iter: 에포크 횟수를 지정 [default: 1000]</li>
<li>매개변수 tol: 반복을 멈출 조건 [default: 0.001]</li>
</ul>
</li>
<li>SGDRegressor: 확률적 경사 하강법을 사용한 회귀모델을 만듬<ul>
<li>매개변수 loss: 손실함수를 지정 [default: squared_loss](제곱오차를 나타냄)</li>
<li>매개변수 max_iter: 에포크 횟수를 지정 [default: 1000]</li>
<li>매개변수 tol: 반복을 멈출 조건 [default: 0.001]</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/29/0329_SGDClassifier01/" data-id="cl1bvqxx90001f0nh6vxlhl4j" data-title="확률적 경사 하강법 01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0328_Regression_01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/28/0328_Regression_01/" class="article-date">
  <time class="dt-published" datetime="2022-03-28T00:00:00.000Z" itemprop="datePublished">2022-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/28/0328_Regression_01/">k-최근접 이웃 회귀 01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="k-최근접-이웃-회귀-Regression"><a href="#k-최근접-이웃-회귀-Regression" class="headerlink" title="k-최근접 이웃 회귀(Regression)"></a>k-최근접 이웃 회귀(Regression)</h1><ul>
<li>중요도: 하 (그냥 넘어갈것)</li>
</ul>
<h1 id="데이터-준비"><a href="#데이터-준비" class="headerlink" title="데이터 준비"></a>데이터 준비</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br></pre></td></tr></table></figure>

<h1 id="시각화"><a href="#시각화" class="headerlink" title="시각화"></a>시각화</h1><ul>
<li>객체지향으로 변경할것</li>
<li>fig, ax &#x3D; plt.subplots()</li>
<li>ax.scatter(Xdata, Ydata)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(perch_length, perch_weight)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;length&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0328_Regression_01/output_4_0.png" alt="png"></p>
<h1 id="훈련-데이터-테스트-데이터셋-분리"><a href="#훈련-데이터-테스트-데이터셋-분리" class="headerlink" title="훈련 데이터 테스트 데이터셋 분리"></a>훈련 데이터 테스트 데이터셋 분리</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    perch_length, perch_weight, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((42,), (14,), (42,), (14,))
</code></pre>
<ul>
<li>reshape() 사용하여 2차원 배열로 바꿈</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input= train_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">test_input= test_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 1) (14, 1)
</code></pre>
<h1 id="결정계수-R-2"><a href="#결정계수-R-2" class="headerlink" title="결정계수 R^2"></a>결정계수 R^2</h1><ul>
<li>모델이 얼마만큼 정확한가<ul>
<li>99.3%</li>
</ul>
</li>
<li>절댓값은 아님 &#x3D;&#x3D;&gt; 상대적인 값임</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 클래스 불러오기</span></span><br><span class="line">knr = KNeighborsRegressor()</span><br><span class="line"></span><br><span class="line"><span class="comment">#  모형학습</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테스트 점수 확인</span></span><br><span class="line">knr.score(test_input, test_target)</span><br></pre></td></tr></table></figure>




<pre><code>0.992809406101064
</code></pre>
<h1 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h1><ul>
<li>타깃과 얘측의 절댓값 오차를 평균하여 반환</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 데이터 만들기</span></span><br><span class="line">test_prediction = knr.predict(test_input)</span><br><span class="line">test_prediction</span><br></pre></td></tr></table></figure>




<pre><code>array([  60. ,   79.6,  248. ,  122. ,  136. ,  847. ,  311.4,  183.4,
        847. ,  113. , 1010. ,   60. ,  248. ,  248. ])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mae = mean_absolute_error(test_target, test_prediction)</span><br><span class="line"><span class="built_in">print</span>(mae)</span><br><span class="line"><span class="comment"># 평균적으로 19g정도 다름</span></span><br></pre></td></tr></table></figure>

<pre><code>19.157142857142862
</code></pre>
<h1 id="과대적합-vs-과소적합"><a href="#과대적합-vs-과소적합" class="headerlink" title="과대적합 vs 과소적합"></a>과대적합 vs 과소적합</h1><ul>
<li>공통점: 머신러닝 모형이 실제 테스트 시 잘 예측을 못함.</li>
<li>차이점:<ul>
<li>과대적합: 훈련데이터에는 예측 잘함, 테스트데이터에서는 예측을 잘 못함.<ul>
<li>처리하기 곤란.</li>
</ul>
</li>
<li>과소적합: 훈련데이터에서는 예측을 못하고, 테스트데이터에서는 예측을 잘하거나 or 둘 다 예측을 잘 못함.<ul>
<li>데이터양이 적거나, 모델을 너무 간단하게 만듬</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 훈련 데이터 점수 확인</span></span><br><span class="line">knr.score(train_input, train_target)  <span class="comment"># 0.97정도 나옴</span></span><br></pre></td></tr></table></figure>




<pre><code>0.9698823289099254
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Default 5를 3으로 변경</span></span><br><span class="line"><span class="comment"># 머신러닝 모형을 변경</span></span><br><span class="line">knr.n_neighbors = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델을 다시 훈련</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(knr.score(train_input, train_target))  <span class="comment"># 0.98정도 나옴</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9804899950518966
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(knr.score(test_input, test_target))  <span class="comment"># 0.97</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9746459963987609
</code></pre>
<ul>
<li>MAE구하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 예측 데이터 만들기</span></span><br><span class="line">test_prediction = knr.predict(test_input)</span><br><span class="line">mae = mean_absolute_error(test_target, test_prediction)</span><br><span class="line"><span class="comment"># test_prediction</span></span><br><span class="line"><span class="built_in">print</span>(mae)  <span class="comment"># 35.4정도 나옴</span></span><br></pre></td></tr></table></figure>

<pre><code>35.42380952380951
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 머신러닝 모형을 변경</span></span><br><span class="line">knr.n_neighbors = <span class="number">7</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델을 다시 훈련</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(knr.score(train_input, train_target))  <span class="comment"># </span></span><br><span class="line"><span class="built_in">print</span>(knr.score(test_input, test_target))  <span class="comment"># </span></span><br></pre></td></tr></table></figure>

<pre><code>0.9761170732051527
0.9781383949643516
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 예측 데이터 만들기</span></span><br><span class="line">test_prediction = knr.predict(test_input)</span><br><span class="line">mae = mean_absolute_error(test_target, test_prediction)</span><br><span class="line"><span class="built_in">print</span>(mae)  <span class="comment"># </span></span><br></pre></td></tr></table></figure>

<pre><code>32.512244897959185
</code></pre>
<h1 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h1><ul>
<li>k그룹을 5로 했을때 R2는 0.98 mae는 19정도 였음</li>
<li>k그룹을 3으로 했을때 R2는 0.97 mae는 35.4정도 였음</li>
<li>k그룹을 7로 했을때 R2는 0.98 mae는 32.5정도 였음</li>
</ul>
<h1 id="내맘대로-코딩"><a href="#내맘대로-코딩" class="headerlink" title="내맘대로 코딩"></a>내맘대로 코딩</h1><ul>
<li>R^2와 mae의 값을 찾기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">TEST = np.arange(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># float R0 = 0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> TEST:</span><br><span class="line">  knr.n_neighbors = i</span><br><span class="line">  knr.fit(train_input, train_target)</span><br><span class="line">  <span class="built_in">print</span>(knr.score(test_input, test_target))</span><br><span class="line"></span><br><span class="line">  R2= knr.score(test_input, test_target)</span><br><span class="line">  test_prediction = knr.predict(test_input)</span><br><span class="line">  mae = mean_absolute_error(test_target, test_prediction)</span><br><span class="line">  <span class="built_in">print</span>(mae, i)</span><br><span class="line">  </span><br></pre></td></tr></table></figure>

<pre><code>0.991309195814175
22.685714285714287 1
0.9725010241788556
35.292857142857144 2
0.9746459963987609
35.42380952380951 3
0.9840231023848637
28.38214285714286 4
0.992809406101064
19.157142857142862 5
0.9855001139899048
28.388095238095243 6
0.9781383949643516
32.512244897959185 7
0.9780541148735824
34.88214285714286 8
0.9692647749722698
43.987301587301594 9
</code></pre>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>회귀: 임의의 수치를 예측하는 문제</li>
<li>k-최근접 이웃 회귀: 가장 가까운 이웃 샘플을 찾고 그 샘플들의 평균으로 예측</li>
<li>결정계수(R²)대표적인 회귀문제의 성능 측정 도구. 1에 가까울수록 좋고 0에 가까울수록 나쁜 모델임</li>
<li>과대적합: 훈련데이터에는 예측 잘함, 테스트데이터에서는 예측을 잘 못함</li>
<li>과소적합: 훈련데이터에서는 예측을 못하고, 테스트데이터에서는 예측을 잘하거나 or 둘 다 예측을 잘 못함</li>
</ul>
</li>
<li>Scikit-learn 패키지<ul>
<li>KNeighborsRegressor: k-최근접 이웃 회귀 모델을 만드는 사이킷런 클래스. n_neighbors 매개변수를 지정함. [default: 5]</li>
<li>mean_absolute_error(A, B): 회귀모델의 평균 절댓값 오차를 계산. A는 타깃, B는 예측값. 타깃과 예측을 뺀 값을 제곱한 다음 전체 샘플에 대해 평균한 값을 반환함.</li>
</ul>
</li>
<li>Numpy 패키지<ul>
<li>reshape(): 배열의 크기를 바꾸는 메서드. -1은 적용 가능한 정수를 자동으로 찾아주는 역할</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/28/0328_Regression_01/" data-id="cl1as2bdh0000dknh7v3acmhs" data-title="k-최근접 이웃 회귀 01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0328_Regression_02" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/28/0328_Regression_02/" class="article-date">
  <time class="dt-published" datetime="2022-03-28T00:00:00.000Z" itemprop="datePublished">2022-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/28/0328_Regression_02/">k-최근접 이웃 회귀 02</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="선형회귀"><a href="#선형회귀" class="headerlink" title="선형회귀"></a>선형회귀</h1><h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br></pre></td></tr></table></figure>

<h1 id="훈련-데이터-테스트-데이터셋-분리"><a href="#훈련-데이터-테스트-데이터셋-분리" class="headerlink" title="훈련 데이터 테스트 데이터셋 분리"></a>훈련 데이터 테스트 데이터셋 분리</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    perch_length, perch_weight, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((42,), (14,), (42,), (14,))
</code></pre>
<ul>
<li>reshape() 사용하여 2차원 배열로 바꿈</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input= train_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">test_input= test_input.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 1) (14, 1)
</code></pre>
<h1 id="모델만들기"><a href="#모델만들기" class="headerlink" title="모델만들기"></a>모델만들기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 클래스 불러오기</span></span><br><span class="line">knr = KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#  모형학습</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsRegressor(n_neighbors=3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1033.33333333]
</code></pre>
<h1 id="시각화"><a href="#시각화" class="headerlink" title="시각화"></a>시각화</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 원본</span></span><br><span class="line"><span class="comment"># import matplotlib.pyplot as plt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 50cm 농어의 이웃을 구하기</span></span><br><span class="line"><span class="comment"># distances, indexes= knr.kneighbors([[50]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 훈련세트의 산점도를 그리기</span></span><br><span class="line"><span class="comment"># plt.scatter(train_input, train_target)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 훈련 세트 중에서 이웃 샘플만 다시 그립니다.</span></span><br><span class="line"><span class="comment"># plt.scatter(train_input[indexes], train_target[indexes], marker= &quot;D&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 50cm 농어 데이터</span></span><br><span class="line"><span class="comment"># plt.scatter(50, 1033, marker= &quot;^&quot;)</span></span><br><span class="line"><span class="comment"># plt.xlabel(&quot;length&quot;)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어의 이웃을 구하기</span></span><br><span class="line">distances, indexes= knr.kneighbors([[<span class="number">50</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련세트의 산점도를 그리기</span></span><br><span class="line"><span class="comment"># plt.scatter(train_input, train_target)</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련 세트 중에서 이웃 샘플만 다시 그립니다.</span></span><br><span class="line">ax.scatter(train_input[indexes], train_target[indexes], marker= <span class="string">&quot;D&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어 데이터</span></span><br><span class="line">ax.scatter(<span class="number">50</span>, <span class="number">1033</span>, marker= <span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;length&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0328_Regression_02/output_12_0.png" alt="png"></p>
<ul>
<li>머신러닝 모델은 주기적으로 훈련해야 합니다.<ul>
<li>MLOps(Machine Learning &amp; Operations)</li>
<li>최근에 각광받는 데이터 관련 직업 필수</li>
<li>입사와 함께 공부시작 (데이터 분석가, 머신러닝 엔지니어, 데이터 싸이언티스트 희망자)</li>
</ul>
</li>
</ul>
<h1 id="선형회귀-머신러닝"><a href="#선형회귀-머신러닝" class="headerlink" title="선형회귀 (머신러닝)"></a>선형회귀 (머신러닝)</h1><ul>
<li>평가지표 확이이 더 중요 - R2점수, MAE, MSE, 등등</li>
</ul>
<h1 id="선형회귀-통계"><a href="#선형회귀-통계" class="headerlink" title="선형회귀 (통계)"></a>선형회귀 (통계)</h1><ul>
<li>5가지 가정들<ul>
<li>장차의 정규성, 등분상성, 다중공선성, 등등…</li>
<li>종속변수 ~ 독립변수간의 “인과관계”를 찾는 과정</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 선형 회귀 모델 훈련</span></span><br><span class="line">lr.fit(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1241.83860323]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax= plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line">ax.scatter(train_input[indexes], train_target[indexes], marker= <span class="string">&quot;D&quot;</span>)</span><br><span class="line">ax.scatter(<span class="number">50</span>, <span class="number">1241</span>, marker= <span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;length&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0328_Regression_02/output_16_0.png" alt="png"></p>
<pre><code>- 농어무게 = 기울기(a) * 농어 길이 + 절편(b)
</code></pre>
<h1 id="회귀식-찾기"><a href="#회귀식-찾기" class="headerlink" title="회귀식 찾기"></a>회귀식 찾기</h1><ul>
<li>기울기</li>
<li>절편</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 기울기, 절편</span></span><br><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[39.01714496] -709.0186449535477


- 기울기 a: 39.01714496
- 절편 b: 709.0186449535477
</code></pre>
<ul>
<li><strong>기울기</strong>: 계수 &#x3D; 가중치 (딥러닝)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax= plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 15~50까지의 1차 방정식 그래프</span></span><br><span class="line">ax.plot([<span class="number">15</span>,<span class="number">50</span>],</span><br><span class="line">        [<span class="number">15</span> * lr.coef_ + lr.intercept_,</span><br><span class="line">         <span class="number">50</span> * lr.coef_ + lr.intercept_],)</span><br><span class="line"></span><br><span class="line">plt.scatter(<span class="number">50</span>, <span class="number">1241.8</span>, marker= <span class="string">&quot;^&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0328_Regression_02/output_22_0.png" alt="png"></p>
<ul>
<li>모형 평가<ul>
<li>과대적합 발생</li>
</ul>
</li>
</ul>
<h1 id="다항회귀"><a href="#다항회귀" class="headerlink" title="다항회귀"></a>다항회귀</h1><ul>
<li>ax^2 + by + c</li>
<li>if) 치어 1cm<ul>
<li>-670g이 나옴</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">1</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[-670.00149999]
</code></pre>
<ul>
<li>1차 방정식을 2차 방정식으로 만드는 과정 필요</li>
<li>넘파이 브로드캐스팅<ul>
<li>배열의 크기가 동일하면 상관없음</li>
<li>배열의 크기가 다른데 연산을 할 때 브로드캐스팅 원리가 적용됨.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_poly = np.column_stack((train_input **<span class="number">2</span>, train_input))</span><br><span class="line">test_poly = np.column_stack((test_input **<span class="number">2</span>, test_input))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_poly.shape, test_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 2) (14, 2)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression()</span><br><span class="line"></span><br><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span>**<span class="number">2</span>,<span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1573.98423528]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[  1.01433211 -21.55792498] 116.0502107827827
</code></pre>
<p>-knn의 문제점</p>
<ul>
<li>농어의 길이가 커져도 무게가 동일함</li>
<li>현실성없음</li>
<li>단순 선형회귀(1차방정식)의 문제점<ul>
<li>치어(1cm)의 무게가 음수로 나옴</li>
<li>현실성없음</li>
</ul>
</li>
<li>다항회귀(2차 방정식)로 변경<ul>
<li>현실성 있음</li>
</ul>
</li>
</ul>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>선형회귀: 특성과 타깃 사이의 관계를 가장 잘 나타내는 선형 방정식을 찾음. 특성이 하나면 직선 방정식이 됨.</li>
<li>모델 파라미터: 선형회귀가 찾은 가중치처럼 머신러닝 모델이 특성에서 학습한 파라미터</li>
<li>다항 회귀: 다항식을 사용하여 특성과 타깃 사이의 관계를 나타냄</li>
</ul>
</li>
<li>Scikit-learn 패키지<ul>
<li>LinearRegression: 선형 회귀 클래스</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/28/0328_Regression_02/" data-id="cl1as2be00001dknhf34d4q7q" data-title="k-최근접 이웃 회귀 02" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/03/31/0331_Principar_Component_Analysis_01/">주성분_분석_01</a>
          </li>
        
          <li>
            <a href="/2022/03/31/0331_Unsupervised_Learning/">비지도_학습_01</a>
          </li>
        
          <li>
            <a href="/2022/03/31/0331_K_Means_01/">K-평균_01</a>
          </li>
        
          <li>
            <a href="/2022/03/30/0330_Cross_Validation01/">교차검증과_랜덤서치_01</a>
          </li>
        
          <li>
            <a href="/2022/03/30/0330_Decision_Tree_01/">결정_트리_01</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>