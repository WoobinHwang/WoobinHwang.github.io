<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>WB&#39;blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="WB&#39;blog">
<meta property="og:url" content="https://woobinhwang.github.io/index.html">
<meta property="og:site_name" content="WB&#39;blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="WB'blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">WB&#39;blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://woobinhwang.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-0406_Convolution_Neural_Network" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/04/06/0406_Convolution_Neural_Network/" class="article-date">
  <time class="dt-published" datetime="2022-04-06T00:00:00.000Z" itemprop="datePublished">2022-04-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/04/06/0406_Convolution_Neural_Network/">합성곱 신경망 (CNN)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="합성곱-신경망-CNN"><a href="#합성곱-신경망-CNN" class="headerlink" title="합성곱 신경망 ( CNN )"></a>합성곱 신경망 ( CNN )</h1><ul>
<li><p>로지스틱 회귀(일반 ML 모형): 81%</p>
<ul>
<li>1950년대</li>
</ul>
</li>
<li><p>인공신경망 (딥러닝 초기 모형): 87%</p>
<ul>
<li>1940 ~ 80년대</li>
</ul>
</li>
<li><p>합성곱(Convolution, CNN): 이미지 관련</p>
<ul>
<li>이미지의 특성을 잡아내는 알고리즘</li>
<li>코드보다는 용어에 초점</li>
<li>변천사: alexnet (2012) - &gt; resnet - &gt; efficientnet 기타 등등…</li>
<li>채널(색 성분), 이미지의 넓이, 크기[&#x3D;높이] (파라미터 튜닝)</li>
<li>Vision Transformer (논문): 이미지 분류 부분의 판도를 크게 바꾼 논문</li>
</ul>
</li>
<li><p>비디오</p>
<ul>
<li>객체인식 (Object Detection) 위주</li>
<li>Yolo (논문): 합성곱 신경망( CNN ) 기반으로 작성됨.</li>
</ul>
</li>
<li><p>순환 신경망(RNN) - LSTM (Long Short-Term Memory models)</p>
<ul>
<li>구글 2017년 Transformer (논문) [자연어 처리 관련]</li>
</ul>
</li>
</ul>
<h1 id="합성곱의-장점"><a href="#합성곱의-장점" class="headerlink" title="합성곱의 장점"></a>합성곱의 장점</h1><ul>
<li>기존: 1차원 배열에서만 연산이 가능</li>
<li>2차원 배열에도 연산을 할 수 있도록 구현돰<ul>
<li>선형대수: 행렬을 이용하여 선형적인 문제를 해결. 행렬의 연산만을 다루는 것이 아니라, 공학적인 문제를 행렬의 형태로 정의하고 그 해답을 구하는 과정과 방법</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">keras.layers.Conv2D(<span class="number">10</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation= <span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"><span class="comment"># 매개변수 명 filters를 적은 정식 명칭</span></span><br><span class="line"><span class="comment"># keras.layers.Conv2D(filters= 10, kernel_size=(3, 3), activation= &#x27;relu&#x27;)</span></span><br><span class="line"><span class="comment"># activation= &#x27;relu&#x27; ==&gt; 연산중 0으로 나오는 값들은 제외</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;keras.layers.convolutional.Conv2D at 0x7facca8a1410&gt;
</code></pre>
<h2 id="패딩의-목적"><a href="#패딩의-목적" class="headerlink" title="패딩의 목적"></a>패딩의 목적</h2><ul>
<li>배열의 크기를 조정하더라도 이미지의 원 특성이 손실되는것을 방지</li>
<li>패딩이 적용되지 않으면 각 모서리의 데이터는 한번씩밖에 읽히지 않음</li>
<li>세임(same) 패딩: 입력 주위에 0이나 1로 패딩하는것</li>
<li>밸리드(valid) 패딩: 패딩 없이 순수한 입력 배열에서만 합성곱을 진행. (특성 맵의 크기가 줄어듦)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 세임패딩 적용</span></span><br><span class="line">keras.layers.Conv2D(<span class="number">10</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                    activation= <span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                    padding= <span class="string">&#x27;same&#x27;</span>) </span><br></pre></td></tr></table></figure>




<pre><code>&lt;keras.layers.convolutional.Conv2D at 0x7facc9f66290&gt;
</code></pre>
<h2 id="풀링"><a href="#풀링" class="headerlink" title="풀링"></a>풀링</h2><ul>
<li><p>값을 추출</p>
</li>
<li><p>최대풀링: 필터마다의 최대값을 도출함</p>
</li>
<li><p>if ex) 100 * 100이미지 –&gt; 주요 이미지의 특성만 뽑은 후, 원이미지와 같게 만듬. 이때 크기는 줄어듬 (50 * 50)</p>
</li>
</ul>
<h1 id="합성곱-신경망의-전체-구조"><a href="#합성곱-신경망의-전체-구조" class="headerlink" title="합성곱 신경망의 전체 구조"></a>합성곱 신경망의 전체 구조</h1><ul>
<li><p>1단계: 이미지 데이터 입력</p>
</li>
<li><p>2단계: 합성곱 층</p>
<ul>
<li><ol>
<li>kernel_size + padding</li>
</ol>
</li>
<li><ol start="2">
<li>황설화 함수 적용</li>
</ol>
</li>
<li><ol start="3">
<li>각각의 특성맵을 산출</li>
</ol>
</li>
</ul>
</li>
<li><p>3단계: 풀링층</p>
<ul>
<li><ol>
<li>Max pooling: 최댓값 추출 (풀링 방법 중 하나)</li>
</ol>
</li>
<li><ol start="2">
<li>최종 특성맵</li>
</ol>
</li>
</ul>
</li>
<li><p>이 과정 (1~3단계) 을 계속 반복하는것이 CNN 알고리즘</p>
</li>
<li><p>4단계: 밀집층 (Fully Connected Layer)</p>
</li>
<li><p>5단계: 분류 &#x2F; 예측 값을 산출 (Softmax 활성화 함수)</p>
</li>
</ul>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li><strong>합성곱</strong>: 밀집층과 비슷하게 입력과 가중치를 곱하고 절편을 더하는 선형계산 (각 합성곱은 입력 전체가 아니라 일부만 사용)</li>
<li><strong>채널</strong>: 채널은 색 성분을 의미하며 흑백이미지는 1이며, 각 픽셀은 0 ~ 255사이의 값을 가짐. 이미지는 ‘높이’, ‘너비’, ‘채널’ 이라는 3차원 텐서로 정의됨.</li>
<li><strong>필터[&#x3D;커널]</strong>: 밀집층의 뉴련에 해당. 합성곱 신경망에서 부르는 명칭. (3 * 3) 과 (5 * 5)를 자주 사용</li>
<li><strong>특성 맵</strong>: 합성곱 층이나 풀링 층의 출력 ‘배열’을 의미</li>
<li><strong>패딩</strong>: 합성곱 층의 입력 주위에 추가한 0으로 채워진 픽셀</li>
<li><strong>스트라이드</strong>: 합성곱 층에서 필터가 입력(데이터) 위를 이동하는 간격. 일반적으로 1픽셀 사용</li>
<li><strong>풀링</strong>: 가중치가 없고 특성 맵의 가로 세로 크기를 줄이는 역할. 대표적으로 최대 풀링과 평균 풀링이 있음.</li>
<li><strong>전이학습(Transfer Learning)</strong>: 특정 분야에서 학습된 신경망의 일부 능력을 유사하거나 전혀 새로운 분야에서 사용되는 신경망의 학습에 이용하는 방법</li>
<li><strong>파인튜닝(Fine tuning)</strong>: 기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적에 맞게 변형하고 이미 학습된 모델의 가중치를 미세하게 조정하여 학습시키는 방법<ul>
<li>캐글 경진대회에서 학습 &#x2F; 실습 가능 (클래스 공부 필요)</li>
</ul>
</li>
</ul>
</li>
<li><strong>TensorFlow 패키지</strong><ul>
<li><strong>Keras.layers</strong>: 케라스의 층, 합성곱 층<ul>
<li><strong>Conv2D</strong>: 특별히 위를 이동하는 합성곱<ul>
<li>매개변수 filters: 필터의 개수</li>
<li>매개변수 kernel_size: 필터(커널)의 크기</li>
<li>매개변수 activation: 활성화 함수.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/04/06/0406_Convolution_Neural_Network/" data-id="cl1o8qzjh0000vwnh4s003g21" data-title="합성곱 신경망 (CNN)" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0406_woob-s" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/04/06/0406_woob-s/" class="article-date">
  <time class="dt-published" datetime="2022-04-06T00:00:00.000Z" itemprop="datePublished">2022-04-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/04/06/0406_woob-s/">Kaggle 프로젝트</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="프로젝트-개요"><a href="#프로젝트-개요" class="headerlink" title="프로젝트 개요"></a>프로젝트 개요</h1><ul>
<li>강의명 : 2022년 K-디지털 직업훈련(Training) 사업 - AI데이터플랫폼을 활용한 빅데이터 분석전문가 과정</li>
<li>교과목명 : 빅데이터 분석 및 시각화, AI개발 기초, 인공지능 프로그래밍</li>
<li>프로젝트 주제 : Spaceship Titanic 데이터를 활용한 탑승유무 분류모형 개발</li>
<li>프로젝트 마감일 : 2022년 4월 12일 화요일</li>
<li>강사명 : 정지훈 강사</li>
<li>수강생명 : 황우빈</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This Python 3 environment comes with many helpful analytics libraries installed</span></span><br><span class="line"><span class="comment"># It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python</span></span><br><span class="line"><span class="comment"># For example, here&#x27;s several helpful packages to load</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input data files are available in the read-only &quot;../input/&quot; directory</span></span><br><span class="line"><span class="comment"># For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dirname, _, filenames <span class="keyword">in</span> os.walk(<span class="string">&#x27;/kaggle/input&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        <span class="built_in">print</span>(os.path.join(dirname, filename))</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; </span></span><br><span class="line"><span class="comment"># You can also write temporary files to /kaggle/temp/, but they won&#x27;t be saved outside of the current session</span></span><br></pre></td></tr></table></figure>

<h1 id="Step-1-라이브러리-및-데이터-불러오기"><a href="#Step-1-라이브러리-및-데이터-불러오기" class="headerlink" title="Step.1 라이브러리 및 데이터 불러오기"></a>Step.1 라이브러리 및 데이터 불러오기</h1><ul>
<li>라이브러리 버전 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line"><span class="keyword">from</span> plotly.subplots <span class="keyword">import</span> make_subplots</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objects <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> make_column_transformer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> uniform, randint</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;success&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">    <span class="comment"># PassengerId: 승객 번호, Transported: 전송</span></span><br><span class="line">sample = pd.read_csv(<span class="string">&quot;/kaggle/input/spaceship-titanic/sample_submission.csv&quot;</span>)</span><br><span class="line"><span class="comment"># print(sample.head())</span></span><br><span class="line">test = pd.read_csv(<span class="string">&quot;/kaggle/input/spaceship-titanic/test.csv&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(test.head())</span><br><span class="line">train = pd.read_csv(<span class="string">&quot;/kaggle/input/spaceship-titanic/train.csv&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(train.head())</span><br></pre></td></tr></table></figure>

<h2 id="칼럼-별-설명"><a href="#칼럼-별-설명" class="headerlink" title="칼럼 별 설명:"></a>칼럼 별 설명:</h2><ul>
<li><p>PassengerId: 각 승객의 고유 ID</p>
</li>
<li><p>HomePlanet: 승객이 출발한 행성</p>
</li>
<li><p>CryoSleep: 승객이 항해 기간 동안 애니메이션을 일시 중단하도록 선택했는지 여부를 나타냄</p>
</li>
<li><p>Cabin: 승객이 머물고 있는 객실 번호입니다.</p>
</li>
<li><p>Destination: 승객이 출발할 행성입니다.</p>
</li>
<li><p>Age: 승객의 나이</p>
</li>
<li><p>VIP: 승객이 항해 중 특별 VIP 서비스 비용을 지불했는지 여부.</p>
</li>
<li><p>RoomService: 승객이 룸서비스에 대해 청구한 금액입니다.</p>
</li>
<li><p>Name: 승객의 이름</p>
</li>
<li><p>Transported: 승객이 다른 차원으로 운송되었는지 여부. 예측하려는 대상인 열</p>
</li>
<li><p>train데이터 결측치 유무, 통계 확인</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train.info()</span><br><span class="line">train.describe()</span><br></pre></td></tr></table></figure>

<ul>
<li>test데이터 결측치 유무, 통계 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 결측치 확인</span></span><br><span class="line">test.info()</span><br><span class="line">test.describe()</span><br></pre></td></tr></table></figure>

<h1 id="Step-2-탐색적-자료-분석-EDA"><a href="#Step-2-탐색적-자료-분석-EDA" class="headerlink" title="Step.2 탐색적 자료 분석(EDA)"></a>Step.2 탐색적 자료 분석(EDA)</h1><ul>
<li><p>데이터 시각화</p>
</li>
<li><p>산점도, 막대 그래프 등</p>
</li>
<li><p>그래프 해석해서 설명을 달아야 함.</p>
</li>
<li><p>약간의 데이터 전처리</p>
</li>
<li><p>시각화하기 위한 함수 작성.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># text = &quot;Age&quot;</span></span><br><span class="line"><span class="comment"># train_series = train[text].value_counts()</span></span><br><span class="line"><span class="comment"># train_df = pd.DataFrame(train_series).sort_index()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># test_series = test[text].value_counts()</span></span><br><span class="line"><span class="comment"># test_df = pd.DataFrame(test_series).sort_index()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig = make_subplots(rows= 1,</span></span><br><span class="line"><span class="comment">#                    cols= 1,</span></span><br><span class="line"><span class="comment">#                    column_titles= [&quot;Target Values&quot;],</span></span><br><span class="line"><span class="comment">#                    y_title= &quot;Values&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig.add_trace(go.Scatter(x= df.index, y= train_df[text],</span></span><br><span class="line"><span class="comment">#                     orientation=&quot;v&quot;,</span></span><br><span class="line"><span class="comment">#                         name= &quot;train&quot;),</span></span><br><span class="line"><span class="comment">#                     1, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fig.add_trace(go.Scatter(x= df.index, y= test_df[text],</span></span><br><span class="line"><span class="comment">#                     orientation=&quot;v&quot;),</span></span><br><span class="line"><span class="comment">#                     1, 1)          </span></span><br><span class="line"><span class="comment"># fig.update_layout()</span></span><br><span class="line"><span class="comment"># fig.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">visual</span>(<span class="params">train, test, text</span>):</span><br><span class="line">    </span><br><span class="line">    train_series = train[text].value_counts()</span><br><span class="line">    train_df = pd.DataFrame(train_series).sort_index()</span><br><span class="line">    </span><br><span class="line">    test_series = test[text].value_counts()</span><br><span class="line">    test_df = pd.DataFrame(test_series).sort_index()</span><br><span class="line"></span><br><span class="line">    fig = make_subplots(rows= <span class="number">1</span>,</span><br><span class="line">                       cols= <span class="number">1</span>,</span><br><span class="line">                       column_titles= [<span class="string">&quot;Target Values&quot;</span>],</span><br><span class="line">                       y_title= <span class="string">&quot;Values&quot;</span>)</span><br><span class="line"></span><br><span class="line">    fig.add_trace(go.Scatter(x= train_df.index, y= train_df[text],</span><br><span class="line">                        orientation=<span class="string">&quot;v&quot;</span>,</span><br><span class="line">                            name= <span class="string">&quot;train_data&quot;</span>),</span><br><span class="line">                        <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    fig.add_trace(go.Scatter(x= test_df.index, y= test_df[text],</span><br><span class="line">                        orientation=<span class="string">&quot;v&quot;</span>,</span><br><span class="line">                            name= <span class="string">&quot;test_data&quot;</span>),</span><br><span class="line">                        <span class="number">1</span>, <span class="number">1</span>)          </span><br><span class="line">    fig.update_layout()</span><br><span class="line">    fig.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;Age&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>- 10대 후반에서 30대 후반의 비율이 높은것을 확인 할 수 있음.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;RoomService&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;FoodCourt&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;ShoppingMall&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;Spa&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visual(train, test, <span class="string">&quot;VRDeck&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>- RoomService, FoodCourt, ShoppingMall, Spa, VRDeck의 데이터중 10 미만의 값들이 압도적으로 많은것을 확인 할 수 있다.
</code></pre>
<ul>
<li>결측값들의 개수 찾기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_null = pd.DataFrame(train.isna().<span class="built_in">sum</span>())</span><br><span class="line">train_null= train_null.sort_values(by= <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(train_null)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">test_null = pd.DataFrame(test.isna().<span class="built_in">sum</span>())</span><br><span class="line">test_null= test_null.sort_values(by= <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(test_null)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 결측치데이터 - 시각화</span></span><br><span class="line">fig = make_subplots(rows= <span class="number">1</span>,</span><br><span class="line">                   cols= <span class="number">2</span>,</span><br><span class="line">                   column_titles= [<span class="string">&quot;train data&quot;</span>, <span class="string">&quot;test data&quot;</span>],</span><br><span class="line">                   x_title= <span class="string">&quot;Missing Values&quot;</span>)</span><br><span class="line"></span><br><span class="line">fig.add_trace(go.Bar(x= train_null[<span class="number">0</span>], y= train_null.index,</span><br><span class="line">                    orientation=<span class="string">&quot;h&quot;</span>,),</span><br><span class="line">                    <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">              </span><br><span class="line">fig.add_trace(go.Bar(x= test_null[<span class="number">0</span>], y= test_null.index,</span><br><span class="line">                    orientation=<span class="string">&quot;h&quot;</span>),</span><br><span class="line">                    <span class="number">1</span>, <span class="number">2</span>)          </span><br><span class="line"></span><br><span class="line">fig.update_layout()</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>

<pre><code>- Transported와 PassengerId를 제외하고는 결측치가 존재하는걸 확인 할 수 있음.
</code></pre>
<h1 id="Step-3-데이터-전처리"><a href="#Step-3-데이터-전처리" class="headerlink" title="Step.3 데이터 전처리"></a>Step.3 데이터 전처리</h1><ul>
<li><p>Feature Engineering</p>
</li>
<li><p>머신러닝(ML) 모형을 돌리기 위해 표준화 등 &#x2F; 원핫-인코딩</p>
</li>
<li><p>파생변수(도출변수) 만들기</p>
<ul>
<li>왜 이 변수를 만들었는지에 대한 설명 필요</li>
</ul>
</li>
<li><p>필요한 데이터를 제외하고는 제외</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.head()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target = train[<span class="string">&#x27;Transported&#x27;</span>]</span><br><span class="line">target</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train[<span class="string">&#x27;PassengerId&#x27;</span>].value_counts())  <span class="comment"># x</span></span><br><span class="line"><span class="comment"># train[&#x27;HomePlanet&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;CryoSleep&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="built_in">print</span>(train[<span class="string">&#x27;Cabin&#x27;</span>].value_counts())  <span class="comment"># x</span></span><br><span class="line"><span class="comment"># train[&#x27;Destination&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;Age&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;VIP&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;RoomService&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;FoodCourt&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;ShoppingMall&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;Spa&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="comment"># train[&#x27;VRDeck&#x27;].value_counts()  # o</span></span><br><span class="line"><span class="built_in">print</span>(train[<span class="string">&#x27;Name&#x27;</span>].value_counts())  <span class="comment"># x</span></span><br></pre></td></tr></table></figure>

<pre><code>- 확인 해 본 결과 PassengerId, Cabin, Name의 특성은 예측에 영향을 안줄것으로 추정하여 제외하도록 함.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_data = train.drop([&#x27;PassengerId&#x27;, &#x27;Name&#x27;], axis= 1)</span></span><br><span class="line"><span class="comment"># test_data = test.drop([&#x27;PassengerId&#x27;, &#x27;Name&#x27;], axis= 1)</span></span><br><span class="line"></span><br><span class="line">train_data = train.drop([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>], axis= <span class="number">1</span>)</span><br><span class="line">test_data = test.drop([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>], axis= <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line"><span class="built_in">print</span>(test_data.shape)</span><br></pre></td></tr></table></figure>

<ul>
<li>결측치를 float 타입은 mean()으로 object 타입은 최빈값으로 채우기 위해 각각의 데이터를 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.info()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># float</span></span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;Age&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;RoomService&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;FoodCourt&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;ShoppingMall&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;Spa&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;VRDeck&quot;</span>].mean())</span><br><span class="line"><span class="comment"># object</span></span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;HomePlanet&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;CryoSleep&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;Destination&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(train_data[<span class="string">&quot;VIP&quot;</span>].mode())</span><br></pre></td></tr></table></figure>

<ul>
<li>train데이터 결측값 대체하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># float</span></span><br><span class="line">train_data[<span class="string">&#x27;Age&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;Age&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;RoomService&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;RoomService&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;FoodCourt&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;FoodCourt&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;ShoppingMall&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;ShoppingMall&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;Spa&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;Spa&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;VRDeck&#x27;</span>].replace(np.nan, train_data[<span class="string">&#x27;VRDeck&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># object</span></span><br><span class="line">train_data[<span class="string">&#x27;HomePlanet&#x27;</span>].replace(np.nan, <span class="string">&#x27;Earth&#x27;</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;Destination&#x27;</span>].replace(np.nan, <span class="string">&#x27;TRAPPIST-1e&#x27;</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;CryoSleep&#x27;</span>].replace(np.nan, <span class="literal">False</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">train_data[<span class="string">&#x27;VIP&#x27;</span>].replace(np.nan, <span class="literal">False</span>, inplace= <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_data.isna().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_data.info()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># float</span></span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;Age&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;RoomService&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;FoodCourt&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;ShoppingMall&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;Spa&quot;</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;VRDeck&quot;</span>].mean())</span><br><span class="line"><span class="comment"># object</span></span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;HomePlanet&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;CryoSleep&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;Destination&quot;</span>].mode())</span><br><span class="line"><span class="built_in">print</span>(test_data[<span class="string">&quot;VIP&quot;</span>].mode())</span><br></pre></td></tr></table></figure>

<ul>
<li>test데이터 결측값 대체하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># float</span></span><br><span class="line">test_data[<span class="string">&#x27;Age&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;Age&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;RoomService&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;RoomService&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;FoodCourt&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;FoodCourt&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;ShoppingMall&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;ShoppingMall&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;Spa&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;Spa&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;VRDeck&#x27;</span>].replace(np.nan, test_data[<span class="string">&#x27;VRDeck&#x27;</span>].mean(), inplace= <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># object</span></span><br><span class="line">test_data[<span class="string">&#x27;HomePlanet&#x27;</span>].replace(np.nan, <span class="string">&#x27;Earth&#x27;</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;Destination&#x27;</span>].replace(np.nan, <span class="string">&#x27;TRAPPIST-1e&#x27;</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;CryoSleep&#x27;</span>].replace(np.nan, <span class="literal">False</span>, inplace= <span class="literal">True</span>)</span><br><span class="line">test_data[<span class="string">&#x27;VIP&#x27;</span>].replace(np.nan, <span class="literal">False</span>, inplace= <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_data.isna().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>

<pre><code> -결측값들 성공적으로 제거!
</code></pre>
<h2 id="원핫인코딩"><a href="#원핫인코딩" class="headerlink" title="원핫인코딩"></a>원핫인코딩</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Transported의 True는 1로, False는 0으로 대체</span></span><br><span class="line">train_data[<span class="string">&#x27;Transported&#x27;</span>] = train_data[<span class="string">&#x27;Transported&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="literal">True</span>: <span class="number">1</span>, <span class="literal">False</span>: <span class="number">0</span>&#125;)</span><br><span class="line">categorical = [<span class="string">&#x27;HomePlanet&#x27;</span>, <span class="string">&#x27;Destination&#x27;</span>, <span class="string">&#x27;CryoSleep&#x27;</span>, <span class="string">&#x27;VIP&#x27;</span>]</span><br><span class="line"></span><br><span class="line">transformer = make_column_transformer(</span><br><span class="line">(OneHotEncoder(), categorical),</span><br><span class="line">remainder = <span class="string">&#x27;passthrough&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_transformed = transformer.fit_transform(train_data[categorical])</span><br><span class="line">train_transformed_df = pd.DataFrame(train_transformed, columns= transformer.get_feature_names_out())</span><br><span class="line">train_data = pd.concat([train_data, train_transformed_df], axis= <span class="number">1</span>)</span><br><span class="line">train_data = train_data.drop(categorical, axis= <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">test_transformed = transformer.fit_transform(test_data[categorical])</span><br><span class="line">test_transformed_df = pd.DataFrame(test_transformed, columns= transformer.get_feature_names_out())</span><br><span class="line">test_data = pd.concat([test_data, test_transformed_df], axis= <span class="number">1</span>)</span><br><span class="line">test_data = test_data.drop(categorical, axis= <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;success&quot;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Step-4-머신러닝-모형-개발"><a href="#Step-4-머신러닝-모형-개발" class="headerlink" title="Step.4 머신러닝 모형 개발"></a>Step.4 머신러닝 모형 개발</h1><ul>
<li><p>모형에 대한 설명 필요</p>
</li>
<li><p>모형 1~2개 사용 권장</p>
</li>
<li><p>교차 검증</p>
</li>
<li><p>하이퍼 파라미터 튜닝</p>
<ul>
<li>랜덤서치(매개변수(max_depth))</li>
<li>그래드서치</li>
</ul>
</li>
<li><p>독립변수와 종속변수를 구분</p>
<ul>
<li>독립변수: x</li>
<li>종속변수: Transported &#x3D;&#x3D; y</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_cols = test_data.columns</span><br><span class="line">x = train_data[x_cols].to_numpy()</span><br><span class="line">y = train_data[<span class="string">&#x27;Transported&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련데이터를 검증데이터로 분리<ul>
<li>검증데이터: val</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_val, y_train, y_val = train_test_split(x, y, test_size= <span class="number">0.3</span>, random_state= <span class="number">42</span>)</span><br><span class="line">x_train.shape,x_val.shape,y_train.shape,y_val.shape</span><br></pre></td></tr></table></figure>

<h2 id="랜덤서치"><a href="#랜덤서치" class="headerlink" title="랜덤서치"></a>랜덤서치</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span>: uniform(<span class="number">0.0001</span>, <span class="number">0.001</span>),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: randint(<span class="number">20</span>, <span class="number">50</span>),</span><br><span class="line">    <span class="string">&#x27;min_samples_split&#x27;</span>: randint(<span class="number">2</span>, <span class="number">25</span>),</span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: randint(<span class="number">1</span>, <span class="number">25</span>),&#125;</span><br><span class="line">gs = RandomizedSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>), params,  <span class="comment"># n_iter: 파라미터 검색 횟수</span></span><br><span class="line">                        n_iter= <span class="number">100</span>, n_jobs= -<span class="number">1</span>, random_state= <span class="number">42</span>)  <span class="comment"># n_jobs: cpu코어 수</span></span><br><span class="line"></span><br><span class="line">gs.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">max</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt.score(x_val, y_val))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;success&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="교차검증"><a href="#교차검증" class="headerlink" title="교차검증"></a>교차검증</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_validate(dt, x_train, y_train)</span><br><span class="line">scores</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="comment"># 평균 점수 0.7903040262941661</span></span><br></pre></td></tr></table></figure>

<ul>
<li>StratifiedKFold()로 Fold 교차검증을 높여봄.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_validate(dt, x_train, y_train, cv= StratifiedKFold())</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">splitter = StratifiedKFold(n_splits=<span class="number">200</span>, shuffle= <span class="literal">True</span>, random_state= <span class="number">42</span>)</span><br><span class="line">scores = cross_validate(dt, x_train, y_train, cv= splitter)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<p>GridSearchCV()의 하이퍼 파라미터를 이용해봄.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">&#x27;min_impurity_decrease&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>]&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>),params, n_jobs= -<span class="number">1</span>)</span><br><span class="line">gs.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>

<ul>
<li>gs로 x,y train데이터 훈련</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt= gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt)</span><br><span class="line"><span class="built_in">print</span>(dt.score(x_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li>gs로 x,y val데이터 훈련</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>),params, n_jobs= -<span class="number">1</span>)</span><br><span class="line">gs.fit(x_val, y_val)</span><br><span class="line"></span><br><span class="line">dt= gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt)</span><br><span class="line"><span class="built_in">print</span>(dt.score(x_val, y_val))</span><br><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">&#x27;min_impurity_decrease&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>],</span><br><span class="line">          <span class="string">&#x27;max_depth&#x27;</span>: <span class="built_in">range</span>(<span class="number">5</span>, <span class="number">20</span>, <span class="number">1</span>),</span><br><span class="line">         <span class="string">&#x27;min_samples_split&#x27;</span>: <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">100</span>, <span class="number">10</span>)&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">max</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<ul>
<li>LightGBM 사용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lgb = LGBMClassifier(random_state= <span class="number">42</span>)</span><br><span class="line">lgb</span><br></pre></td></tr></table></figure>

<h1 id="Step-5-모형-평가"><a href="#Step-5-모형-평가" class="headerlink" title="Step.5 모형 평가"></a>Step.5 모형 평가</h1><ul>
<li><p>훈련데이터를 쪼개어 훈련데이터 + 검증데이터 분리</p>
</li>
<li><p>정확도 비교</p>
</li>
<li><p>혼동행렬(confusion Matrix) 설명</p>
</li>
<li><p>cross_validate() 활용</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 1st challenge</span></span><br><span class="line">splitter = StratifiedKFold(n_splits = <span class="number">5</span>, shuffle = <span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(lgb, x_train, y_train, return_train_score = <span class="literal">True</span>, cv=splitter)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train Acc.&quot;</span>, np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test Acc.&quot;</span>, np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<ul>
<li>검증데이터를 활용하여 정확도를 예상해본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1st challenge</span></span><br><span class="line"></span><br><span class="line">lgb.fit(x_train, y_train)</span><br><span class="line">y_pred = lgb.predict(x_val)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Acc.&quot;</span>, accuracy_score(y_val, y_pred))</span><br><span class="line"><span class="comment"># Acc. 0.7864263803680982</span></span><br></pre></td></tr></table></figure>

<h2 id="혼동행렬-오분류-비용"><a href="#혼동행렬-오분류-비용" class="headerlink" title="혼동행렬 - 오분류 비용"></a>혼동행렬 - 오분류 비용</h2><ul>
<li><p><strong>나무위키 정의</strong>: 어떤 개인이나 모델, 검사도구, 알고리즘의 ‘진단’, ‘분류’, ‘판별’, ‘예측’능력을 평가하기 위해 고안된 표. 오류행렬(error matrix)이라고도 하며, 국내에는 오분류표라고 번역되기도 한다.</p>
</li>
<li><p>표로 나타내기.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">confusion_matrix</span>():</span><br><span class="line">    col = [<span class="string">&quot;실제로 맞았다  &quot;</span>, <span class="string">&quot;  실제로 틀렸다&quot;</span>]</span><br><span class="line">    ind = [<span class="string">&quot;맞을것이다&quot;</span>, <span class="string">&quot;틀릴것이다&quot;</span>]</span><br><span class="line">    con = [[<span class="string">&quot;예측 성공&quot;</span>, <span class="string">&quot;예측 실패&quot;</span>], [<span class="string">&quot;예측 실패&quot;</span>, <span class="string">&quot;예측 성공&quot;</span>]]</span><br><span class="line">    matrix = pd.DataFrame(con, columns=col, index=ind)</span><br><span class="line">    <span class="built_in">print</span>(matrix)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">confusion_matrix()</span><br></pre></td></tr></table></figure>

<pre><code>- True, False 기준에서 작성했기에 2 by 2의 모습
- 기준을 어떻게 잡느냐에 따라서 3 by 3 이상의 다등급 분류를 나타내는 혼동행렬로 나타낼 수 있다.
</code></pre>
<h1 id="Step-6-제출"><a href="#Step-6-제출" class="headerlink" title="Step.6 제출"></a>Step.6 제출</h1><ul>
<li>제출 양식 샘플은 만들어줌.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1st challenge</span></span><br><span class="line">test_preds = lgb.predict(test_data.to_numpy())</span><br><span class="line">sample[<span class="string">&#x27;Transported&#x27;</span>] = test_preds.astype(<span class="string">&quot;bool&quot;</span>)</span><br><span class="line">sample.to_csv(<span class="string">&quot;submission.csv&quot;</span>,index=<span class="literal">False</span>)</span><br><span class="line">sample.head()</span><br></pre></td></tr></table></figure>

<h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><ul>
<li>다른 사람의 code 설명을 쭉 따라치는경우<ul>
<li>노트북 표절 방지 위해서, 참조한 코드는 반드시 링크 걸어둘것</li>
<li>저자 이름, 글 제목, 링크 주소</li>
</ul>
</li>
</ul>
<h1 id="마감일"><a href="#마감일" class="headerlink" title="마감일"></a>마감일</h1><ul>
<li>4월 12일 17시 40분</li>
<li>제출 형태<ul>
<li>Leaderboard 랭킹 사진 캡처</li>
<li>고용노동부 보고 양식 (다음주에 확인하고 알려주실 예정)</li>
</ul>
</li>
</ul>
<h1 id="My-Note"><a href="#My-Note" class="headerlink" title="My_Note"></a>My_Note</h1><ul>
<li>value_counts(): 값 별 개수 세기</li>
<li>Pandas라이브러리<ul>
<li>fillna(): 결측값을 지정한 값으로 채움</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/04/06/0406_woob-s/" data-id="cl1o8qzjp0001vwnhcdksetfj" data-title="Kaggle 프로젝트" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0404_Deep_Neural_Network" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/04/05/0404_Deep_Neural_Network/" class="article-date">
  <time class="dt-published" datetime="2022-04-05T00:00:00.000Z" itemprop="datePublished">2022-04-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/04/05/0404_Deep_Neural_Network/">심층_신경망</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="심증-신경망"><a href="#심증-신경망" class="headerlink" title="심증 신경망"></a>심증 신경망</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line">(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_scaled = train_input / <span class="number">255.0</span></span><br><span class="line">train_scaled = train_scaled.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">train_scaled, val_scaled, train_target, val_target = train_test_split(</span><br><span class="line">    train_scaled, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>입력값 및 출력값 층 만들기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dense1 = keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>, input_shape=(<span class="number">784</span>,))</span><br><span class="line">dense2 = keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="심층-신경망-만들기"><a href="#심층-신경망-만들기" class="headerlink" title="심층 신경망 만들기"></a>심층 신경망 만들기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential([dense1, dense2])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_8 (Dense)             (None, 100)               78500     
                                                                 
 dense_9 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h1 id="층을-추가하는-다른-방법"><a href="#층을-추가하는-다른-방법" class="headerlink" title="층을 추가하는 다른 방법"></a>층을 추가하는 다른 방법</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>, input_shape=(<span class="number">784</span>,), name=<span class="string">&#x27;hidden&#x27;</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, name=<span class="string">&#x27;output&#x27;</span>)</span><br><span class="line">], name=<span class="string">&#x27;패션 MNIST 모델&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;패션 MNIST 모델&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 hidden (Dense)              (None, 100)               78500     
                                                                 
 output (Dense)              (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>, input_shape=(<span class="number">784</span>,)))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_10 (Dense)            (None, 100)               78500     
                                                                 
 dense_11 (Dense)            (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.fit(train_scaled, train_target, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/5
1500/1500 [==============================] - 4s 2ms/step - loss: 0.5603 - accuracy: 0.8106
Epoch 2/5
1500/1500 [==============================] - 4s 2ms/step - loss: 0.4079 - accuracy: 0.8532
Epoch 3/5
1500/1500 [==============================] - 4s 2ms/step - loss: 0.3727 - accuracy: 0.8659
Epoch 4/5
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3509 - accuracy: 0.8736
Epoch 5/5
1500/1500 [==============================] - 4s 2ms/step - loss: 0.3342 - accuracy: 0.8785





&lt;keras.callbacks.History at 0x7f0fbfcf9050&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_6&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_2 (Flatten)         (None, 784)               0         
                                                                 
 dense_12 (Dense)            (None, 100)               78500     
                                                                 
 dense_13 (Dense)            (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h1 id="옵티마이저"><a href="#옵티마이저" class="headerlink" title="옵티마이저"></a>옵티마이저</h1><ul>
<li><p>대체적으로 Adam을 사용하면 됨.</p>
</li>
<li><p>이유: 스텝 방향 &amp; 스템 사이즈를 모두 고려한 옵티마이저</p>
<ul>
<li>스텝 방향만 고려: GD, SGD, Momentum, NAG</li>
<li>스템 사이즈만 고려: GD, SGD, Adagrad, RMSProp</li>
</ul>
</li>
<li><p>오류 방지용 base</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">train_scaled = train_input / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">train_scaled, val_scaled, train_target, val_target = train_test_split(</span><br><span class="line">    train_scaled, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">model.fit(train_scaled, train_target, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/5
1500/1500 [==============================] - 5s 3ms/step - loss: 0.5357 - accuracy: 0.8103
Epoch 2/5
1500/1500 [==============================] - 4s 3ms/step - loss: 0.3911 - accuracy: 0.8590
Epoch 3/5
1500/1500 [==============================] - 4s 3ms/step - loss: 0.3529 - accuracy: 0.8730
Epoch 4/5
1500/1500 [==============================] - 4s 3ms/step - loss: 0.3329 - accuracy: 0.8804
Epoch 5/5
1500/1500 [==============================] - 4s 3ms/step - loss: 0.3182 - accuracy: 0.8872





&lt;keras.callbacks.History at 0x7f0fbfba4950&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(val_scaled, val_target)</span><br></pre></td></tr></table></figure>

<pre><code>375/375 [==============================] - 1s 1ms/step - loss: 0.3537 - accuracy: 0.8813





[0.35373446345329285, 0.8812500238418579]
</code></pre>
<ul>
<li>옵티마이저 실습</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sgd = keras.optimizers.SGD()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=sgd, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>learning_rate &#x3D; 0.1<ul>
<li>랜덤서치, 그리드서치</li>
<li>–&gt; 딥러닝에서도 하이퍼파라미터 튜닝</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sgd = keras.optimizers.SGD(learning_rate= <span class="number">0.1</span>)</span><br><span class="line">sgd = keras.optimizers.SGD(momentum= <span class="number">0.9</span>, nesterov= <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>심층 신경망: 2개 이상의 층을 포함한 신경망. 종종 다층 인공 신경망, 심층 신경망, 딥러닝을 같은 의미로 사용</li>
<li>렐루 함수: 이미지 분류 모데의 은닉층을 많이 사용하는 활성화 함수</li>
<li>옵티마이저: 신경망의 가중치와 절편을 학습하기 위한 알고리즘 또는 방법</li>
</ul>
</li>
<li>TensorFlow 패키지<ul>
<li>add(): 케라스 모델에 층을 추가하는 메서드</li>
<li>summary(): 케라스 모델의 정보를 출력</li>
<li>SGD: 기본 경사 하강법 옵티마이저 클래스</li>
<li>Adagrad: Adagrad 옵티마이저 클래스</li>
<li>RMSprop: RMSprop옵티마이저 클래스</li>
<li>Adam: Adam옵티마이저 클래스</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/04/05/0404_Deep_Neural_Network/" data-id="cl1km1rbd0001pwnh9ypc2bp1" data-title="심층_신경망" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0405_Neural_Network_Model" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/04/05/0405_Neural_Network_Model/" class="article-date">
  <time class="dt-published" datetime="2022-04-05T00:00:00.000Z" itemprop="datePublished">2022-04-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/04/05/0405_Neural_Network_Model/">신경망_모델_훈련</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="신경망-모델-훈련"><a href="#신경망-모델-훈련" class="headerlink" title="신경망 모델 훈련"></a>신경망 모델 훈련</h1><h1 id="손실곡선"><a href="#손실곡선" class="headerlink" title="손실곡선"></a>손실곡선</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">(train_input, train_target), (test_input, test_target) = \</span><br><span class="line">    keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">train_scaled = train_input / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">train_scaled, val_scaled, train_target, val_target = train_test_split(</span><br><span class="line">    train_scaled, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>사용자 정의 함수를 작성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model_fn</span>(<span class="params">a_layer=<span class="literal">None</span></span>):</span><br><span class="line">  model = keras.Sequential()</span><br><span class="line">  model.add(keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">  model.add(keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">  <span class="keyword">if</span> a_layer:</span><br><span class="line">    model.add(a_layer)</span><br><span class="line">  model.add(keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">model = model_fn()</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 784)               0         
                                                                 
 dense (Dense)               (None, 100)               78500     
                                                                 
 dense_1 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<ul>
<li>모델 정의 후, 학습</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics= <span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">5</span>, verbose= <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/5
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3084 - accuracy: 0.8907
Epoch 2/5
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2963 - accuracy: 0.8947
Epoch 3/5
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2866 - accuracy: 0.8985
Epoch 4/5
1500/1500 [==============================] - 4s 3ms/step - loss: 0.2826 - accuracy: 0.9015
Epoch 5/5
1500/1500 [==============================] - 4s 3ms/step - loss: 0.2754 - accuracy: 0.9037
</code></pre>
<ul>
<li>history 객체 무슨 값이 있나??</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(history.history.keys())</span><br></pre></td></tr></table></figure>

<pre><code>dict_keys([&#39;loss&#39;, &#39;accuracy&#39;])
</code></pre>
<ul>
<li>그래프 작성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0405_Neural_Network_Model/output_10_0.png" alt="png"></p>
<ul>
<li>정확도 출력</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0405_Neural_Network_Model/output_12_0.png" alt="png"></p>
<ul>
<li>손실그래프</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn()</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">0</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0405_Neural_Network_Model/output_14_0.png" alt="png"></p>
<ul>
<li>검증 손실</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 중요</span></span><br><span class="line"><span class="comment"># history = model.fit(train_scaled, train_target, epochs=10, verbose=1, </span></span><br><span class="line"><span class="comment">#                     validation_data=(val_scaled, val_target))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.plot(history.history[&#x27;loss&#x27;])</span></span><br><span class="line"><span class="comment"># plt.plot(history.history[&#x27;val_loss&#x27;])</span></span><br><span class="line"><span class="comment"># plt.xlabel(&#x27;epoch&#x27;)</span></span><br><span class="line"><span class="comment"># plt.ylabel(&#x27;loss&#x27;)</span></span><br><span class="line"><span class="comment"># plt.legend([&#x27;train&#x27;, &#x27;val&#x27;])</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn()</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">10</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target))</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/10
1500/1500 [==============================] - 4s 2ms/step - loss: 0.5272 - accuracy: 0.8130 - val_loss: 0.4003 - val_accuracy: 0.8572
Epoch 2/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3944 - accuracy: 0.8576 - val_loss: 0.3871 - val_accuracy: 0.8617
Epoch 3/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3568 - accuracy: 0.8729 - val_loss: 0.3542 - val_accuracy: 0.8726
Epoch 4/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3324 - accuracy: 0.8805 - val_loss: 0.3576 - val_accuracy: 0.8765
Epoch 5/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3198 - accuracy: 0.8861 - val_loss: 0.3562 - val_accuracy: 0.8795
Epoch 6/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3072 - accuracy: 0.8910 - val_loss: 0.3875 - val_accuracy: 0.8758
Epoch 7/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2966 - accuracy: 0.8956 - val_loss: 0.3722 - val_accuracy: 0.8764
Epoch 8/10
1500/1500 [==============================] - 4s 2ms/step - loss: 0.2872 - accuracy: 0.8982 - val_loss: 0.3690 - val_accuracy: 0.8783
Epoch 9/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2840 - accuracy: 0.8990 - val_loss: 0.3649 - val_accuracy: 0.8838
Epoch 10/10
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2745 - accuracy: 0.9041 - val_loss: 0.4154 - val_accuracy: 0.8708
</code></pre>
<p><img src="/Images/0405_Neural_Network_Model/output_17_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 에포크 20으로 늘림</span></span><br><span class="line">model = model_fn()</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target))</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1500/1500 [==============================] - 4s 2ms/step - loss: 0.5319 - accuracy: 0.8131 - val_loss: 0.4284 - val_accuracy: 0.8492
Epoch 2/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3936 - accuracy: 0.8571 - val_loss: 0.3844 - val_accuracy: 0.8645
Epoch 3/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3560 - accuracy: 0.8704 - val_loss: 0.3669 - val_accuracy: 0.8715
Epoch 4/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3353 - accuracy: 0.8792 - val_loss: 0.3503 - val_accuracy: 0.8792
Epoch 5/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3200 - accuracy: 0.8857 - val_loss: 0.3798 - val_accuracy: 0.8707
Epoch 6/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3089 - accuracy: 0.8902 - val_loss: 0.3681 - val_accuracy: 0.8759
Epoch 7/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2984 - accuracy: 0.8945 - val_loss: 0.4130 - val_accuracy: 0.8653
Epoch 8/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2925 - accuracy: 0.8955 - val_loss: 0.3637 - val_accuracy: 0.8847
Epoch 9/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2822 - accuracy: 0.9012 - val_loss: 0.3923 - val_accuracy: 0.8762
Epoch 10/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2762 - accuracy: 0.9031 - val_loss: 0.3755 - val_accuracy: 0.8808
Epoch 11/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2726 - accuracy: 0.9040 - val_loss: 0.3748 - val_accuracy: 0.8794
Epoch 12/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2631 - accuracy: 0.9085 - val_loss: 0.3988 - val_accuracy: 0.8809
Epoch 13/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2600 - accuracy: 0.9087 - val_loss: 0.4310 - val_accuracy: 0.8813
Epoch 14/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2549 - accuracy: 0.9116 - val_loss: 0.4131 - val_accuracy: 0.8844
Epoch 15/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2533 - accuracy: 0.9139 - val_loss: 0.4343 - val_accuracy: 0.8820
Epoch 16/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2479 - accuracy: 0.9151 - val_loss: 0.4254 - val_accuracy: 0.8862
Epoch 17/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2406 - accuracy: 0.9166 - val_loss: 0.4298 - val_accuracy: 0.8858
Epoch 18/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2369 - accuracy: 0.9176 - val_loss: 0.4401 - val_accuracy: 0.8852
Epoch 19/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2347 - accuracy: 0.9192 - val_loss: 0.4332 - val_accuracy: 0.8883
Epoch 20/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2316 - accuracy: 0.9211 - val_loss: 0.4471 - val_accuracy: 0.8796
</code></pre>
<p><img src="/Images/0405_Neural_Network_Model/output_18_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 옵티마이저 적용</span></span><br><span class="line">model = model_fn()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= <span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target))</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.5265 - accuracy: 0.8185 - val_loss: 0.4242 - val_accuracy: 0.8491
Epoch 2/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3969 - accuracy: 0.8575 - val_loss: 0.3747 - val_accuracy: 0.8667
Epoch 3/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3550 - accuracy: 0.8715 - val_loss: 0.3502 - val_accuracy: 0.8747
Epoch 4/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3292 - accuracy: 0.8795 - val_loss: 0.3671 - val_accuracy: 0.8695
Epoch 5/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3079 - accuracy: 0.8876 - val_loss: 0.3563 - val_accuracy: 0.8748
Epoch 6/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2941 - accuracy: 0.8918 - val_loss: 0.3482 - val_accuracy: 0.8759
Epoch 7/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2816 - accuracy: 0.8972 - val_loss: 0.3568 - val_accuracy: 0.8693
Epoch 8/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2702 - accuracy: 0.9002 - val_loss: 0.3165 - val_accuracy: 0.8883
Epoch 9/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2575 - accuracy: 0.9045 - val_loss: 0.3286 - val_accuracy: 0.8808
Epoch 10/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2501 - accuracy: 0.9072 - val_loss: 0.3677 - val_accuracy: 0.8698
Epoch 11/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2387 - accuracy: 0.9115 - val_loss: 0.3232 - val_accuracy: 0.8850
Epoch 12/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2338 - accuracy: 0.9126 - val_loss: 0.3256 - val_accuracy: 0.8865
Epoch 13/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2259 - accuracy: 0.9145 - val_loss: 0.3364 - val_accuracy: 0.8852
Epoch 14/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2178 - accuracy: 0.9184 - val_loss: 0.3426 - val_accuracy: 0.8797
Epoch 15/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2121 - accuracy: 0.9204 - val_loss: 0.3343 - val_accuracy: 0.8855
Epoch 16/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2076 - accuracy: 0.9230 - val_loss: 0.3224 - val_accuracy: 0.8903
Epoch 17/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2025 - accuracy: 0.9222 - val_loss: 0.3432 - val_accuracy: 0.8807
Epoch 18/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.1963 - accuracy: 0.9260 - val_loss: 0.3421 - val_accuracy: 0.8889
Epoch 19/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.1904 - accuracy: 0.9277 - val_loss: 0.3387 - val_accuracy: 0.8859
Epoch 20/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.1869 - accuracy: 0.9308 - val_loss: 0.3481 - val_accuracy: 0.8863
</code></pre>
<p><img src="/Images/0405_Neural_Network_Model/output_19_1.png" alt="png"></p>
<h1 id="드롭아웃"><a href="#드롭아웃" class="headerlink" title="드롭아웃"></a>드롭아웃</h1><ul>
<li>제프리 힌턴</li>
<li>기본적으로 모든 파라미터를 연산하는것이 원칙<ul>
<li>but. 일부 뉴런에서 출력이 없는 뉴런 발생</li>
<li>–&gt; 기존 일부 뉴런은 계산에서 제외 시킴</li>
</ul>
</li>
<li>인공신경망 (뇌과학)<ul>
<li>값이 쏠림 현상이 발생 %&#x3D; 뇌에 피가 고인 현상 %&#x3D; 뇌출혈</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn(keras.layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_6&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_6 (Flatten)         (None, 784)               0         
                                                                 
 dense_12 (Dense)            (None, 100)               78500     
                                                                 
 dropout (Dropout)           (None, 100)               0         
                                                                 
 dense_13 (Dense)            (None, 10)                1010      
                                                                 
=================================================================
Total params: 79,510
Trainable params: 79,510
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 드롭아웃 적용</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer= <span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target))</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.5938 - accuracy: 0.7927 - val_loss: 0.4280 - val_accuracy: 0.8453
Epoch 2/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.4419 - accuracy: 0.8411 - val_loss: 0.4036 - val_accuracy: 0.8522
Epoch 3/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.4047 - accuracy: 0.8537 - val_loss: 0.3683 - val_accuracy: 0.8670
Epoch 4/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3828 - accuracy: 0.8608 - val_loss: 0.3504 - val_accuracy: 0.8707
Epoch 5/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3714 - accuracy: 0.8635 - val_loss: 0.3404 - val_accuracy: 0.8767
Epoch 6/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3539 - accuracy: 0.8703 - val_loss: 0.3410 - val_accuracy: 0.8760
Epoch 7/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3483 - accuracy: 0.8721 - val_loss: 0.3377 - val_accuracy: 0.8776
Epoch 8/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3357 - accuracy: 0.8763 - val_loss: 0.3315 - val_accuracy: 0.8807
Epoch 9/20
1500/1500 [==============================] - 4s 3ms/step - loss: 0.3314 - accuracy: 0.8773 - val_loss: 0.3301 - val_accuracy: 0.8771
Epoch 10/20
1500/1500 [==============================] - 4s 2ms/step - loss: 0.3214 - accuracy: 0.8812 - val_loss: 0.3274 - val_accuracy: 0.8787
Epoch 11/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3180 - accuracy: 0.8831 - val_loss: 0.3325 - val_accuracy: 0.8813
Epoch 12/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.3121 - accuracy: 0.8852 - val_loss: 0.3194 - val_accuracy: 0.8821
Epoch 13/20
1500/1500 [==============================] - 4s 2ms/step - loss: 0.3078 - accuracy: 0.8860 - val_loss: 0.3408 - val_accuracy: 0.8773
Epoch 14/20
1500/1500 [==============================] - 4s 3ms/step - loss: 0.3026 - accuracy: 0.8865 - val_loss: 0.3316 - val_accuracy: 0.8817
Epoch 15/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2940 - accuracy: 0.8890 - val_loss: 0.3322 - val_accuracy: 0.8831
Epoch 16/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2955 - accuracy: 0.8900 - val_loss: 0.3196 - val_accuracy: 0.8870
Epoch 17/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2919 - accuracy: 0.8908 - val_loss: 0.3243 - val_accuracy: 0.8853
Epoch 18/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2835 - accuracy: 0.8925 - val_loss: 0.3362 - val_accuracy: 0.8830
Epoch 19/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2844 - accuracy: 0.8926 - val_loss: 0.3243 - val_accuracy: 0.8819
Epoch 20/20
1500/1500 [==============================] - 3s 2ms/step - loss: 0.2812 - accuracy: 0.8943 - val_loss: 0.3184 - val_accuracy: 0.8881
</code></pre>
<p><img src="/Images/0405_Neural_Network_Model/output_22_1.png" alt="png"></p>
<pre><code>- 드롭아웃을 적용했더니 과대적합 되던 모형이 많이 완화됨.
</code></pre>
<h1 id="모댈-저장과-복원"><a href="#모댈-저장과-복원" class="headerlink" title="모댈 저장과 복원"></a>모댈 저장과 복원</h1><ul>
<li>개발자: 정확도는 중요하지 않음<ul>
<li>딥러닝 모델 활용해서 웹앱을 개발하는게 목적</li>
</ul>
</li>
<li>분석가 &amp; 머신러닝 엔지니어: 캐글 대회 (정확도 검증 필수)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save_weights(<span class="string">&#x27;model-weights.h5&#x27;</span>)</span><br><span class="line">model.save(<span class="string">&#x27;model-whole.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>모델 불러오기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn(keras.layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.load_weights(<span class="string">&#x27;model-weights.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">val_labels = np.argmax(model.predict(val_scaled), axis=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(val_labels == val_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8810833333333333
</code></pre>
<h1 id="콜백"><a href="#콜백" class="headerlink" title="콜백"></a>콜백</h1><ul>
<li>model.checkpoint(): 체크포인트를 기록</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn(keras.layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">0</span>, </span><br><span class="line">          validation_data=(val_scaled, val_target),</span><br><span class="line">          callbacks=[checkpoint_cb])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;keras.callbacks.History at 0x7f673a848ad0&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = keras.models.load_model(<span class="string">&#x27;best-model.h5&#x27;</span>)</span><br><span class="line">model.evaluate(val_scaled, val_target)</span><br></pre></td></tr></table></figure>

<pre><code>375/375 [==============================] - 1s 1ms/step - loss: 0.3137 - accuracy: 0.8893





[0.31372642517089844, 0.8893333077430725]
</code></pre>
<ul>
<li>Early Stopping<ul>
<li>조기 종료</li>
<li>에포크를 많이 주면 많이 줄수록 성능이 좋아야 하는 것이 원리 (가중치 업데이트 &#x2F; 기울기가 계속 미분)</li>
<li>if) 에포크 100 &#x2F; 50 에포크 시점과 90에포크 시점 성능 차이 없음</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = model_fn(keras.layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;best-model.h5&#x27;</span>, </span><br><span class="line">                                                save_best_only=<span class="literal">True</span>)</span><br><span class="line">early_stopping_cb = keras.callbacks.EarlyStopping(patience=<span class="number">2</span>,</span><br><span class="line">                                                  restore_best_weights=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(train_scaled, train_target, epochs=<span class="number">20</span>, verbose=<span class="number">0</span>, </span><br><span class="line">                    validation_data=(val_scaled, val_target),</span><br><span class="line">                    callbacks=[checkpoint_cb, early_stopping_cb])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(early_stopping_cb.stopped_epoch)</span><br></pre></td></tr></table></figure>

<pre><code>14
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0405_Neural_Network_Model/output_35_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li><p>키워드:</p>
<ul>
<li>드롭아웃: 은닉층에 있는 뉴런의 출력을 랜덤하게 꺼서 과대적합을 막는 기법</li>
<li>콜백: 케라스 모델을 훈련하는 도중에 어떤 작업을 수행 할 수 있도록 도와주는 도구</li>
<li>조기종료: 검증점수가 더 이상 감소하지 않고 상승하여 과대적합이 일어나면 훈련을 계속 진행하지 않고 멈추는 기법</li>
</ul>
</li>
<li><p>TensorFlow 패키지</p>
<ul>
<li>Dropout: 드롭아웃 층</li>
<li>save_weights(): 모든 층의 가중치와 절편을 파일에 저장</li>
<li>load_weights(): 모든 층의 가중치와 절편을 파일에 읽음</li>
<li>save(): 모델 구조와 모든 가중치와 절편을 파일에 저장</li>
<li>load_model(): model.save()로 저장된 모델을 로드</li>
<li>ModelCheckpoint: 케라스 모델과 가중치를 일정 간격으로 저장</li>
<li>EarlyStopping: 관심지표가 더이상 향상하지 않으면 훈련을 중지</li>
</ul>
</li>
<li><p>NumPy 패키지</p>
<ul>
<li>argmax: 배열에서 축을 따라 최댓값의 인덱스 반환<ul>
<li>매개변수 axis: 어떤축을 따라 최댓값을 찾을지 지정 [default: None] (전체 배열에서 최댓값)</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/04/05/0405_Neural_Network_Model/" data-id="cl1m1avpg0000l8nh2hiyg4k0" data-title="신경망_모델_훈련" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0405_Pipeline" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/04/05/0405_Pipeline/" class="article-date">
  <time class="dt-published" datetime="2022-04-05T00:00:00.000Z" itemprop="datePublished">2022-04-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/04/05/0405_Pipeline/">파이프_라인_(데이터_전처리)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="데이터-누수-방지-위한-모델링-기법"><a href="#데이터-누수-방지-위한-모델링-기법" class="headerlink" title="데이터 누수 방지 위한 모델링 기법:"></a>데이터 누수 방지 위한 모델링 기법:</h1><h3 id="파이프라인-구축"><a href="#파이프라인-구축" class="headerlink" title="파이프라인 구축"></a>파이프라인 구축</h3><ul>
<li>수능시험 &#x3D; 최종테스트 데이터</li>
<li>모의고사 or 기출문제 &#x3D; 검증데이터</li>
<li>교과서 문제지 &#x3D; 훈련데이터</li>
<li>머신러닝 엔지니어 : MLOps (선행되어야 하는 코드 조건, Pipeline 형태로 구축)<ul>
<li>머신러닝 코드 자동화 가능, 운영 가능</li>
<li>개발 업계의 최상위 연봉자</li>
</ul>
</li>
</ul>
<h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/data/daily-bike-share.csv&#x27;</span>)</span><br><span class="line">data.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 731 entries, 0 to 730
Data columns (total 14 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   instant     731 non-null    int64  
 1   dteday      731 non-null    object 
 2   season      731 non-null    int64  
 3   yr          731 non-null    int64  
 4   mnth        731 non-null    int64  
 5   holiday     731 non-null    int64  
 6   weekday     731 non-null    int64  
 7   workingday  731 non-null    int64  
 8   weathersit  731 non-null    int64  
 9   temp        731 non-null    float64
 10  atemp       731 non-null    float64
 11  hum         731 non-null    float64
 12  windspeed   731 non-null    float64
 13  rentals     731 non-null    int64  
dtypes: float64(4), int64(9), object(1)
memory usage: 80.1+ KB
</code></pre>
<h1 id="데이터-추출"><a href="#데이터-추출" class="headerlink" title="데이터 추출"></a>데이터 추출</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cols = [<span class="string">&#x27;season&#x27;</span>, <span class="string">&#x27;mnth&#x27;</span>, <span class="string">&#x27;holiday&#x27;</span>, <span class="string">&#x27;weekday&#x27;</span>, <span class="string">&#x27;workingday&#x27;</span>, <span class="string">&#x27;weathersit&#x27;</span>, <span class="string">&#x27;temp&#x27;</span>, <span class="string">&#x27;atemp&#x27;</span>, <span class="string">&#x27;hum&#x27;</span>, <span class="string">&#x27;windspeed&#x27;</span>, <span class="string">&#x27;rentals&#x27;</span>]</span><br><span class="line">data = data[cols]</span><br><span class="line">data.info()</span><br><span class="line"><span class="comment"># data[&#x27;mnth&#x27;].value_counts()</span></span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 731 entries, 0 to 730
Data columns (total 11 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   season      731 non-null    int64  
 1   mnth        731 non-null    int64  
 2   holiday     731 non-null    int64  
 3   weekday     731 non-null    int64  
 4   workingday  731 non-null    int64  
 5   weathersit  731 non-null    int64  
 6   temp        731 non-null    float64
 7   atemp       731 non-null    float64
 8   hum         731 non-null    float64
 9   windspeed   731 non-null    float64
 10  rentals     731 non-null    int64  
dtypes: float64(4), int64(7)
memory usage: 62.9 KB
</code></pre>
<ul>
<li><p>기존: 데이터 불러오기 -&gt; 데이터 전처리 -&gt; 피처공학(원핫인코딩) -&gt; 데이터셋 분리 -&gt; 모델링 코드 -&gt; 모델평가</p>
</li>
<li><p>파이프라인: 데이터 불러오기 -&gt; 데이터 전처리 -&gt; 데이터셋 분리 -&gt; 파이프라인 구축 (피처공학, 모델링 코드) -&gt; 모델평가</p>
</li>
</ul>
<h1 id="데이터셋-분리"><a href="#데이터셋-분리" class="headerlink" title="데이터셋 분리"></a>데이터셋 분리</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X = data.drop(<span class="string">&#x27;rentals&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line">y = data[<span class="string">&#x27;rentals&#x27;</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>Data Prepocessing</p>
<ul>
<li>결측치 수동으로 채우거나</li>
<li>불필요한 변수를 제거하거나</li>
<li>이상치를 제거하거나</li>
<li>파생변수를 만들거나 등등</li>
</ul>
</li>
<li><p>Feature Engineering</p>
<ul>
<li>기존: 개별적으로 코드 작성</li>
<li>현재: Pipeline 코드로 추가할것</li>
</ul>
</li>
</ul>
<h1 id="Pipeline-구축"><a href="#Pipeline-구축" class="headerlink" title="Pipeline 구축"></a>Pipeline 구축</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, OrdinalEncoder, OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 타입 3가지</span></span><br><span class="line"><span class="comment"># 수치형 데이터, 무자열 데이터</span></span><br><span class="line"><span class="comment"># 문자열 데이터: 범주형(명목형, 서열형 데이터 구분)</span></span><br><span class="line">numeric_transformer = Pipeline(steps=[</span><br><span class="line">       (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;mean&#x27;</span>))</span><br><span class="line">      ,(<span class="string">&#x27;scaler&#x27;</span>, StandardScaler())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">ordinal_transformer = Pipeline(steps=[</span><br><span class="line">       (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;constant&#x27;</span>))</span><br><span class="line">      ,(<span class="string">&#x27;ordEncoder&#x27;</span>, OrdinalEncoder())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">onehot_transformer = Pipeline(steps=[</span><br><span class="line">       (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;constant&#x27;</span>))</span><br><span class="line">      ,(<span class="string">&#x27;oheEncoder&#x27;</span>, OneHotEncoder())                                   </span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 수치형 데이터 및 Categorical 데이터 컬럼 분리</span></span><br><span class="line"></span><br><span class="line">numeric_features = [<span class="string">&#x27;temp&#x27;</span>, <span class="string">&#x27;atemp&#x27;</span>, <span class="string">&#x27;hum&#x27;</span>, <span class="string">&#x27;windspeed&#x27;</span>]</span><br><span class="line">ordinal_features = [<span class="string">&#x27;holiday&#x27;</span>, <span class="string">&#x27;weekday&#x27;</span>, <span class="string">&#x27;workingday&#x27;</span>, <span class="string">&#x27;weathersit&#x27;</span>]</span><br><span class="line">onehot_features  = [<span class="string">&#x27;season&#x27;</span>, <span class="string">&#x27;mnth&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># numeric_features = data.select_dtypes(include=[&#x27;int64&#x27;, &#x27;float64&#x27;]).columns</span></span><br><span class="line"><span class="comment"># categorical_features = data.select_dtypes(include=[&#x27;object&#x27;]).drop([&#x27;Loan_Status&#x27;], axis=1).columns</span></span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">   transformers=[</span><br><span class="line">     (<span class="string">&#x27;numeric&#x27;</span>, numeric_transformer, numeric_features)</span><br><span class="line">   , (<span class="string">&#x27;ord_categorical&#x27;</span>, ordinal_transformer, ordinal_features)</span><br><span class="line">   , (<span class="string">&#x27;ohe_categorical&#x27;</span>, onehot_transformer, onehot_features)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h1 id="모델-적용"><a href="#모델-적용" class="headerlink" title="모델 적용"></a>모델 적용</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"></span><br><span class="line">pipeline = Pipeline(steps = [</span><br><span class="line">               (<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor)</span><br><span class="line">              ,(<span class="string">&#x27;regressor&#x27;</span>, RandomForestRegressor())</span><br><span class="line">           ])</span><br><span class="line"></span><br><span class="line">rf_model = pipeline.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(rf_model)</span><br></pre></td></tr></table></figure>

<pre><code>Pipeline(steps=[(&#39;preprocessor&#39;,
                 ColumnTransformer(transformers=[(&#39;numeric&#39;,
                                                  Pipeline(steps=[(&#39;imputer&#39;,
                                                                   SimpleImputer()),
                                                                  (&#39;scaler&#39;,
                                                                   StandardScaler())]),
                                                  [&#39;temp&#39;, &#39;atemp&#39;, &#39;hum&#39;,
                                                   &#39;windspeed&#39;]),
                                                 (&#39;ord_categorical&#39;,
                                                  Pipeline(steps=[(&#39;imputer&#39;,
                                                                   SimpleImputer(strategy=&#39;constant&#39;)),
                                                                  (&#39;ordEncoder&#39;,
                                                                   OrdinalEncoder())]),
                                                  [&#39;holiday&#39;, &#39;weekday&#39;,
                                                   &#39;workingday&#39;,
                                                   &#39;weathersit&#39;]),
                                                 (&#39;ohe_categorical&#39;,
                                                  Pipeline(steps=[(&#39;imputer&#39;,
                                                                   SimpleImputer(strategy=&#39;constant&#39;)),
                                                                  (&#39;oheEncoder&#39;,
                                                                   OneHotEncoder())]),
                                                  [&#39;season&#39;, &#39;mnth&#39;])])),
                (&#39;regressor&#39;, RandomForestRegressor())])
</code></pre>
<h1 id="모델-평가"><a href="#모델-평가" class="headerlink" title="모델 평가"></a>모델 평가</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">predictions = rf_model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span> (r2_score(y_test, predictions))</span><br></pre></td></tr></table></figure>

<pre><code>0.7623870644942855
</code></pre>
<h1 id="다중모형-개발"><a href="#다중모형-개발" class="headerlink" title="다중모형 개발"></a>다중모형 개발</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">regressors = [</span><br><span class="line">    RandomForestRegressor()</span><br><span class="line">   ,DecisionTreeRegressor()</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># regressors = [pipe_rf, pipe_dt]</span></span><br><span class="line"><span class="keyword">for</span> regressor <span class="keyword">in</span> regressors:</span><br><span class="line">    pipeline = Pipeline(steps = [</span><br><span class="line">               (<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor)</span><br><span class="line">              ,(<span class="string">&#x27;regressor&#x27;</span>,regressor)</span><br><span class="line">           ])</span><br><span class="line">    model = pipeline.fit(X_train, y_train)</span><br><span class="line">    predictions = model.predict(X_test)</span><br><span class="line">    <span class="built_in">print</span>(regressor)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Model r2 score:<span class="subst">&#123;r2_score(predictions, y_test)&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>RandomForestRegressor()
Model r2 score:0.7385832717833691
DecisionTreeRegressor()
Model r2 score:0.6033264470675421
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/04/05/0405_Pipeline/" data-id="cl1m1avq00001l8nhd1erhblx" data-title="파이프_라인_(데이터_전처리)" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0404_Artificial_Neural_Network" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/04/04/0404_Artificial_Neural_Network/" class="article-date">
  <time class="dt-published" datetime="2022-04-04T00:00:00.000Z" itemprop="datePublished">2022-04-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/04/04/0404_Artificial_Neural_Network/">인공_신경망</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="패션-MNIST"><a href="#패션-MNIST" class="headerlink" title="패션 MNIST"></a>패션 MNIST</h1><h1 id="딥러닝-라이브러리"><a href="#딥러닝-라이브러리" class="headerlink" title="딥러닝 라이브러리"></a>딥러닝 라이브러리</h1><ul>
<li>텐서플로 : <a target="_blank" rel="noopener" href="https://www.tensorflow.org/">https://www.tensorflow.org/</a><ul>
<li>2016년 텐서플로 1 버전 vs 텐서플로 2 버전</li>
<li>문법적으로 매우 다름</li>
<li>산업용</li>
</ul>
</li>
<li>파이토치 : <a target="_blank" rel="noopener" href="https://pytorch.org/">https://pytorch.org/</a><ul>
<li>연구용</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow</span><br><span class="line"><span class="built_in">print</span>(tensorflow.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>2.8.0
</code></pre>
<h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()</span><br></pre></td></tr></table></figure>

<ul>
<li>데이터 확인<ul>
<li>60000개 이미지, 이미지 크기는 28 * 28</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input.shape, train_target.shape)</span><br><span class="line"><span class="built_in">print</span>(test_input.shape, test_target.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(60000, 28, 28) (60000,)
(10000, 28, 28) (10000,)
</code></pre>
<ul>
<li>이미지 시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, axs= plt.subplots(<span class="number">1</span>, <span class="number">10</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">  axs[i].imshow(train_input[i], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">  axs[i].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0404_Artificial_Neural_Network/output_8_0.png" alt="png"></p>
<ul>
<li>타겟값 리스트</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>([train_target[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)])</span><br></pre></td></tr></table></figure>

<pre><code>[9, 0, 0, 3, 0, 2, 7, 2, 5, 5]
</code></pre>
<ul>
<li>실제 타겟값의 값을 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(np.unique(train_target, return_counts= <span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<pre><code>(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]))
</code></pre>
<h1 id="로지스틱-회귀로-패션-아이템-분류하기"><a href="#로지스틱-회귀로-패션-아이템-분류하기" class="headerlink" title="로지스틱 회귀로 패션 아이템 분류하기"></a>로지스틱 회귀로 패션 아이템 분류하기</h1><ul>
<li>경사하강법(기울기)</li>
<li>전제조건: 각 컬럼의 데이터셋 동일 (표준화)</li>
<li>why 255? : 각 픽셀의 값 0 ~ 255 사이의 정숫값을 가진다.</li>
<li>0 ~ 1 사이의 값으로 정규화 시킴</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_scaled = train_input/ <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1차원 배열로 만들기</span></span><br><span class="line">train_scaled = train_scaled.reshape(-<span class="number">1</span>, <span class="number">28</span>* <span class="number">28</span>)</span><br><span class="line"><span class="built_in">print</span>(train_scaled.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(60000, 784)
</code></pre>
<h2 id="모델-만들기"><a href="#모델-만들기" class="headerlink" title="모델 만들기"></a>모델 만들기</h2><ul>
<li>비정형데이터에 선형모델 또는 비선형 모델을 적용시키는것이 합리적인가??<ul>
<li>결론: 아니다!</li>
<li>다른 대안은 있는가??: 인공신경망!</li>
</ul>
</li>
<li>정형데이터에 인공신경망 및 딥러닝 모델을 적용시키는 것이 합리적인가<ul>
<li>결론: 아니다!</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>, max_iter=<span class="number">5</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scores = cross_validate(sc, train_scaled, train_target, n_jobs=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8195666666666668
</code></pre>
<h2 id="인공신경망-모델-적용"><a href="#인공신경망-모델-적용" class="headerlink" title="인공신경망 모델 적용"></a>인공신경망 모델 적용</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_scaled, val_scaled, train_target, val_target = train_test_split(</span><br><span class="line">    train_scaled, train_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_scaled.shape, train_target.shape)</span><br><span class="line"><span class="built_in">print</span>(val_scaled.shape, val_target.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(48000, 784) (48000,)
(12000, 784) (12000,)
</code></pre>
<ul>
<li><p>밀집하게 연결되어 있는것을 완전 연결층</p>
<ul>
<li>fully connected layer</li>
</ul>
</li>
<li><p>p.354</p>
<ul>
<li>이진분류 시그모이드 함수(로지스틱 회귀)</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dense = keras.layers.Dense(<span class="number">10</span>, activation= <span class="string">&#x27;softmax&#x27;</span>, input_shape=(<span class="number">784</span>, ))</span><br><span class="line">model = keras.Sequential(dense)</span><br><span class="line">model.<span class="built_in">compile</span>(loss= <span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics= <span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">model.fit(train_scaled, train_target, epochs= <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.6102 - accuracy: 0.7926
Epoch 2/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4791 - accuracy: 0.8392
Epoch 3/5
1500/1500 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.8481
Epoch 4/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4453 - accuracy: 0.8519
Epoch 5/5
1500/1500 [==============================] - 2s 2ms/step - loss: 0.4363 - accuracy: 0.8558





&lt;keras.callbacks.History at 0x7f04ab0dcc50&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(val_scaled, val_target)</span><br></pre></td></tr></table></figure>

<pre><code>375/375 [==============================] - 1s 3ms/step - loss: 0.4559 - accuracy: 0.8462





[0.45591267943382263, 0.8462499976158142]
</code></pre>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>인공신경망: 생물학적 뉴런에서 영감을 받아 만든 머신러닝 알고리즘. 인공신경망 알고리즘을 종종 딥러닝이라고 부름.</li>
<li>텐서플로: 구글이 만든 딥러닝 라이브러리. 케라스를 사용하면 간단한 모델에서 아주 복잡한 모델까지 손쉽게 만들 수 있다.</li>
<li>밀집층: 가장 간단한 인공 신경망의 층</li>
<li>원-핫 인코딩: 정숫값을 배열에서 해당 정수 위치의 원소만 1이고 나머지는 모두 0으로 변환</li>
</ul>
</li>
<li>TensorFlow 패키지<ul>
<li>Dense: 신경망에서 가장 기본 층인 밀집층을 만드는 클래스</li>
<li>Sequential: 케라스에서 신경망 모델을 만드는 클래스</li>
<li>Compile(): 모델 객체를 만든 후 훈련하기 전에 사용할 손실 함수와 측정 지표 등을 지정하는 메서드</li>
<li>fit(): 모델을 훈련하는 메서드</li>
<li>evaluate(): 모델 성능을 평가하는 메서드</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/04/04/0404_Artificial_Neural_Network/" data-id="cl1km1j0d0000pwnh8gh4go09" data-title="인공_신경망" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0331_Principar_Component_Analysis_01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/31/0331_Principar_Component_Analysis_01/" class="article-date">
  <time class="dt-published" datetime="2022-03-31T00:00:00.000Z" itemprop="datePublished">2022-03-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/31/0331_Principar_Component_Analysis_01/">주성분_분석_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h1><h3 id="중요"><a href="#중요" class="headerlink" title="중요"></a><em><strong>중요</strong></em></h3><ul>
<li><p>차원 축소의 개념</p>
</li>
<li><p>PCA개념</p>
</li>
<li><p>과일 사진의 경우, 10000개의 픽셀 (높이 * 너비)</p>
<ul>
<li>10000개의 특성이 있는 셈(차원)</li>
</ul>
</li>
<li><p>정형데이터에서도 활용 가능</p>
<ul>
<li>문자열 데이터, 수치형 데이터 (연속형 데이터, 비연속형 데이터)</li>
<li>캐글 대회: 수치형 데이터 304개<ul>
<li>연산은 RAM에서 처리</li>
<li>라면을 5개 끓여야하는데 냄비 크기는 3개분량의 크기인 상황</li>
</ul>
</li>
</ul>
</li>
<li><p>차원축소 &#x3D; 일부 특성을 선택하여 데이터 크기를 줄임</p>
</li>
<li><p>머신러닝 측면: 과대적합 방지 &amp; 성능 향상</p>
</li>
<li><p>양적 데이터 사이의 분산-공분산 관계를 이용해서 선형결합으로 표시되는 주성분을 찾음</p>
</li>
<li><p>2-3개의 주성분으로 전체 변동을 찾는것이 PCA</p>
</li>
<li><p>알고리즘 구성 할 때, 필요한 데이터 픽셀 수</p>
<ul>
<li>300* 10000개 픽셀</li>
<li>300 * PCA 10주성분으로 줄임</li>
<li>기존 1시간 걸리던게 10분으로 줄어듦</li>
<li>그럼에도 불구하고, 분류가 더 잘됨</li>
</ul>
</li>
</ul>
<h1 id="PCA-클래스"><a href="#PCA-클래스" class="headerlink" title="PCA 클래스"></a>PCA 클래스</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-03-31 06:16:41--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11
Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-03-31 06:16:41--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 140.82.114.4
Connecting to github.com (github.com)|140.82.114.4|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-03-31 06:16:41--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.02s   

2022-03-31 06:16:41 (169 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fruits = np.load(<span class="string">&#x27;fruits_300.npy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(fruits.shape)  <span class="comment"># fruits: 3차원 배열</span></span><br><span class="line">fruits_2d = fruits.reshape(-<span class="number">1</span>, <span class="number">100</span>*<span class="number">100</span>)</span><br><span class="line">fruits_2d.shape  <span class="comment"># fruits_2d: 2차원 배열</span></span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)





(300, 10000)
</code></pre>
<ul>
<li>sklaern.decomposition 모듈</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components= <span class="number">50</span>)</span><br><span class="line"><span class="comment"># PCA 50개 성분으로 300 * 10000픽셀값을 압축</span></span><br><span class="line">pca.fit(fruits_2d)</span><br></pre></td></tr></table></figure>




<pre><code>PCA(n_components=50)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pca.components_.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(50, 10000)
</code></pre>
<ul>
<li>그래프 그리기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_fruits</span>(<span class="params">arr, ratio=<span class="number">1</span></span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)    <span class="comment"># n은 샘플 개수입니다</span></span><br><span class="line">    <span class="comment"># 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. </span></span><br><span class="line">    rows = <span class="built_in">int</span>(np.ceil(n/<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.</span></span><br><span class="line">    cols = n <span class="keyword">if</span> rows &lt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">10</span></span><br><span class="line">    fig, axs = plt.subplots(rows, cols, </span><br><span class="line">                            figsize=(cols*ratio, rows*ratio), squeeze=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">            <span class="keyword">if</span> i*<span class="number">10</span> + j &lt; n:    <span class="comment"># n 개까지만 그립니다.</span></span><br><span class="line">                axs[i, j].imshow(arr[i*<span class="number">10</span> + j], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">            axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># draw_fruits(fruits[km.labels_ == 0])</span></span><br><span class="line">draw_fruits(pca.components_.reshape(-<span class="number">1</span>, <span class="number">100</span>, <span class="number">100</span>))</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_12_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_pca = pca.transform(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(fruits_pca.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 50)
</code></pre>
<ul>
<li>데이터의 원래 크기 대비해서 1&#x2F;200 줄임</li>
<li>용량이 줄었다는 것과 똑같음</li>
</ul>
<h1 id="원본-데이터-재구성"><a href="#원본-데이터-재구성" class="headerlink" title="원본 데이터 재구성"></a>원본 데이터 재구성</h1><ul>
<li>10000개의 특성을 50개로 줄임</li>
<li>100% 재구성은 어렵지만, 그래도 쓸만하다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inverse_transform(): 축소시킨 데이터를 다시 복원</span></span><br><span class="line">fruits_inverse = pca.inverse_transform(fruits_pca)</span><br><span class="line"><span class="built_in">print</span>(fruits_inverse.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 10000)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_reconstruct = fruits_inverse.reshape(-<span class="number">1</span>, <span class="number">100</span>, <span class="number">100</span>)  <span class="comment"># 다시 3차원으로 재배열</span></span><br><span class="line"><span class="built_in">print</span>(fruits_reconstruct.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>  start <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">100</span>, <span class="number">200</span>]:</span><br><span class="line">  draw_fruits(fruits_reconstruct[start:start+<span class="number">100</span>])</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_18_0.png" alt="png"></p>
<p><img src="/Images/0331_Principar_Component_Analysis_01/output_18_2.png" alt="png"></p>
<p><img src="/Images/0331_Principar_Component_Analysis_01/output_18_4.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ## 주성분을 2개로 지정했을때 나오는 형태</span></span><br><span class="line"><span class="comment"># pca = PCA(n_components= 2)</span></span><br><span class="line"><span class="comment"># pca.fit(fruits_2d)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fruits_pca = pca.transform(fruits_2d)</span></span><br><span class="line"><span class="comment"># # print(fruits_pca.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fruits_inverse = pca.inverse_transform(fruits_pca)</span></span><br><span class="line"><span class="comment"># # print(fruits_inverse.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fruits_reconstruct = fruits_inverse.reshape(-1, 100, 100)</span></span><br><span class="line"><span class="comment"># # print(fruits_reconstruct.shape)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># for  start in [0, 100, 200]:</span></span><br><span class="line"><span class="comment">#   draw_fruits(fruits_reconstruct[start:start+100])</span></span><br><span class="line"><span class="comment">#   print(&quot;\n&quot;)</span></span><br></pre></td></tr></table></figure>

<h1 id="설명된-분산"><a href="#설명된-분산" class="headerlink" title="설명된 분산"></a>설명된 분산</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># explained_variance_ratio_: 분산의 비율</span></span><br><span class="line">plt.plot(pca.explained_variance_ratio_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_21_0.png" alt="png"></p>
<ul>
<li>처음 10개의 주성분이 대부분의 분산을 표현한다.</li>
<li>11개 주성분부터 ~50개까지는 잘 설명이 안됨.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 92퍼센트정도 설명이 가능하다는걸 확인</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(pca.explained_variance_ratio_))</span><br></pre></td></tr></table></figure>

<pre><code>0.9215689086016662
</code></pre>
<h1 id="다른-알고리즘과-함께-사용하기"><a href="#다른-알고리즘과-함께-사용하기" class="headerlink" title="다른 알고리즘과 함께 사용하기"></a>다른 알고리즘과 함께 사용하기</h1><ul>
<li>3개의 과일 사진 분류 위해 로지스틱 회귀</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"></span><br><span class="line">target = np.array([<span class="number">0</span>]* <span class="number">100</span> + [<span class="number">1</span>]* <span class="number">100</span> + [<span class="number">2</span>]* <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br></pre></td></tr></table></figure>

<pre><code>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores = cross_validate(lr, fruits_2d, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9966666666666667
1.3491935729980469
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PCA 수행 후, 학습 시간 비교</span></span><br><span class="line">scores = cross_validate(lr, fruits_pca, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>1.0
0.023451614379882812
</code></pre>
<ul>
<li>주성분의 매개변수 개수 지정, 분산 비율 지정</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components= <span class="number">0.5</span>)</span><br><span class="line">pca.fit(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(pca.n_components_)</span><br></pre></td></tr></table></figure>

<pre><code>2
</code></pre>
<ul>
<li>주성분을 2개로 압축</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_pca = pca.transform(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(fruits_pca.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 2)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = cross_validate(lr, fruits_pca, target)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;fit_time&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9933333333333334
0.03700056076049805


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">km = KMeans(n_clusters=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">km.fit(fruits_pca)</span><br><span class="line"><span class="built_in">print</span>(np.unique(km.labels_, return_counts=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<pre><code>(array([0, 1, 2], dtype=int32), array([110,  99,  91]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">  draw_fruits(fruits[km.labels_== label])</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;/n&quot;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_34_0.png" alt="png"></p>
<pre><code>/n
</code></pre>
<p><img src="/Images/0331_Principar_Component_Analysis_01/output_34_2.png" alt="png"></p>
<pre><code>/n
</code></pre>
<p><img src="/Images/0331_Principar_Component_Analysis_01/output_34_4.png" alt="png"></p>
<pre><code>/n
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>):</span><br><span class="line">  data = fruits_pca[km.labels_== label]</span><br><span class="line">  plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>])</span><br><span class="line">plt.legend([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>, <span class="string">&#x27;pineapple&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Principar_Component_Analysis_01/output_35_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>차원 축소: 원본 데이터의 특성을 적은 수의 새로운 특성으로 변환하는 비지도 학습의 한 종류. 저장공간을 줄이고 시각화 하기 쉽다. 다른 알고리즘의 성능을 높임.</li>
<li>주성분 분석: 차원 축소의 알고리즘의 하나로 데이터에서 가장 분산이 큰 방향을 찾는 방법</li>
<li>설명된 분석: 주성분 분석에서 주성분이 얼마나 원본 데이터의 분산을 잘 나타내는지 기록한것</li>
</ul>
</li>
<li>Scikit-learn 패키지<ul>
<li>PCA: 주성분 분석을 수행하는 클래스<ul>
<li>n_components: 주성분의 개수를 지정 [default: None](샘플 개수와 특성 개수중에서 작은 것의 값을 사용)</li>
<li>random_state: 넘파이 난수 시드값을 지정</li>
<li>속성 components_: 훈련세트에서 찾은 주성분이 저장</li>
<li>속성 explained_variance_ : 설명된 분산이 저장</li>
<li>속성 explained_variance_ratio_: 설명된 분산의 비율이 저장</li>
<li>inverse_transform(): transfrom()메서드로 차원을 축소시킨 데이터를 다시 원본 차원으로 복원함.</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/31/0331_Principar_Component_Analysis_01/" data-id="cl1ewiwzi0000d0nh12tud94l" data-title="주성분_분석_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0331_Unsupervised_Learning" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/31/0331_Unsupervised_Learning/" class="article-date">
  <time class="dt-published" datetime="2022-03-31T00:00:00.000Z" itemprop="datePublished">2022-03-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/31/0331_Unsupervised_Learning/">비지도_학습_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="비지도-학습"><a href="#비지도-학습" class="headerlink" title="비지도 학습"></a>비지도 학습</h1><ul>
<li>vs 지도학습</li>
<li>종속변수 &#x3D; 타겟</li>
<li>비짇 학습은 종속변수 및 타겟이 없음</li>
<li>분류<ul>
<li>다중분류</li>
<li>전제조건이 (다양한 유형) 데이터가 많아야 함</li>
<li>딥러닝과 연관이 됨 (자연어 처리, 이미지)</li>
</ul>
</li>
</ul>
<h1 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-03-31 01:10:43--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10
Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-03-31 01:10:43--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 140.82.112.3
Connecting to github.com (github.com)|140.82.112.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-03-31 01:10:43--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.01s   

2022-03-31 01:10:43 (210 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<ul>
<li>numpy 파일을 불러옴</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fruits = np.load(<span class="string">&#x27;fruits_300.npy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(fruits.shape)</span><br><span class="line"><span class="built_in">print</span>(fruits.ndim)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)
3
</code></pre>
<ul>
<li>첫번째 차원 &#x3D; 샘플의 개수</li>
<li>두번째 차원 &#x3D; 이미지 높이</li>
<li>세번째 차원 &#x3D; 이미지 넓이</li>
<li>이미지 크기 100 * 100</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fruits[<span class="number">0</span>, <span class="number">0</span>, :]</span><br></pre></td></tr></table></figure>




<pre><code>array([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,
         1,   1,   1,   2,   1,   2,   2,   2,   2,   2,   2,   1,   1,
         1,   1,   1,   1,   1,   1,   2,   3,   2,   1,   2,   1,   1,
         1,   1,   2,   1,   3,   2,   1,   3,   1,   4,   1,   2,   5,
         5,   5,  19, 148, 192, 117,  28,   1,   1,   2,   1,   4,   1,
         1,   3,   1,   1,   1,   1,   1,   2,   2,   1,   1,   1,   1,
         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,
         1,   1,   1,   1,   1,   1,   1,   1,   1], dtype=uint8)
</code></pre>
<ul>
<li>이미지 시각화<ul>
<li>흑백사진을 담고 있다.</li>
<li>0 ~ 255까지의 정수값을 가진다.<ul>
<li>0에 가까우면 검게 나타남</li>
<li>255에 가까우면 밝게 나타남</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(fruits[<span class="number">0</span>], cmap= <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<pre><code>/Images/0331_Unsupervised_Learning
</code></pre>
<p><img src="/Images/0331_Unsupervised_Learning/output_8_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cmap = &#x27;gray_r&#x27; 일 경우 반대로 나타남</span></span><br><span class="line">plt.imshow(fruits[<span class="number">0</span>], cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_9_0.png" alt="png"></p>
<ul>
<li>여러 이미지 시각화</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">axs[<span class="number">0</span>].imshow(fruits[<span class="number">100</span>], cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].imshow(fruits[<span class="number">200</span>], cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_11_0.png" alt="png"></p>
<h1 id="픽셀값-분석"><a href="#픽셀값-분석" class="headerlink" title="픽셀값 분석"></a>픽셀값 분석</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">apple = fruits[<span class="number">0</span>: <span class="number">100</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)</span><br><span class="line">pineapple = fruits[<span class="number">100</span>: <span class="number">200</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)</span><br><span class="line">banana = fruits[<span class="number">200</span>: <span class="number">300</span>].reshape(-<span class="number">1</span>, <span class="number">100</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(apple.shape, banana.shape, pineapple.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(100, 10000) (100, 10000) (100, 10000)
</code></pre>
<ul>
<li><p>axis &#x3D; 0 vs axis &#x3D; 1 차이 확인(p,293)</p>
</li>
<li><p>각 이미지에 대한 픽셀 평균값 비교</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># axis= 1  : 행 기준</span></span><br><span class="line"><span class="built_in">print</span>(apple.mean(axis= <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[ 88.3346  97.9249  87.3709  98.3703  92.8705  82.6439  94.4244  95.5999
  90.681   81.6226  87.0578  95.0745  93.8416  87.017   97.5078  87.2019
  88.9827 100.9158  92.7823 100.9184 104.9854  88.674   99.5643  97.2495
  94.1179  92.1935  95.1671  93.3322 102.8967  94.6695  90.5285  89.0744
  97.7641  97.2938 100.7564  90.5236 100.2542  85.8452  96.4615  97.1492
  90.711  102.3193  87.1629  89.8751  86.7327  86.3991  95.2865  89.1709
  96.8163  91.6604  96.1065  99.6829  94.9718  87.4812  89.2596  89.5268
  93.799   97.3983  87.151   97.825  103.22    94.4239  83.6657  83.5159
 102.8453  87.0379  91.2742 100.4848  93.8388  90.8568  97.4616  97.5022
  82.446   87.1789  96.9206  90.3135  90.565   97.6538  98.0919  93.6252
  87.3867  84.7073  89.1135  86.7646  88.7301  86.643   96.7323  97.2604
  81.9424  87.1687  97.2066  83.4712  95.9781  91.8096  98.4086 100.7823
 101.556  100.7027  91.6098  88.8976]
</code></pre>
<ul>
<li>각 과일에 대한 히스토그램</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="comment"># ax.hist(np.mean(apple, axis= 1), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(banana, axis= 1), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(pineapple, axis= 1), alpha= 0.8)</span></span><br><span class="line"></span><br><span class="line">ax.hist(apple.mean(axis= <span class="number">1</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line">ax.hist(pineapple.mean(axis= <span class="number">1</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line">ax.hist(banana.mean(axis= <span class="number">1</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line"><span class="comment"># ax.hist(np.mean(apple, axis= 0), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(banana, axis= 0), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(pineapple, axis= 0), alpha= 0.8)</span></span><br><span class="line"></span><br><span class="line">ax.legend([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;pineapple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_18_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="comment"># ax.hist(np.mean(apple, axis= 1), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(banana, axis= 1), alpha= 0.8)</span></span><br><span class="line"><span class="comment"># ax.hist(np.mean(pineapple, axis= 1), alpha= 0.8)</span></span><br><span class="line"></span><br><span class="line">ax.hist(np.mean(apple, axis= <span class="number">0</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line">ax.hist(np.mean(banana, axis= <span class="number">0</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line">ax.hist(np.mean(pineapple, axis= <span class="number">0</span>), alpha= <span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">ax.legend([<span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;pineapple&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_19_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize= (<span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line">axs[<span class="number">0</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(apple, axis= <span class="number">0</span>))</span><br><span class="line">axs[<span class="number">1</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(pineapple, axis= <span class="number">0</span>))</span><br><span class="line">axs[<span class="number">2</span>].bar(<span class="built_in">range</span>(<span class="number">10000</span>), np.mean(banana, axis= <span class="number">0</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_20_0.png" alt="png"></p>
<ul>
<li>대표 이미지</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apple_mean = np.mean(apple, axis= <span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">pineapple_mean = np.mean(pineapple, axis= <span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">banana_mean = np.mean(banana, axis= <span class="number">0</span>).reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize= (<span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line">axs[<span class="number">0</span>].imshow(apple_mean, cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].imshow(pineapple_mean, cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">axs[<span class="number">2</span>].imshow(banana_mean, cmap= <span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line"><span class="comment"># axs[3].imshow(apple_mean, cmap= &#x27;gray_r&#x27;)</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_22_0.png" alt="png"></p>
<h1 id="평균값과-가까운-사진-고르기"><a href="#평균값과-가까운-사진-고르기" class="headerlink" title="평균값과 가까운 사진 고르기"></a>평균값과 가까운 사진 고르기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">abs_diff = np.<span class="built_in">abs</span>(fruits- apple_mean)</span><br><span class="line">abs_mean = np.mean(abs_diff, axis=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(abs_mean.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300,)
</code></pre>
<ul>
<li>오차의 값이 가장 작은 순서대로 100개를 골라본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apple_index = np.argsort(abs_mean)[:<span class="number">100</span>]</span><br><span class="line">fig, axs= plt.subplots(<span class="number">10</span>, <span class="number">10</span>, figsize= (<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    axs[i, j].imshow(fruits[apple_index[i*<span class="number">10</span> + j]], cmap= <span class="string">&#x27;gray_r&#x27;</span>)  <span class="comment"># imshow(): 크기에 맞게 이미지 출력</span></span><br><span class="line">    axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)  <span class="comment"># 축 지우기</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_26_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">3</span>, figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># axs[0].imshow(apple_mean, cmap= &#x27;gray_r&#x27;) </span></span><br><span class="line"><span class="comment"># axs[1].imshow(pineapple_mean, cmap= &#x27;gray_r&#x27;)</span></span><br><span class="line"><span class="comment"># axs[2].imshow(banana_mean, cmap= &#x27;gray_r&#x27;)</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fig, axs = plt.subplots()</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_Unsupervised_Learning/output_27_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>비지도 학습: 머신러닝의 한 종류로 훈련 데이터에 타깃이 없음. 타깃이 없기 때문에 외부의 도움 없이 스스로 유용한 무언가를 학습해야함.</li>
<li>히스토그램: 구간별로 값이 발생한 빈도를 그래프로 표시</li>
<li>군집: 비슷한 샘플끼리 하나의 그룹으로 모으는 대표적인 비지도 학습 작업</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/31/0331_Unsupervised_Learning/" data-id="cl1ewiwzv0001d0nhfboydkj9" data-title="비지도_학습_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0331_K_Means_01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/31/0331_K_Means_01/" class="article-date">
  <time class="dt-published" datetime="2022-03-31T00:00:00.000Z" itemprop="datePublished">2022-03-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/31/0331_K_Means_01/">K-평균_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="K-평균"><a href="#K-평균" class="headerlink" title="K-평균"></a>K-평균</h1><ul>
<li><p>각각의 픽셀값 (3차원 -&gt; 1차원 배열) 평균 구함</p>
<ul>
<li>픽셀의 평균값을 활용해서 사과, 바나나, 파인애플에 근사한 이미지를 추출하는 것</li>
</ul>
</li>
<li><p>어떻게 평균값을 구할 수 있을까?</p>
<ul>
<li>K-평균 알고리즘(K-Means) 알고리즘</li>
<li>평균값 &#x3D; Cluster Center &#x3D; Centroid</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-03-31 02:14:27--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10
Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-03-31 02:14:27--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 140.82.114.3
Connecting to github.com (github.com)|140.82.114.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-03-31 02:14:28--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.07s   

2022-03-31 02:14:28 (43.0 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fruits = np.load(<span class="string">&#x27;fruits_300.npy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(fruits.shape)</span><br><span class="line"><span class="built_in">print</span>(fruits.ndim)  <span class="comment"># ndim: n차원인지 알아냄</span></span><br><span class="line"><span class="comment"># print(fruits[:5])</span></span><br></pre></td></tr></table></figure>

<pre><code>(300, 100, 100)
3
</code></pre>
<ul>
<li>3차원 (샘플개수, 넓이, 높이)</li>
<li>2차원 (샘플개수, 넓이* 높이)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fruits_2d = fruits.reshape(-<span class="number">1</span>, <span class="number">100</span>* <span class="number">100</span>)</span><br><span class="line">fruits_2d.shape</span><br></pre></td></tr></table></figure>




<pre><code>(300, 10000)
</code></pre>
<ul>
<li>K-평균 알고리즘 활용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">km = KMeans(n_clusters= <span class="number">3</span>, random_state= <span class="number">42</span>)</span><br><span class="line">km.fit(fruits_2d)</span><br></pre></td></tr></table></figure>




<pre><code>KMeans(n_clusters=3, random_state=42)
</code></pre>
<ul>
<li>모형학습 후, labels 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(km.labels_)</span><br></pre></td></tr></table></figure>

<pre><code>[2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1]
</code></pre>
<ul>
<li>직접 샘플의 개수 확인</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.unique(km.labels_, return_counts= <span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<pre><code>(array([0, 1, 2], dtype=int32), array([111,  98,  91]))
</code></pre>
<ul>
<li>그래프를 그려본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_fruits</span>(<span class="params">arr, ratio=<span class="number">1</span></span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)    <span class="comment"># n은 샘플 개수입니다</span></span><br><span class="line">    <span class="comment"># 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. </span></span><br><span class="line">    rows = <span class="built_in">int</span>(np.ceil(n/<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.</span></span><br><span class="line">    cols = n <span class="keyword">if</span> rows &lt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">10</span></span><br><span class="line">    fig, axs = plt.subplots(rows, cols, </span><br><span class="line">                            figsize=(cols*ratio, rows*ratio), squeeze=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">            <span class="keyword">if</span> i*<span class="number">10</span> + j &lt; n:    <span class="comment"># n 개까지만 그립니다.</span></span><br><span class="line">                axs[i, j].imshow(arr[i*<span class="number">10</span> + j], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">            axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_fruits(fruits[km.labels_ == <span class="number">0</span>])</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_K_Means_01/output_14_0.png" alt="png"></p>
<h1 id="크러스터-중심"><a href="#크러스터-중심" class="headerlink" title="크러스터 중심"></a>크러스터 중심</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_fruits(km.cluster_centers_.reshape(-<span class="number">1</span>, <span class="number">100</span>, <span class="number">100</span>), ratio= <span class="number">3</span>)</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_K_Means_01/output_16_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(km.transform(fruits_2d[<span class="number">100</span>:<span class="number">101</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[[3393.8136117  8837.37750892 5267.70439881]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(km.predict(fruits_2d[<span class="number">100</span>:<span class="number">101</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_fruits(fruits[<span class="number">100</span>:<span class="number">101</span>])</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_K_Means_01/output_19_0.png" alt="png"></p>
<h1 id="최적의-K-찾기"><a href="#최적의-K-찾기" class="headerlink" title="최적의 K 찾기"></a>최적의 K 찾기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inertia= []</span></span><br><span class="line"><span class="comment"># for k in range(2,7):</span></span><br><span class="line"><span class="comment">#   km= KMeans(n_clusters= k, random_state= 42)</span></span><br><span class="line"><span class="comment">#   km.fit(fruits_2d)</span></span><br><span class="line"><span class="comment">#   inertia.append(km.inertia_)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.plot(range(2,7), inertia)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">inertia= []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,<span class="number">7</span>):</span><br><span class="line">  km= KMeans(n_clusters= k, random_state= <span class="number">42</span>)</span><br><span class="line">  km.fit(fruits_2d)</span><br><span class="line">  inertia.append(km.inertia_)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(<span class="built_in">range</span>(<span class="number">2</span>,<span class="number">7</span>), inertia)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/Images/0331_K_Means_01/output_22_0.png" alt="png"></p>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li>키워드<ul>
<li>K-평균: 처음에 랜덤하게 클러스터 중심을 정하고 클러스터를 만듬. 그 후에 클러스터의 중심을 이동하고 다시 클러스터를 만드는 식으로 반복해서 최적의 클러스터를 구성하는 알고리즘.</li>
<li>클러스터 중심: K-평균 알고리즘이 만든 클러스터에 속한 샘플의 특성 평균값. 센트로이드라고도 부름</li>
<li>엘보우 방법: 최적의 클러스터 개수를 정하는 방법 중 하나</li>
</ul>
</li>
<li>Scikit-Learn 패키지<ul>
<li>KMeans: K-평균 알고리즘 클래스<ul>
<li>n_clusters: 클러스터 개수를 지정. [default: 8]</li>
<li>n_init: 반복 횟수를 지정. [default: 10]</li>
<li>max_iter: K-평균 알고리즘의 한 번 실행에서 최적의 센트로이드를 찾기 위해 반복 할 수 있는 최대 횟수. [default: 200]</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/31/0331_K_Means_01/" data-id="cl1ewiwzw0002d0nhgzdzcf01" data-title="K-평균_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-0330_Cross_Validation01" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/30/0330_Cross_Validation01/" class="article-date">
  <time class="dt-published" datetime="2022-03-30T00:00:00.000Z" itemprop="datePublished">2022-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/03/30/0330_Cross_Validation01/">교차검증과_랜덤서치_01</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="교차-검증과-그리드-서치"><a href="#교차-검증과-그리드-서치" class="headerlink" title="교차 검증과 그리드 서치"></a>교차 검증과 그리드 서치</h1><ul>
<li>키워드: 하이퍼 파라미터</li>
<li>데이터가 작을 때, 주로 사용</li>
<li>하이퍼 파라미터<ul>
<li>max_depth: 3일때, 정확도가 84%</li>
</ul>
</li>
<li>결론<ul>
<li>모르면 default만 쓸것</li>
<li>가성비 (시간 대비 성능 보장 안됨)</li>
</ul>
</li>
</ul>
<h1 id="검증-세트"><a href="#검증-세트" class="headerlink" title="검증 세트"></a>검증 세트</h1><ul>
<li>테스트 세트 (1회성)</li>
<li>훈련 데이터를 훈련데이터 + 검증 데이터로 재분할</li>
</ul>
<h2 id="현실"><a href="#현실" class="headerlink" title="현실"></a>현실</h2><ul>
<li>테스트 데이터가 별도로 존재안함</li>
<li>ex) 전체 데이터 &#x3D; 훈련(6) : 검증(2) : 테스트(2)<ul>
<li>테스트 데이터는 모르는 데이터로 간주</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&quot;https://bit.ly/wine_csv_data&quot;</span>)</span><br><span class="line"></span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target= wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br><span class="line">wine.head()</span><br></pre></td></tr></table></figure>





  <div id="df-7bbb17c4-c2ff-4a49-b897-7cc39b6d3337">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.8</td>
      <td>2.6</td>
      <td>3.20</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9.8</td>
      <td>2.3</td>
      <td>3.26</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9.8</td>
      <td>1.9</td>
      <td>3.16</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.4</td>
      <td>1.9</td>
      <td>3.51</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7bbb17c4-c2ff-4a49-b897-7cc39b6d3337')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-7bbb17c4-c2ff-4a49-b897-7cc39b6d3337 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-7bbb17c4-c2ff-4a49-b897-7cc39b6d3337&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size= <span class="number">0.2</span>, random_state= <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(5197, 3) (1300, 3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train 데이터의 20%를 val 데이터로 분류</span></span><br><span class="line">sub_input, val_input, sub_target, val_target = train_test_split(</span><br><span class="line">    train_input, train_target, test_size= <span class="number">0.2</span>, random_state= <span class="number">42</span>  <span class="comment"># random_state: 추출값 고정이 목적</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(sub_input.shape, val_input.shape, val_target.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(4157, 3) (1040, 3) (1040,)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(sub_input, sub_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(sub_input, sub_target))  <span class="comment"># 0.9971133028626413</span></span><br><span class="line"><span class="built_in">print</span>(dt.score(val_input, val_target))  <span class="comment"># 0.864423076923077</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9971133028626413
0.864423076923077
</code></pre>
<h1 id="교차검증"><a href="#교차검증" class="headerlink" title="교차검증"></a>교차검증</h1><ul>
<li>교차검증의 목적: 좋은 모델이 만들어진다!<ul>
<li>좋은 모델 &#x3D; 과대적합이 아닌 모델 &#x3D; 모형의 오차가 적은 모델 &#x3D; 안정적인 모델</li>
<li>성능 좋은 모델이 좋은 모델이란게 아님</li>
</ul>
</li>
<li>교재 245p<ul>
<li>모델평가1: 90% (소요시간: 1시간)</li>
<li>모델평가2: 85%</li>
<li>모델평가3: 80%</li>
</ul>
</li>
<li>단점: 시간이 오래 걸림</li>
</ul>
<h1 id="교차검증-함수"><a href="#교차검증-함수" class="headerlink" title="교차검증 함수"></a>교차검증 함수</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores = cross_validate(dt, train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.0083735 , 0.00927544, 0.00848556, 0.00817442, 0.00816131]), &#39;score_time&#39;: array([0.00126314, 0.00097775, 0.00073361, 0.00077486, 0.00080872]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125;
</code></pre>
<ul>
<li>최종점수 평균 구하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.855300214703487
</code></pre>
<ul>
<li>훈련 세트 섞은 후, 10-폴드 교차검증</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line">splitter = StratifiedKFold(n_splits = <span class="number">10</span>, shuffle = <span class="literal">True</span>, random_state = <span class="number">42</span>)</span><br><span class="line">scores = cross_validate(dt, train_input, train_target, cv= splitter)</span><br><span class="line"><span class="built_in">print</span>(scores[<span class="string">&#x27;test_score&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[0.84807692 0.89423077 0.87115385 0.85576923 0.86346154 0.87884615
 0.87692308 0.86319846 0.87668593 0.87475915]
0.8703105083740921
</code></pre>
<h1 id="하이퍼파라미터-튜닝"><a href="#하이퍼파라미터-튜닝" class="headerlink" title="하이퍼파라미터 튜닝"></a>하이퍼파라미터 튜닝</h1><ul>
<li>그리드 서치 vs 랜덤 서치</li>
<li>꼭 사용하고 싶다면 -&gt; 랜덤 서치 사용</li>
<li>자동으로 잡아주는 라이브러리 등장<ul>
<li>hyperopt 등등…</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.core.common <span class="keyword">import</span> random_state</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">params = &#123;<span class="string">&#x27;min_impurity_decrease&#x27;</span>: [<span class="number">0.0001</span>, <span class="number">0.0002</span>, <span class="number">0.0003</span>, <span class="number">0.0004</span>, <span class="number">0.0005</span>],</span><br><span class="line">          <span class="comment"># &#x27;max_depth&#x27;: [3, 4, 5, 6, 7]</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># dt = DecisionTreeClassifier(random_state= 42)</span></span><br><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>),params, n_jobs= -<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,
             param_grid=&#123;&#39;min_impurity_decrease&#39;: [0.0001, 0.0002, 0.0003,
                                                   0.0004, 0.0005]&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt= gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_input, train_target))</span><br><span class="line"><span class="built_in">print</span>(gs.best_params_)</span><br></pre></td></tr></table></figure>

<pre><code>DecisionTreeClassifier(min_impurity_decrease=0.0001, random_state=42)
0.9615162593804117
&#123;&#39;min_impurity_decrease&#39;: 0.0001&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]
</code></pre>
<h1 id="랜덤서치"><a href="#랜덤서치" class="headerlink" title="랜덤서치"></a>랜덤서치</h1><ul>
<li>매개변수 값의 목록을 전달하는것이 아니라 매개변수를 샘플링 할 수 있도록 확률 분포 객체를 전달</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># scipy라이브러리: 적분, 보간, 선형대수, 확률 등을 포함한 수치 계산 전용으로 파이썬의 핵심 과학 라이브러리</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> uniform, randint  <span class="comment"># randint: 정수값을 뽑음,  uniform: 실수값을 뽑음.</span></span><br><span class="line">rgen = randint(<span class="number">0</span>,<span class="number">10</span>)</span><br><span class="line">rgen.rvs(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 4, 9, 5, 9, 9, 1, 0, 2, 1])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.unique(rgen.rvs(<span class="number">1000</span>), return_counts= <span class="literal">True</span>)  <span class="comment"># 각각 추출된 숫자의 갯수</span></span><br></pre></td></tr></table></figure>




<pre><code>(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
 array([ 99, 116,  90,  99,  87, 118, 104, 101,  81, 105]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ugen= uniform(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">ugen.rvs(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([0.4111007 , 0.57571785, 0.55554775, 0.58827729, 0.92876842,
       0.98869391, 0.87016065, 0.51721186, 0.54686086, 0.97925777])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span>: uniform(<span class="number">0.0001</span>, <span class="number">0.001</span>),</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: randint(<span class="number">20</span>, <span class="number">50</span>),</span><br><span class="line">    <span class="string">&#x27;min_samples_split&#x27;</span>: randint(<span class="number">2</span>, <span class="number">25</span>),</span><br><span class="line">    <span class="string">&#x27;min_samples_leaf&#x27;</span>: randint(<span class="number">1</span>, <span class="number">25</span>),&#125;</span><br><span class="line">gs = RandomizedSearchCV(DecisionTreeClassifier(random_state= <span class="number">42</span>), params,  <span class="comment"># n_iter: 파라미터 검색 횟수</span></span><br><span class="line">                        n_iter= <span class="number">100</span>, n_jobs= -<span class="number">1</span>, random_state= <span class="number">42</span>)  <span class="comment"># n_jobs: cpu코어 수</span></span><br><span class="line"></span><br><span class="line">gs.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=42),
                   n_iter=100, n_jobs=-1,
                   param_distributions=&#123;&#39;max_depth&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6ec0604a90&gt;,
                                        &#39;min_impurity_decrease&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6ec0604910&gt;,
                                        &#39;min_samples_leaf&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6ec0604e90&gt;,
                                        &#39;min_samples_split&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6ec0604a50&gt;&#125;,
                   random_state=42)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(gs.best_params_)  <span class="comment"># 최고의 교차검증 점수</span></span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;max_depth&#39;: 39, &#39;min_impurity_decrease&#39;: 0.00034102546602601173, &#39;min_samples_leaf&#39;: 7, &#39;min_samples_split&#39;: 13&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 검증 점수</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">max</span>(gs.cv_results_[<span class="string">&#x27;mean_test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8695428296438884
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 테스트 세트로 성능 확인</span></span><br><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_input, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.86
</code></pre>
<h1 id="마무리-정리"><a href="#마무리-정리" class="headerlink" title="마무리 정리"></a>마무리 정리</h1><ul>
<li><p>키워드</p>
<ul>
<li>검증세트: 하이퍼파라미터 튜닝을 위해 모델을 평가 할 때, 테스트 세트를 사용하지 않기 위해 훈련세트에서 다시 떼어 낸 데이터 세트</li>
<li>교차검증: 훈련세트를 여러 폴드로 나눈 다음 한 폴드가 검증 세트의 역할을 하고 나머지 폴드에서는 모델을 훈련</li>
<li>그리드 서치: 하이퍼파라미터 탐색을 자동화해주는 도구. 탐색할 매개변수를 나열하면 교차 거증을 수행하여 가장 좋은 검증 점수의 매개변수 조합을 선택. 이 매개변수 조합으로 최종 모델을 훈련</li>
<li>랜덤 서치: 연속된 매개변수 값을 탐색할 때 유용함. 탐색할 값을 직접 나열하는것이 아니고 탐색값을 샘플링 할 수 있는 확률 분포 객체를 전달</li>
</ul>
</li>
<li><p>Scikit-learn 패키지</p>
<ul>
<li>crpss_va;odate(): 교차 검증을 수행하는 함수</li>
<li>GridSerchCV: 교차검증으로 하이퍼파라미터 탐색을 수행</li>
<li>RandomizedSearchCV: 교차검증으로 랜덤한 하이퍼파라미터 탐색을 수행</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://woobinhwang.github.io/2022/03/30/0330_Cross_Validation01/" data-id="cl1dhk3ww0000hknhb8ob3ee9" data-title="교차검증과_랜덤서치_01" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/04/06/0406_Convolution_Neural_Network/">합성곱 신경망 (CNN)</a>
          </li>
        
          <li>
            <a href="/2022/04/06/0406_woob-s/">Kaggle 프로젝트</a>
          </li>
        
          <li>
            <a href="/2022/04/05/0404_Deep_Neural_Network/">심층_신경망</a>
          </li>
        
          <li>
            <a href="/2022/04/05/0405_Neural_Network_Model/">신경망_모델_훈련</a>
          </li>
        
          <li>
            <a href="/2022/04/05/0405_Pipeline/">파이프_라인_(데이터_전처리)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>